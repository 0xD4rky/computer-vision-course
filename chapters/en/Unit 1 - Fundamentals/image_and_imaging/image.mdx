
## Definition of Image
An image is a visual representation of something. An image is an n-dimensional function. To simplify things, we will consider it to be two-dimensional (n=2). Let us denote: F(X, Y), where X and Y are spatial coordinates. The amplitude of F at a pair of coordinates (x1, y1) is the intensity or gray level of the image at that point. Typically, when we have the pair coordinate x1 and y1, we refer to them as pixels (picture elements).
*add scheme here*
Most of the images are generated by a combination of an illumination source and the reflection or absorption of energy. We will discuss in more detail how different types of images will form in the chapter “How we imaged everything”.  What matters to us right now is that the value of F at specific coordinates holds a physical meaning. And that the function F(X, Y) is characterized by two components: the amount of illumination from the source and the amount of illumination reflected by the object in the scene. Images are also constrained in their intensity since the function is typically non-negative and their values are finite.
Volumetric or 3D images are images in which the number of dimensions is equal to three and as a result have an F(X, Y, Z). Most of our reason still applies, with the only difference being that the triplet x1, y1, z1 is called a voxel.
*add an example of 3D image
That is not the only type of representation that you could have within three dimensions, instead of z, you can also have a time component, thus F(X, Y, T).  This would be similar to video, but in which you have no audio.
*add an example of no video with no audio
As you can see, these are slightly different types of images, but they still respect our proposed definition. We note here that while images are discrete, the processes involved in assembling them are continuous, you will more details about how this affects image acquisition in the next section about the technical aspects of imaging.
Matrices are commonly used to represent images, often as a 2-D numerical array. They are widely employed in computers. Apart from gain-of-peformance in reading/writing and/or memory usage, most different image formats end up in your script as a numpy array. Seeing matrices as images helps to understand some of the processes in convolution neural networks and an a image preprocessing. For instace, aligning an image  might be decompose into a mix of rotation and shearing operations much like the tipical linear algebra problem. 
Alternatively, images might be represented as graphs where each edge is a coordinate and the edges are the neighboring coordinates. Take a moment to let that sink in, this means that the algorithms and models that are used for graphs can also be used for images. The inverse can also be true, you might be able to transform a graph into an image and analyze it as if it were a picture.

## Difference between Image and Video
#TODO

## Images vs other forms of data

In tabular data, dimensionality is usually defined by the number of features (columns) describing one data point. In data, dimensionality usually refer to the cardinality of your combined dimensions. Due to the spatial relantion in the data each pixel contributes to add more dimensions to the data. Features that describe your image are usually generated by traditional preprocessing or learned throught deep learning methods. Thus feature extraction in an image involves different algorithms discussed in detail in the next chapter of this unit.
Moreover, tabular data often require the handlign of missing values, encodning categorical variables and re-scaling numerical features. The analogous process for image data is image resizing, normalization or data augmentation. We call these processes pre-processing and we will discuss them in greater detail in the chapter "pre-processing for computer vision".

