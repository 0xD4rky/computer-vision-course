# Challenges and Pitfalls Associated With Using Synthetic Data

In this unit, we have learned how to generate synthetic data using several different methods.
Before using synthetic data to train a model, however, there are several important things that need to be considered.

## Does the Dataset Adequately Reflect Real World Data?

One challenge is that synthetic data might not adequately represent the complexity
and diversity of the real-world data. It's like trying to paint a picture of a flower garden using only
a few colors – you might capture some aspects, but it won't be as rich as the real thing.

## Is there overfitting?

Overfitting occurs when a machine learning model learns the training data so well that it doesn't perform well on new, unseen data.
It's akin to learning a specific way to solve a math problem but realizing that it doesn't work for all types of problems.
If the process of generating synthetic data is too simple or there are are overly consistent patterns, your model might overfit to the limited variations
present in the synthetic data. As a very simple example, if you trained a model using a synthetic
dataset of 25 red circles and 25 blue squares it will probably learn to associate circles with the color red and squares with the color blue. If you
then trained an shape classifier using this dataset it would likely fail if presented with a red square.

<Tip warning="true">
  Be sure the double check that your dataset doesn't have the following types of
  patterns!
</Tip>

_Overly Consistent Color_
![](URL)

_Overly Consistent Size_
![](URL)

_Overly Consistent Background_
![](URL)

_Overly Consistent Location_
![](URL)

<Tip>
  Try to make sure your dataset reflects the variety found in the real world!
</Tip>

_Nice Variety_
![](URL)

## Are there biases in the synthetic data?

If the process of generating synthetic data has biases or inaccuracies, your model may unintentionally
learn and perpetuate those biases. Beware of the following pitfalls:

_Limited Diversity:_

The circle example might have seemed trivial, but there are lots of real world situations where failing
to account for the wide variety of people, places, animals, or objects will result in a model that doesn't perform well. For
example, suppose you wanted to train a model to monitor the population of an endangered species, such as aye-aye lemurs.  
If your synthetic dataset only contains images of ring-tailed lemurs, the model might struggle to accurately identify aye-aye lemurs in the wild.
This limitation could lead to errors in population assessments.

_Copying Existing Biases:_

If the data you used to create the synthetic images already had biases, your the model might unintentionally
learn and replicate those biases. It's like copying a friend's notes without realizing they made a mistake
– your computer might end up with the same misunderstandings.

## Does the benefits of using synthetic data outweight the computational cost?

Generating high-quality synthetic data can be computationally expensive. This may pose challenges in terms
of both time and resources, especially for complex models or large datasets. As a general rule, generating and using a synthetic data
only makes sense if it ultimately saves resources (money, time, etc.).

## What is the perceived quality of synthetic images?

Let's consider the lung images we generated using DCGAN. While some of the images looked pretty realistic, others were not
so good. A model trained with the low-quality images might fail to detect pneumonia because they contain noise that isn't present in the real images.
Your model might also get really good at recognizing patterns in the synthetic data, but those patterns might not exist
or may be different in the real world. A good practice is to evaluate your dataset using a measure such as Frechet Inception Distance (FID), Inception Score (IS), or the Classification
Accuracy Score (CAS).

_FID:_

FID uses a pre-trained neural network model, often Inception, which is good at recognizing objects in images.
The model is used to extract features from both the real and generated images.
FID calculates the Frechet distance between the feature distributions of real and generated images.
The Frechet distance is a measure of how "far" one distribution is from another,
taking into account both the mean and covariance of the distributions.

A low FID suggests that the feature distributions of real and generated images are similar and the generated images are statistically
close to the real images in terms of features, making them more realistic and harder to distinguish.

FID$$(\mu_1, \Sigma_1, \mu_2, \Sigma_2) = \|\mu_1 - \mu_2\|^2 + \text{Tr}(\Sigma_1 + \Sigma_2 - 2(\Sigma_1^{1/2}\Sigma_2\Sigma_1^{1/2})^{1/2})$$

Here:

- $$\mu_1$$ and $$\mu_2$$ are the mean vectors of the two distributions
- $$\Sigma_1$$ are $$\Sigma_2$$ the covariance matrices of the two distributions
- $$\| * \|$$ denotes the Euclidean or L2 norm
- $$\text{Tr}$$ represents the trace of a matrix
- The notation $$\Sigma^{1/2}$$ denotes the square root of the covariance matrix

_IS:_

IS uses a pre-trained Inception model to evaluate the quality of generated images produced by generative models, particularly GANs.
For each generated image, the Inception model assigns a score based on its confidence in recognizing objects within that image.
High scores indicate that the Inception model is confident and certain about the content of the image. It also takes into account the diversity of the generated images.
It's important to note that the Inception Score has been criticized for not always correlating with human judgment
of image quality. While it provides insights into the performance of a generative model, it might not capture all aspects of visual fidelity and creativity.

_CAS:_

$$\text{Accuracy} = \frac{\text{Correct Predictions}}{\text{Total Predictions}}$$

The primary purpose of creating a synthetic image dataset is likely to train a machine learning model. Classification accuracy provides a straightforward and easily interpretable metric to evaluate how well your model is performing on the synthetic data. Going back to our lemur example,
CAS helps evaluate how well the model is learning from the synthetic dataset, with a higher accuracy indicates that the model is effectively
capturing the features and patterns of lemurs. Low accuracy scores for certain classes may indicate issues with the synthetic data generation process.
This could include problems such as unrealistic backgrounds, incorrect textures, or inconsistent lighting conditions.
By analyzing class-specific accuracy, you can identify and address these issues to improve the overall quality of the synthetic dataset.

## Conclusion

Even after training your model, it's crucial to continuously monitor its performance in real-world scenarios.
If your model encounters new situations or trends that weren't present in the synthetic data, it might struggle to adapt.
Addressing these challenges involves thoughtful design of the synthetic data generation process, careful evaluation
of the model's performance on real data, and ongoing efforts to enhance the model's robustness and fairness.

## Resources and Further Reading

- [Analyzing Effects of Fake Training Data on the Performance of Deep Learning Systems](https://arxiv.org/pdf/2303.01268.pdf)
- [Bridging the Gap: Enhancing the Utility of Synthetic Data Via Post-Processing Techniques](https://arxiv.org/pdf/2305.10118.pdf)
- [CIFAKE: Image Classification and Explanable Identification of AI-Generated Synthetic Images](https://arxiv.org/pdf/2303.14126.pdf)
- [Classification Accuracy Score for Conditional Generative Models](https://arxiv.org/abs/1905.10887)
- [GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium](https://arxiv.org/abs/1706.08500)
- [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498)
  [Metrics](https://github.com/huggingface/community-events/tree/main/huggan/pytorch/metrics)
- [pytorch-fid](https://github.com/mseitzer/pytorch-fid)
