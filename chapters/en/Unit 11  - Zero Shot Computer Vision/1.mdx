# Introduction

Besides fundamentals, this unit assumes familiarity with concepts in transfer and multimodal learning. If you are not viewing the course sequentially in the provided order, we suggest at least reading the transfer learning section in unit 2, and the whole of unit 4.

## On Generalization

We have now trained our model like a student cramming all epochs for a test. Now, the real test begins! We hope this knowledge translates beyond the specific pictures it learned from, allowing it to recognize unseen cats like Alice's and Ted’s furry friends. Think of it as the model learning the essence of catness, not just those specific furry faces it saw during training. This ability to apply knowledge to new situations is called generalization, and it's what separates a good model from a mere cat picture memorizer. Can you imagine an alternate universe without generalization? Yes, it’s pretty simple actually, you’ll only have to train your model on ALL the images of cats in the world (assuming they only exist on earth), including Alice’s and Ted’s.

Actually, I wasn’t totally accurate when I said that the model is expected to generalize to all cat pictures that it has not seen. It is expected to generalize to all cat pictures that come from the same distribution as the image data it was trained on. Simply, if you trained your model on cat selfies and then presented it with a cartoon picture of a cat, it probably won’t be able to recognize it. These two pictures come from totally different distributions or domains. Making your cat selfies model able to recognize cartoon cats is referred to as domain adaptation (we’ll briefly talk about it later). It's like taking all the knowledge your model learned about real cats and teaching it to recognize their animated cousins.

So, we’ve gone from generalization, recognizing the unseen Alice’s and Ted’s cat pictures, to domain adaptation, recognizing animated cat pictures. But we’re much Greedier than that. You don’t want your model to be able to only recognize your cat pictures, or Alice’s and Ted’s, or not even cartoon cat! Having a model trained on cat pictures, you also want it to recognize pictures of llamas and falcons.

Well, now we’re in the turf of Zero-shot Learning. Also known as, ZSL.

[comment]: # (TODO: Illustration showing the difference between generalization, domain adaptation, and ZSL)

## What is Zero-shot Learning?

Let’s warm up with a definition

Zero-shot learning is a setup in which the model is presented with images belonging to **only** classes that it was not exposed to during training, at test time. 

Just a heads-up: in the classic ZSL setup, the test set only has pictures of classes the model hasn't seen before, not a single one from its training days. This may seem a little bit unrealistic, it's  like asking a student to ace an exam on only materials they've never studied. 

Luckily, there's a more pragmatic version of ZSL that doesn't have this strict rule and is called generalized zero-shot learning, or GZSL. This more flexible approach allows the test set to include both seen and unseen classes. It's a more realistic scenario, reflecting how things work in the real world.

[comment]: # (TODO: Illustration showing the difference between ZSL and GZSL)
