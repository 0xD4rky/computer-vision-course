# Ethics and Bias in AI üßë‚Äçü§ù‚Äçüßë

We hope that you found the ImageNet Roulette case study interesting and learned what can go wrong with AI models in general. In this chapter, we will go through yet another example of a powerful technology that has cool applications but can also raise ethical concerns if kept unchecked. Let's first quickly summarize the ImageNet Roulette case study and its after-effects.
1. ImageNet Roulette is a great example of an AI model gone wrong, due to the inherent biases and overlooking the labelling and data pre-processing stages.
2. The experiment was hand-crafted just to demonstrate how things can go wrong if kept unchecked.
3. This led to a great deal of corrections done by the ImageNet team in the dataset as well as take appropriate measures to  mitigate the problems like: face obfuscation, removal of harmful and triggering synsets, removal of corresponding images etc.
4. Finally, it opened up an ongoing discussion, research work and steps that are being taken to mitigate the risks. 

Now let us take a look into another example of a powerful technology but before diving in, let's think on for a while on some questions. Is electricity good or bad? Is internet generally safe or harmful? In general, is technology good or bad? With these questions in mind, let's begin our journey.

## Deepfakes üé•

Imagine, you are a recent fresher who wants to learn about Deep Learning and you enroll to an the Course on Introduction to Deep Learning (MIT 6.S191)by MIT. To make things more interesting the course team released a really cool video on what things can be done using deep learning. Check the video here:

<Youtube id="l82PxsKHxYc"/>
*An introduction to the course MIT 6.S191, where deepfakes were used to give an impression of a welcome by Barack Obama.*

Yup, the introduction session was made in such a way that it puts an impression that the students are being welcomed by none other than Barack Obama himself. Really cool application, a course on deep learning with an introduction curated to showcase one of the usecases of deep generative models. For the first timers, this would be really engaging, making them interested in the technology and everyone would like to try it out. After all you can actually make such videos and images easily within a few minutes using a decent GPU and start posting memes, posts etc surrounding this.
Let's see another example of this technology but with different after effects. Imagine, if we can come up with the same deepfake of an influential political leader or actor during times of elections or wars. The same fake video can be used to spread hatred, misinformation leading to marginalizing different people. Even though the person himself didnot actually spread misinformation, but due to the video there can be massive outrage. This can be horrifying and also the main problem lies in the fact that once the misinformation is spread, even after realizing the video was manipulated the harm is already done and people are divided. So the harm can only be reduced if the manipulated video is not made public in the first place. This makes this technology equally dangerous, so is this technology safe or harmful? Technology itself is never good or bad but the usage (who uses it and for what purpose) can cause good or bad effects.

Deepfakes are synthetic media that are created using the help of deep generative CV models. You can actually manipulate images with a different person's image and also generate videos through it. Audio deepfake is another technology which can complement the CV counterpart by mimicing the exact voice of the subject in consideration. This was just one of the examples how deepfakes can cause havoc, but in reality the implications are far more dangerous as it can have life long impact on the lives of the victims.

## What is Ethics and Bias in AI?

From the previous example, a few aspects of this technology to keep in mind would be:
1. Consent of the subject before using the images/videos to manipulate and form new media.
2. Algorithms that actually facilitate creation of synthetic media which can be used for manipulation.
3. Algorithms that can be used to detect such synthetic media.
4. Awareness about these algorithms and its after effects.

<Tip>
üí°Check out The Consentful Tech Project here: https://www.consentfultech.io/. This project raises awareness, develops strategies and shares skills to help people build and use technology consentfully.
</Tip>

Let us now formalize some definitions on the basis of these examples. So what is Ethics and Bias? Ethics can be defined in simple words as a set of moral principles which help us distinguish between wrong and right. Now, AI Ethics can be defined as the set of values, principles and techniques that employ widely accepted standards of right and wrong to guide moral conduct in the development and use of AI. AI Ethics is a multidisciplinary field that studies how to optimize AI's beneficial impact while reducing risks and adverse outcomes. This field involves a variety of stakeholders:
1. *Researchers, Engineers and Developers:* people incharge of models, algorithms, datasets development and curation.
2. *Government bodies, legal authorities (like lawyers), AI Ethicists:* bodies and people in charge of regulatory aspects of Ethical AI development.
3. *Companies and organizations:* stakeholders that are in the fore front of delivering AI products and services.
4. *Citizens:* people who use AI services and products in their daily lives, and are largely affected by the technology.

Bias in AI refers to the biases in output of the algorithms which might happen due to assumptions during model development or training data. These assumptions stem from the inherent biases that are inside humans who were responsible for the development. As a result AI models and algorithms start reflecting on these biases. These biases can lead to disrupting the ethical development or principles and therefore need attention and ways to mitigate them. We will be covering more about biases, how they creep in different AI models, their types, evaluation and mitigation (with focus on CV models) in detail in the upcoming chapters of the unit. To understand more about Ethics in AI, let us look closely into principles for Ethical AI.

## Ethical AI Principles ü§ó üåé

### Asimov's Three Laws of Robotics ü§ñ 

There have been many historic works that reflect on development of ethics for technology. The earliest work can be traced back to the famous science fiction writer Isaac Asimov. He came up with the three laws of robotics keeping in mind the potential risks of autonomous AI agents. The laws are:
1. A robot may not injure a human being or through inaction allow a human being to come to harm.
2. A robot must obey orders given to it by human beings except where such orders would conflict with the first law.
3. A robot must protect its own existence as long as such protection does not conflict with the first or second law.

### Asilomar AI Principles üßëüèª‚Äç‚öñÔ∏èüßëüèª‚Äçüéìüßëüèª‚Äçüíª

Asimov's laws of robotics were one of the earliest works in ethics for technology. In 2017, a conference was organized at Asilomar Conference Grounds, California. This conference was held to discuss about the impacts of AI on society. The outcome of this conference was the development of guidelines for the responsible development of AI. The guideline has 23 principles which was signed by around 5,000 individuals including 844 AI and robotics researchers. 

![Asilomar AI Principles](https://huggingface.co/datasets/hf-vision/course-assets/blob/main/asilomar-ai.png)
*23 Asilomar AI Principles for Responsible AI Development*

<Tip>
üí°You can check the full list of the 23 Asilomar AI Principles and the signatories here: https://futureoflife.org/open-letter/ai-principles/.
</Tip>

These principles are a guide for ethical development and implementation of AI models in general. Let's now look into a recent work on ethical AI guidelines by UNESCO.

### UNESCO's report: Recommendations on the Ethics of Artificial Intelligence üßëüèº‚Äçü§ù‚Äçüßëüèºüåê

UNESCO came up with a global standard on AI ethics in form of a report named **"Recommendation on the Ethics of Artificial Intelligence"** which was adopted by 193 member countries in November 2021. Previous guidelines on Ethical AI were lacking in terms of actionable policy, but the recent report by UNESCO allows policymakers to translate the core principles into action with respect to different domains like data governance, environment, gender, health etc.
The four core values of the recommendation which lay the foundation for AI systems are:
1. **Human rights and human dignity** Respect, protection and promotion of human rights and fundamental freedoms and human dignity.
2. **Living in Peaceful** just and interconnected societies.
3. **Ensuring diversity and inclusiveness.**
4. **Environment and ecosystem flourishing.**

![AI Policy Areas](https://huggingface.co/datasets/hf-vision/course-assets/blob/main/ai_policy.png)
*11 key policy areas for responsible developments in AI.*

The ten core principles that lay out a human-rights centered approach to Ethics of AI by UNESCO are give below:
**1. Proportionality and Do No Harm:** The use of AI systems must not go beyond what is necessary to achieve a legitimate aim. Risk assessment should be used to prevent harms which may result from such uses. 
**2. Safety and Security:** Unwanted harms (safety risks) as well as vulnerabilities to attack (security risks) should be avoided and addressed by AI actors.
**3. Right to Privacy and Data Protection:** Privacy must be protected and promoted throughout the AI lifecycle. Adequate data protection frameworks should also be established.
**4. Multi-stakeholder and Adaptive Governance & Collaboration:** International law & national sovereignty must be respected in the use of data. Additionally, participation of diverse stakeholders is necessary for inclusive approaches to AI governance.
**5. Responsibility and Accountability:** AI systems should be auditable and traceable. There should be oversight, impact assessment, audit and due diligence mechanisms in place to avoid conflicts with human rights norms and threats to environmental wellbeing.
**6. Transparency and Explainability:** The ethical deployment of AI systems depends on their transparency & explainability (T&E). The level of T&E should be appropriate to the context, as there may be tensions between T&E and other principles such as privacy, safety and security.
**7. Human Oversight and Determination:** Member States should ensure that AI systems do not displace ultimate human responsibility and accountability.
**8. Sustainability:** AI technologies should be assessed against their impacts on "sustainability", understood as a set of constantly evolving goals including those set out in the UN's Sustainable Development Goals.
**9. Awareness & Literacy:** Public understanding of AI and data should be promoted through open & accessible education, civic engagement, digital skills & AI ethics training, media & information literacy.
**10. Fairness and Non-Discrimination:** AI actors should promote social justice, fairness, and non-discrimination while taking an inclusive approach to ensure AI's benefits are accessible to all.

<Tip>
üí°To read the complete report by UNESCO on "Recommendations on the Ethics of Artificial Intelligence", you can go to: https://unesdoc.unesco.org/ark:/48223/pf0000381137
</Tip>

As we close the unit we will also look into Hugging Face's efforts to ensure Ethical AI practises. In the next chapter, we will learn more about biases, types and how they creep in different AI models. 
