# GoogLeNet

### 1. Introduction 

Inception is a convolution neural network (CNN) architecture, used for computer vision classification and detection tasks. It has less than 7 million parameters, which is 9 times smaller than AlexNet, and 22 times smaller than VGG16. In ImageNet 2014 challenge, the authors from Google submitted a version of Inception network callled GoogLeNet (an homage to LeNet), which achieved state-of-the-art results with less parameters than prior best methods.   

### 2. Key Architecture 

Before Inception, successful network architectures such as AlexNet or VGG have shown the importance of increasing network depth. However, increasing network depth also increases computation steps, and problems such as overfitting and vanishing gradient may occur. Inception network introduced a method to efficiently train complex CNNs wih less floating parameters.   

To design a CNN network, one typically selects each layer to be a pooling layer or a convolution layer, including the choice of convolution filter size. Stacking convolution filters of different sizes on top of one another is useful for various tasks, but the total number of parameters can grow very quickly. In Inception networks, convolution filters of different sizes (1X1, 3X3, 5X5) are connected in parallel, and combined with maxpooling into a single module, called the Inception module. GoogLeNet network is constructed by connecting 9 Inception module in series. With this structure, the network can be flexible and learn complex tasks without much incease in depth.  


### 3. Code 

import torch
import torch.nn as nn
import torch.nn.functional as F

class InceptionModule(nn.Module):
    def __init__(self, in_channels, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_proj):
        super(InceptionModule, self).__init__()
        self.b1 = nn.Sequential(
            nn.Conv2d(in_channels, n1x1, kernel_size=1),
            nn.ReLU(True),
        )
        
        self.b2 = nn.Sequential(
            nn.Conv2d(in_channels, n3x3red, kernel_size=1),
            nn.ReLU(True),
            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),
            nn.ReLU(True),
        )

        self.b3 = nn.Sequential(
            nn.Conv2d(in_channels, n5x5red, kernel_size=1),
            nn.ReLU(True),
            nn.Conv2d(n5x5red, n5x5, kernel_size=5, padding=2),
            nn.ReLU(True),
        )

        self.b4 = nn.Sequential(
            nn.MaxPool2d(3, stride=1, padding=1),
            nn.Conv2d(in_channels, pool_proj, kernel_size=1),
            nn.ReLU(True),
        )

    def forward(self, x):
        y1 = self.b1(x)
        y2 = self.b2(x)
        y3 = self.b3(x)
        y4 = self.b4(x)
        return torch.cat([y1, y2, y3, y4], 1)

    
class GoogLeNet(nn.Module):
    def __init__(self):
        super(GoogLeNet, self).__init__()
        self.pre_layers = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(True),
        )
        
        self.inception_blocks = nn.Sequential(
            InceptionModule(64, 16, 32, 32, 16, 8, 8),
            InceptionModule(64, 24, 32, 48, 16, 12, 12),
            nn.MaxPool2d(3, stride=2, padding=1),
            InceptionModule(96, 24, 32, 48, 16, 12, 12),
            InceptionModule(96, 16, 32, 48, 16, 16, 16),
            InceptionModule(96, 16, 32, 48, 16, 16, 16),
            InceptionModule(96, 32, 32, 48, 16, 24, 24),
            nn.MaxPool2d(3, stride=2, padding=1),
            InceptionModule(128, 32, 48, 64, 16, 16, 16),
            InceptionModule(128, 32, 48, 64, 16, 16, 16)
        )
        
        self.output_net = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(128, 100)
        )

    def forward(self, x):
        x = self.pre_layers(x)
        x = self.inception_blocks(x)
        x = self.output_net(x)
        return F.softmax(x, dim=1)