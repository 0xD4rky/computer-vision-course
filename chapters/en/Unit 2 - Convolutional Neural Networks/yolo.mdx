You Only Look Once

<!--  
- [x]  YOLOv2 and YOLOv3
- [x]  YOLOv4, YOLOv5
- [x]  YOLOv6-YOLOv7
- [x]  YOLOv8-YOLOv9
Additional checks:
- [x] Add comment about licences difference between (up to) YOLOv4 and rest
- [ ] Recheck YOLOv4 and YOLOv5
- [ ] Add in the introduction the the evolution of YOLO is not a linear story.
-->

## Evolution of YOLO

So far, we have seen the basic characteristics of YOLO and how it allows it to perform highly accurate and fast predictions. YOLOv1 was released in 2015 and until today multiple versions have been released. YOLOv1 was groundbreaking in terms of accuracy and speed. However, it suffered from poor localization and detection of multiple objects in a small image area.

### **YOLOv2 (2016)** 

After a year of releasing the first version, YOLOv2[1] came out. The improvements focused on both accuracy and speed but also dealt with the localization problem. Many improvements were made (image1). First, YOLOv2 replaced YOLOv1’s backbone architecture with Darknet-19, which is a variant of the Darknet architecture. Darknet-19 is lighter than the previous version’s backbone and it consists of 19 convolutional layers followed by max-pooling layers. This led to YOLOv2 having the ability to capture more information. Also, it included batch normalization to all convolutional layers removed the dropout layers dealing with the overfitting problem, and increased the mAP. It also introduced anchor boxes, which added prior knowledge to the detected width and height of the detected boxes (specifically they used). Additionally, to deal with the poor localization YOLOv2 predicted the class and objects for every anchor box and as previously grid (now 13x13). So we have a maximum (for 5 anchor boxes) of 13x13x5 = 845 boxes.

### **YOLOv3 (2018)**

YOLOv3[2] again improved significantly the detection speed and accuracy by replacing the Darknet-19 architecture with the more complex but efficient Darknet-53. Also, it dealt more with the localization problem by using three different scales for object detection (13x13, 26x26, and 52x52 grids). This helped find objects with different sizes in the same area. This increased the bounding boxes to: 13 x 13 x 3 + 26 x 26 x 3 + 52 x 52 x 3 = 10,647. The Non-Maximum Suppression (NMS) was still used to filter out redundant overlapping boxes.

### **YOLOv4 (2020)**

Back in 2020, YOLOv4[3] became one of the best detection models in terms of speed and accuracy. The authors changed again the backbone architecture to the faster and better accuracy CSPDarknet53[4]. An important improvement of this version was the optimization for efficient resource utilization, making it suitable for deployment on various hardware platforms, including edge devices. Also, It included a number of augmentations before training that further improved the model prediction accuracy on custom data.

### **YOLOv5 (2020)**

YOLOv5[5] translated the Darknet framework (written in C) to the more flexible and ease of use Pytorch framework. This version automated the previous anchor detection mechanism introducing the auto-anchors. Auto-anchors train the model anchors automatically to match your data. During training, YOLO automatically uses k-means initially and genetic methods to evolve the new better-matched anchors and place them back into the YOLO model. Also, it offered different types of models that depend on the hardware constraints with names similar to today’s YOLOv8 models: YOLOv5s, YOLOv5m, YOLOv5l, and YOLOv5x.

### **YOLOv6 (2022)**

The next version, YOLOv6[6][7], was released by the Meituan Vision AI Department under the article title: "YOLOv6: A Single-Stage Object Detection Framework for Industry." This team made further improvements in terms of speed and accuracy by focusing on five aspects:
1) Reparameterization using the RepVGG technique. Which is a modified version of VGG with skip connections. During inference, these connections are fused to improve the speed.
2) Quantization of reparameterization-based detectors. Which added blocks that are called Rep-PANs.
3) Recognition of the importance of considering different hardware costs and capabilities for model deployment.
4) Further verification of label assignment and loss function design after architectural improvements. YOLOv6 uses Varifocal Loss for Classification. For Box Regression, it uses IoU Series Loss and Distribution Focal Loss.
5) Accuracy improvements during training using knowledge distillation.
In 2023, YOLOv6 v3[8] was released with the title: "YOLOv6 v3.0: A Full-Scale Reload," which introduced enhancements to the network architecture and training scheme, once again advancing speed and accuracy (evaluated on the COCO dataset) compared to previously released versions.

### **YOLOv7 (2022)**
YOLOv7 was released with the paper name: “YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors”[9][10] by the authors of YOLOv4. Trainable bag-of-freebies refer to optimization methods that aim to increase the model's accuracy in real-time detection without increasing the inference cost. These methods refer mostly to optimizations in the training process. Specifically, they include a new label assignment method called coarse-to-fine lead guided label assignment and use gradient flow propagation paths to analyze how re-parameterized convolution should be combined with different networks. They also, proposed  “extend” and “compound scaling” methods for the real-time object detector that can effectively utilize parameters and computation. Again, all these improvements took the real-time-object detection to a new state-of-the-art outperforming previous releases.

### **YOLOv8 (2023)**

YOLOv8[11], developed by Ultralytics in 2023 became again the new SOTA. It introduced improvements on the backbone and neck, alongside an anchor-free approach which eliminates the need for predefined anchor boxes. Instead, predictions are made directly. This version supports a wide range of vision tasks including classification, segmentation, and pose estimation. Additionally, YOLOv8 has scaling capabilities with pre-trained models available in various sizes: nano, small, medium, large, and extra-large, and can easily fine-tuned on custom datasets. 

### **YOLOv9 (2024)**

YOLOv9 was released with the paper name: “YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information”[12][13] by a similar team of YOLOv7 and YOLOv4 authors. This paper highlights the issue of information loss that existing methods and architectures have during layer-by-layer feature extraction and spatial transformation. To address this issue, the authors proposed:

* Concept of programmable gradient information (PGI) to cope with the various changes
required by deep networks to achieve multiple objectives.
* Generalized Efficient Layer Aggregation Network (GELAN), a new lightweight network architecture that achieves better parameter utilization than the current methods without sacrificing computational efficiency.

With these changes, YOLOv9 set new benchmarks on the MS COCO.

### **Note about the different versions**


This short chapter presented the history/evolution of YOLO in a linear way. However, this is not the case—many other versions of YOLO were released in parallel. Notice the release of YOLOv4 and YOLOv5 in the same year. Other versions that we did not cover include YOLOvX (2021) which was based on YOLOv3 (2018), YOLOR (2021) which was based on YOLOv4(2020), and many others.
Also, It is important to understand that the selection of the ‘best’ model version depends on the user requirements such as speed, accuracy, hardware limitations, and user-friendliness. For example, YOLOv2 is very good at speed. YOLOv3 provides a balance between accuracy and speed. YOLOv4 has the best ability for adapting/being compatible across different hardware.


References:

[1] [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242)

[2] [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767)

[3] [YOLOv4: Optimal Speed and Accuracy of Object Detection](https://arxiv.org/abs/2004.10934)

[4] [YOLOv4 GitHub repo](https://github.com/AlexeyAB/darknet)

[5] [Ultralytics YOLOv5](https://docs.ultralytics.com/models/yolov5/)

[6] [YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications](https://arxiv.org/abs/2209.02976)

[7] [YOLOv6 GitHub repo](https://github.com/meituan/YOLOv6)

[8] [YOLOv6 v3.0: A Full-Scale Reloading](https://arxiv.org/abs/2301.05586)

[9] [YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors](https://arxiv.org/abs/2207.02696)

[10] [YOLOv7 GitHub repo](https://github.com/WongKinYiu/yolov7)

[11] [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)

[12] [YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information](https://arxiv.org/abs/2402.13616)

[13] [YOLOv9 GitHub repo](https://github.com/WongKinYiu/yolov9)

[14] [YOLOvX](https://yolovx.com/)

[15] [You Only Learn One Representation: Unified Network for Multiple Tasks](https://arxiv.org/abs/2105.04206)

