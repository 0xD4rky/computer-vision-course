# YOLO 

## A short introduction to Object Detection

Convolutional Neural Networks have taken a big step towards the image classifcation problem. But there remains
another big task to solve - object detection. Object detection not only requires to categorize the object from the image but also to accurately predict the location (in this case the co-ordinates of the bounding boxes of the object) from the image. Here came the big breakthrough of YOLO. Before delving into the depth of YOLO, lets get through the history of object detection algorithms using CNN.


### RCNN , Fast RCNN , Faster RCNN

#### RCNN
RCNN is the simplest way possible to use convolutional neural networks for object detection. To be as simple as possible , the basic idea is to 
detect a "region" and then use CNN to classify the region . So this is a multi-step process . Based on this idea the RCNN paper was shared in 2012[1]

The RCNN uses following steps , 

- Use Selective Search algorithm to select a region. 
- Use CNN based classifier to classify an object from the region. 

For training purpose, the paper proposed following steps 

- Make a dataset of regions detected from the Object detection dataset. 
- Fine tune Alexnet model on the regions dataset . 
- Then use the fine tuned model on the object detection dataset . 

The following is a basic pipeline of RCNN 
![rcnn](https://huggingface.co/datasets/hf-vision/course-assets/blob/main/RCNN.png)


#### Fast RCNN 

Fast RCNN is focused on improvisation over the original RCNN. They added these three improvements

- Training in a single-stage instead of multi-stage like RCNN. Uses multi-task loss
- No disk storage required
- Introduces ROI pooling layer to only get the features from the  Region of Interests.
- Trains an end-to-end model in contrary to multi-step RCNN / SPPnet models using multi-task loss.

![fast_rcnn](https://huggingface.co/datasets/hf-vision/course-assets/blob/main/Fast%20R-CNN.png)

#### Faster RCNN 

- It introduces RPN , regional proposal network . The RPN is an attention based model which trains the model to give "attention" to the region of the image containing the object . 
- It merges RPN with Fast RCNN , making it as the End-to-End object detection model. 

![Faster RCNN](https://cdn-uploads.huggingface.co/production/uploads/6141a88b3a0ec78603c9e784/n8eDqnlEvDS5SIKGoSUpz.png)

#### Feature Pyramid Network (FPN)
- Feature Pyramid network is kind of Inception model for Object detection.
- It first downscales the image into lower representations.
- Then it it upscalses them again. From every upscaled images it tries to predict the output (in this case the categories.)
- But there are also skip connections between the similar dimensional features as well! Please refer to the following images which are taken from the paper.[20]

   [FPN](https://huggingface.co/datasets/hf-vision/course-assets/blob/main/FPN.png)
   [FPN2](https://huggingface.co/datasets/hf-vision/course-assets/blob/main/FPN_2.png)

## YOLO architecture

TODO (to be added.)

## Evolution of YOLO

So far, we have seen the basic characteristics of YOLO and how it allows for highly accurate and fast predictions. This was actually the first version of YOLO, called YOLOv1. YOLOv1 was released in 2015, and since then, multiple versions have been released. It was groundbreaking in terms of accuracy and speed since it introduced the concept of using a single convolutional neural network (CNN) that processes the entire image at once, dividing it into an SxS grid. Each grid cell predicts bounding boxes and class probabilities directly. However, it suffered from poor localization and detection of multiple objects in a small image area. In the following years, many new versions were released by different teams to gradually improve the accuracy, speed, and robustness.

### **YOLOv2 (2016)** 

After a year of releasing the first version, YOLOv2[5] came out. The improvements focused on both accuracy and speed but also dealt with the localization problem. First, YOLOv2 replaced YOLOv1’s backbone architecture with Darknet-19, which is a variant of the Darknet architecture. Darknet-19 is lighter than the previous version’s backbone and it consists of 19 convolutional layers followed by max-pooling layers. This led to YOLOv2 having the ability to capture more information. Also, it included batch normalization to all convolutional layers and hence, removed the dropout layers dealing with the overfitting problem increasing the mAP. It also introduced the concept of anchor boxes, which added prior knowledge to the detected width and height of the detected boxes (specifically they used). Additionally, to deal with the poor localization YOLOv2 predicted the class and objects for every anchor box and as previously grid (now 13x13). So we have a maximum (for 5 anchor boxes) of 13x13x5 = 845 boxes.

### **YOLOv3 (2018)**

YOLOv3[6] again improved significantly the detection speed and accuracy by replacing the Darknet-19 architecture with the more complex but efficient Darknet-53. Also, it dealt with the localization problem better by using three different scales for object detection (13x13, 26x26, and 52x52 grids). This helped finding the objects with different sizes in the same area. It increased the bounding boxes to: 13 x 13 x 3 + 26 x 26 x 3 + 52 x 52 x 3 = 10,647. The Non-Maximum Suppression (NMS) was still used to filter out redundant overlapping boxes.

### **YOLOv4 (2020)**

Back in 2020, YOLOv4[7] became one of the best detection models in terms of speed and accuracy achieving state-of-the-art results on object detection benchmarks. The authors changed the backbone architecture again, opting for the faster and more accurate CSPDarknet53[8]. An important improvement of this version was the optimization for efficient resource utilization, making it suitable for deployment on various hardware platforms, including edge devices. Also, It included a number of augmentations before training that further improved the model generalization. The authors include this improvement in a set of methodologies called bag-of-freebies. Bag-of-freebies are optimization methods that have a cost to the training process but aim to increase the model's accuracy in real-time detection without increasing the inference time.

### **YOLOv5 (2020)**

YOLOv5[9] translated the Darknet framework (written in C) to the more flexible and ease of use Pytorch framework. This version automated the previous anchor detection mechanism introducing the auto-anchors. Auto-anchors train the model anchors automatically to match your data. During training, YOLO automatically uses k-means initially and genetic methods to evolve the new better-matched anchors and place them back into the YOLO model. Also, it offered different types of models that depend on the hardware constraints with names similar to today’s YOLOv8 models: YOLOv5s, YOLOv5m, YOLOv5l, and YOLOv5x.

### **YOLOv6 (2022)**

The next version, YOLOv6[10][11], was released by the Meituan Vision AI Department under the article title: "YOLOv6: A Single-Stage Object Detection Framework for Industry." This team made further improvements in terms of speed and accuracy by focusing on five aspects:
1) Reparameterization using the RepVGG technique. Which is a modified version of VGG with skip connections. During inference, these connections are fused to improve the speed.
2) Quantization of reparameterization-based detectors. Which added blocks that are called Rep-PANs.
3) Recognition of the importance of considering different hardware costs and capabilities for model deployment. Specifically, the authors tested the latency with lowpower GPUs (like Tesla T4) compared to the previous works which mostly used high-cost machines (like V100).
4) Introducttion to new types of loss functions such as, Varifocal Loss for Classification. IoU Series Loss  for Boundig Box Regression, and Distribution Focal Loss.
5) Accuracy improvements during training using knowledge distillation.
In 2023, YOLOv6 v3[12] was released with the title: "YOLOv6 v3.0: A Full-Scale Reload," which introduced enhancements to the network architecture and training scheme, once again advancing speed and accuracy (evaluated on the COCO dataset) compared to previously released versions.

### **YOLOv7 (2022)**

YOLOv7 was released with the paper name: “YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors”[13][14] by the authors of YOLOv4.Specifically, this version of bag-of-freebies includes a new label assignment method called coarse-to-fine lead guided label assignment and uses gradient flow propagation paths to analyze how re-parameterized convolution should be combined with different networks. They also, proposed  “extend” and “compound scaling” methods for the real-time object detector that can effectively utilize parameters and computation. Again, all these improvements took the real-time-object detection to a new state-of-the-art outperforming previous releases.

### **YOLOv8 (2023)**

YOLOv8[15], developed by Ultralytics in 2023 became again the new SOTA. It introduced improvements on the backbone and neck, alongside an anchor-free approach which eliminates the need for predefined anchor boxes. Instead, predictions are made directly. This version supports a wide range of vision tasks including classification, segmentation, and pose estimation. Additionally, YOLOv8 has scaling capabilities with pre-trained models available in various sizes: nano, small, medium, large, and extra-large, and can easily fine-tuned on custom datasets. 

### **YOLOv9 (2024)**

YOLOv9 was released with the paper name: “YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information”[16][17] by the same authors of YOLOv7 and YOLOv4 . This paper highlights the issue of information loss that existing methods and architectures have during layer-by-layer feature extraction and spatial transformation. To address this issue, the authors proposed:

* Concept of programmable gradient information (PGI) to cope with the various changes
required by deep networks to achieve multiple objectives.
* Generalized Efficient Layer Aggregation Network (GELAN), a new lightweight network architecture that achieves better parameter utilization than the current methods without sacrificing computational efficiency.

With these changes, YOLOv9 set new benchmarks on the MS COCO challenge

### **Note about the different versions**

This short chapter presented the history/evolution of YOLO in a linear way. However, this is not the case—many other versions of YOLO were released in parallel. Notice the release of YOLOv4 and YOLOv5 in the same year. Other versions that we did not cover include YOLOvX (2021) which was based on YOLOv3 (2018), YOLOR (2021) which was based on YOLOv4(2020), and many others.
Also, It is important to understand that the selection of the ‘best’ model version depends on the user requirements such as speed, accuracy, hardware limitations, and user-friendliness. For example, YOLOv2 is very good at speed. YOLOv3 provides a balance between accuracy and speed. YOLOv4 has the best ability for adapting/being compatible across different hardware.


## Reference 

[1] [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524v5)
[2] [Fast R-CNN](https://arxiv.org/abs/1504.08083)
[3] [Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf)
[4] [Feature Pyramid Network](https://arxiv.org/pdf/1612.03144.pdf)
[5] [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) <br />
[6] [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767) <br />
[7] [YOLOv4: Optimal Speed and Accuracy of Object Detection](https://arxiv.org/abs/2004.10934) <br />
[8] [YOLOv4 GitHub repo](https://github.com/AlexeyAB/darknet) <br />
[9] [Ultralytics YOLOv5](https://docs.ultralytics.com/models/yolov5/) <br />
[10] [YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications](https://arxiv.org/abs/2209.02976) <br />
[11] [YOLOv6 GitHub repo](https://github.com/meituan/YOLOv6) <br />
[12] [YOLOv6 v3.0: A Full-Scale Reloading](https://arxiv.org/abs/2301.05586) <br />
[13] [YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors](https://arxiv.org/abs/2207.02696) <br />
[14] [YOLOv7 GitHub repo](https://github.com/WongKinYiu/yolov7) <br />
[15] [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) <br />
[16] [YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information](https://arxiv.org/abs/2402.13616) <br />
[17] [YOLOv9 GitHub repo](https://github.com/WongKinYiu/yolov9) <br />
[18] [YOLOvX](https://yolovx.com/) <br />
[19] [You Only Learn One Representation: Unified Network for Multiple Tasks](https://arxiv.org/abs/2105.04206)
[20] [Feature Pyramid network Paper](https://arxiv.org/abs/1612.03144)