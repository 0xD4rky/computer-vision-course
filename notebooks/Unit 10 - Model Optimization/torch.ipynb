{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (0.16.2)\n",
      "Requirement already satisfied: filelock in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: numpy in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: requests in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/harzad/anaconda3/envs/model_optimization/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.quantization\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Quantization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mnist dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True,transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False,transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.346256\n",
      "Train Epoch: 1 [32/60000 (0%)]\tLoss: 2.331087\n",
      "Train Epoch: 1 [64/60000 (0%)]\tLoss: 2.174083\n",
      "Train Epoch: 1 [96/60000 (0%)]\tLoss: 1.948799\n",
      "Train Epoch: 1 [128/60000 (0%)]\tLoss: 2.063534\n",
      "Train Epoch: 1 [160/60000 (0%)]\tLoss: 2.173075\n",
      "Train Epoch: 1 [192/60000 (0%)]\tLoss: 1.654042\n",
      "Train Epoch: 1 [224/60000 (0%)]\tLoss: 1.806324\n",
      "Train Epoch: 1 [256/60000 (0%)]\tLoss: 1.894512\n",
      "Train Epoch: 1 [288/60000 (0%)]\tLoss: 1.542542\n",
      "Train Epoch: 1 [320/60000 (1%)]\tLoss: 1.602335\n",
      "Train Epoch: 1 [352/60000 (1%)]\tLoss: 1.444259\n",
      "Train Epoch: 1 [384/60000 (1%)]\tLoss: 1.384955\n",
      "Train Epoch: 1 [416/60000 (1%)]\tLoss: 1.297989\n",
      "Train Epoch: 1 [448/60000 (1%)]\tLoss: 1.231365\n",
      "Train Epoch: 1 [480/60000 (1%)]\tLoss: 1.590174\n",
      "Train Epoch: 1 [512/60000 (1%)]\tLoss: 1.377761\n",
      "Train Epoch: 1 [544/60000 (1%)]\tLoss: 1.096890\n",
      "Train Epoch: 1 [576/60000 (1%)]\tLoss: 1.383488\n",
      "Train Epoch: 1 [608/60000 (1%)]\tLoss: 1.371453\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.349930\n",
      "Train Epoch: 1 [672/60000 (1%)]\tLoss: 0.993799\n",
      "Train Epoch: 1 [704/60000 (1%)]\tLoss: 1.014130\n",
      "Train Epoch: 1 [736/60000 (1%)]\tLoss: 1.006907\n",
      "Train Epoch: 1 [768/60000 (1%)]\tLoss: 0.975760\n",
      "Train Epoch: 1 [800/60000 (1%)]\tLoss: 0.754409\n",
      "Train Epoch: 1 [832/60000 (1%)]\tLoss: 0.960870\n",
      "Train Epoch: 1 [864/60000 (1%)]\tLoss: 0.850877\n",
      "Train Epoch: 1 [896/60000 (1%)]\tLoss: 0.897032\n",
      "Train Epoch: 1 [928/60000 (2%)]\tLoss: 0.892995\n",
      "Train Epoch: 1 [960/60000 (2%)]\tLoss: 0.646346\n",
      "Train Epoch: 1 [992/60000 (2%)]\tLoss: 0.809913\n",
      "Train Epoch: 1 [1024/60000 (2%)]\tLoss: 0.876595\n",
      "Train Epoch: 1 [1056/60000 (2%)]\tLoss: 0.937857\n",
      "Train Epoch: 1 [1088/60000 (2%)]\tLoss: 0.683850\n",
      "Train Epoch: 1 [1120/60000 (2%)]\tLoss: 0.978319\n",
      "Train Epoch: 1 [1152/60000 (2%)]\tLoss: 0.596300\n",
      "Train Epoch: 1 [1184/60000 (2%)]\tLoss: 0.597231\n",
      "Train Epoch: 1 [1216/60000 (2%)]\tLoss: 0.896523\n",
      "Train Epoch: 1 [1248/60000 (2%)]\tLoss: 0.748354\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.558194\n",
      "Train Epoch: 1 [1312/60000 (2%)]\tLoss: 0.614103\n",
      "Train Epoch: 1 [1344/60000 (2%)]\tLoss: 0.787440\n",
      "Train Epoch: 1 [1376/60000 (2%)]\tLoss: 0.625357\n",
      "Train Epoch: 1 [1408/60000 (2%)]\tLoss: 0.559444\n",
      "Train Epoch: 1 [1440/60000 (2%)]\tLoss: 0.431568\n",
      "Train Epoch: 1 [1472/60000 (2%)]\tLoss: 0.481720\n",
      "Train Epoch: 1 [1504/60000 (3%)]\tLoss: 0.756548\n",
      "Train Epoch: 1 [1536/60000 (3%)]\tLoss: 0.482652\n",
      "Train Epoch: 1 [1568/60000 (3%)]\tLoss: 0.546747\n",
      "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 0.638025\n",
      "Train Epoch: 1 [1632/60000 (3%)]\tLoss: 0.386524\n",
      "Train Epoch: 1 [1664/60000 (3%)]\tLoss: 0.458806\n",
      "Train Epoch: 1 [1696/60000 (3%)]\tLoss: 0.278183\n",
      "Train Epoch: 1 [1728/60000 (3%)]\tLoss: 0.361709\n",
      "Train Epoch: 1 [1760/60000 (3%)]\tLoss: 0.415943\n",
      "Train Epoch: 1 [1792/60000 (3%)]\tLoss: 0.437973\n",
      "Train Epoch: 1 [1824/60000 (3%)]\tLoss: 0.423992\n",
      "Train Epoch: 1 [1856/60000 (3%)]\tLoss: 0.366520\n",
      "Train Epoch: 1 [1888/60000 (3%)]\tLoss: 0.408888\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.418661\n",
      "Train Epoch: 1 [1952/60000 (3%)]\tLoss: 0.491483\n",
      "Train Epoch: 1 [1984/60000 (3%)]\tLoss: 0.464424\n",
      "Train Epoch: 1 [2016/60000 (3%)]\tLoss: 0.666677\n",
      "Train Epoch: 1 [2048/60000 (3%)]\tLoss: 0.435101\n",
      "Train Epoch: 1 [2080/60000 (3%)]\tLoss: 0.426774\n",
      "Train Epoch: 1 [2112/60000 (4%)]\tLoss: 0.330518\n",
      "Train Epoch: 1 [2144/60000 (4%)]\tLoss: 0.166959\n",
      "Train Epoch: 1 [2176/60000 (4%)]\tLoss: 0.390640\n",
      "Train Epoch: 1 [2208/60000 (4%)]\tLoss: 0.310279\n",
      "Train Epoch: 1 [2240/60000 (4%)]\tLoss: 0.210160\n",
      "Train Epoch: 1 [2272/60000 (4%)]\tLoss: 0.388529\n",
      "Train Epoch: 1 [2304/60000 (4%)]\tLoss: 0.342879\n",
      "Train Epoch: 1 [2336/60000 (4%)]\tLoss: 0.312764\n",
      "Train Epoch: 1 [2368/60000 (4%)]\tLoss: 0.397804\n",
      "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 0.646952\n",
      "Train Epoch: 1 [2432/60000 (4%)]\tLoss: 0.410489\n",
      "Train Epoch: 1 [2464/60000 (4%)]\tLoss: 0.302323\n",
      "Train Epoch: 1 [2496/60000 (4%)]\tLoss: 0.165979\n",
      "Train Epoch: 1 [2528/60000 (4%)]\tLoss: 0.390041\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.270950\n",
      "Train Epoch: 1 [2592/60000 (4%)]\tLoss: 0.344847\n",
      "Train Epoch: 1 [2624/60000 (4%)]\tLoss: 0.450969\n",
      "Train Epoch: 1 [2656/60000 (4%)]\tLoss: 0.579736\n",
      "Train Epoch: 1 [2688/60000 (4%)]\tLoss: 0.392539\n",
      "Train Epoch: 1 [2720/60000 (5%)]\tLoss: 0.458225\n",
      "Train Epoch: 1 [2752/60000 (5%)]\tLoss: 0.395921\n",
      "Train Epoch: 1 [2784/60000 (5%)]\tLoss: 0.448781\n",
      "Train Epoch: 1 [2816/60000 (5%)]\tLoss: 0.392996\n",
      "Train Epoch: 1 [2848/60000 (5%)]\tLoss: 0.171734\n",
      "Train Epoch: 1 [2880/60000 (5%)]\tLoss: 0.489303\n",
      "Train Epoch: 1 [2912/60000 (5%)]\tLoss: 0.357361\n",
      "Train Epoch: 1 [2944/60000 (5%)]\tLoss: 0.263907\n",
      "Train Epoch: 1 [2976/60000 (5%)]\tLoss: 0.301101\n",
      "Train Epoch: 1 [3008/60000 (5%)]\tLoss: 0.420733\n",
      "Train Epoch: 1 [3040/60000 (5%)]\tLoss: 0.554718\n",
      "Train Epoch: 1 [3072/60000 (5%)]\tLoss: 0.304591\n",
      "Train Epoch: 1 [3104/60000 (5%)]\tLoss: 0.323603\n",
      "Train Epoch: 1 [3136/60000 (5%)]\tLoss: 0.251102\n",
      "Train Epoch: 1 [3168/60000 (5%)]\tLoss: 0.203985\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.356256\n",
      "Train Epoch: 1 [3232/60000 (5%)]\tLoss: 0.171487\n",
      "Train Epoch: 1 [3264/60000 (5%)]\tLoss: 0.487273\n",
      "Train Epoch: 1 [3296/60000 (5%)]\tLoss: 0.252258\n",
      "Train Epoch: 1 [3328/60000 (6%)]\tLoss: 0.243506\n",
      "Train Epoch: 1 [3360/60000 (6%)]\tLoss: 0.375911\n",
      "Train Epoch: 1 [3392/60000 (6%)]\tLoss: 0.411528\n",
      "Train Epoch: 1 [3424/60000 (6%)]\tLoss: 0.229366\n",
      "Train Epoch: 1 [3456/60000 (6%)]\tLoss: 0.338543\n",
      "Train Epoch: 1 [3488/60000 (6%)]\tLoss: 0.366059\n",
      "Train Epoch: 1 [3520/60000 (6%)]\tLoss: 0.478419\n",
      "Train Epoch: 1 [3552/60000 (6%)]\tLoss: 0.250686\n",
      "Train Epoch: 1 [3584/60000 (6%)]\tLoss: 0.138227\n",
      "Train Epoch: 1 [3616/60000 (6%)]\tLoss: 0.232841\n",
      "Train Epoch: 1 [3648/60000 (6%)]\tLoss: 0.456436\n",
      "Train Epoch: 1 [3680/60000 (6%)]\tLoss: 0.259901\n",
      "Train Epoch: 1 [3712/60000 (6%)]\tLoss: 0.513505\n",
      "Train Epoch: 1 [3744/60000 (6%)]\tLoss: 0.336916\n",
      "Train Epoch: 1 [3776/60000 (6%)]\tLoss: 0.348532\n",
      "Train Epoch: 1 [3808/60000 (6%)]\tLoss: 0.389601\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.198786\n",
      "Train Epoch: 1 [3872/60000 (6%)]\tLoss: 0.235061\n",
      "Train Epoch: 1 [3904/60000 (7%)]\tLoss: 0.169272\n",
      "Train Epoch: 1 [3936/60000 (7%)]\tLoss: 0.285325\n",
      "Train Epoch: 1 [3968/60000 (7%)]\tLoss: 0.324133\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.320739\n",
      "Train Epoch: 1 [4032/60000 (7%)]\tLoss: 0.347349\n",
      "Train Epoch: 1 [4064/60000 (7%)]\tLoss: 0.443024\n",
      "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 0.220431\n",
      "Train Epoch: 1 [4128/60000 (7%)]\tLoss: 0.472125\n",
      "Train Epoch: 1 [4160/60000 (7%)]\tLoss: 0.372957\n",
      "Train Epoch: 1 [4192/60000 (7%)]\tLoss: 0.256389\n",
      "Train Epoch: 1 [4224/60000 (7%)]\tLoss: 0.259363\n",
      "Train Epoch: 1 [4256/60000 (7%)]\tLoss: 0.483067\n",
      "Train Epoch: 1 [4288/60000 (7%)]\tLoss: 0.192154\n",
      "Train Epoch: 1 [4320/60000 (7%)]\tLoss: 0.353783\n",
      "Train Epoch: 1 [4352/60000 (7%)]\tLoss: 0.268456\n",
      "Train Epoch: 1 [4384/60000 (7%)]\tLoss: 0.287860\n",
      "Train Epoch: 1 [4416/60000 (7%)]\tLoss: 0.147188\n",
      "Train Epoch: 1 [4448/60000 (7%)]\tLoss: 0.440984\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.441488\n",
      "Train Epoch: 1 [4512/60000 (8%)]\tLoss: 0.111210\n",
      "Train Epoch: 1 [4544/60000 (8%)]\tLoss: 0.108534\n",
      "Train Epoch: 1 [4576/60000 (8%)]\tLoss: 0.193272\n",
      "Train Epoch: 1 [4608/60000 (8%)]\tLoss: 0.441981\n",
      "Train Epoch: 1 [4640/60000 (8%)]\tLoss: 0.422031\n",
      "Train Epoch: 1 [4672/60000 (8%)]\tLoss: 0.335772\n",
      "Train Epoch: 1 [4704/60000 (8%)]\tLoss: 0.204449\n",
      "Train Epoch: 1 [4736/60000 (8%)]\tLoss: 0.374393\n",
      "Train Epoch: 1 [4768/60000 (8%)]\tLoss: 0.284151\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.316435\n",
      "Train Epoch: 1 [4832/60000 (8%)]\tLoss: 0.229429\n",
      "Train Epoch: 1 [4864/60000 (8%)]\tLoss: 0.166115\n",
      "Train Epoch: 1 [4896/60000 (8%)]\tLoss: 0.203459\n",
      "Train Epoch: 1 [4928/60000 (8%)]\tLoss: 0.457701\n",
      "Train Epoch: 1 [4960/60000 (8%)]\tLoss: 0.360119\n",
      "Train Epoch: 1 [4992/60000 (8%)]\tLoss: 0.299880\n",
      "Train Epoch: 1 [5024/60000 (8%)]\tLoss: 0.219143\n",
      "Train Epoch: 1 [5056/60000 (8%)]\tLoss: 0.383313\n",
      "Train Epoch: 1 [5088/60000 (8%)]\tLoss: 0.287368\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.410123\n",
      "Train Epoch: 1 [5152/60000 (9%)]\tLoss: 0.617788\n",
      "Train Epoch: 1 [5184/60000 (9%)]\tLoss: 0.183660\n",
      "Train Epoch: 1 [5216/60000 (9%)]\tLoss: 0.147355\n",
      "Train Epoch: 1 [5248/60000 (9%)]\tLoss: 0.154925\n",
      "Train Epoch: 1 [5280/60000 (9%)]\tLoss: 0.392301\n",
      "Train Epoch: 1 [5312/60000 (9%)]\tLoss: 0.390693\n",
      "Train Epoch: 1 [5344/60000 (9%)]\tLoss: 0.319811\n",
      "Train Epoch: 1 [5376/60000 (9%)]\tLoss: 0.309037\n",
      "Train Epoch: 1 [5408/60000 (9%)]\tLoss: 0.171285\n",
      "Train Epoch: 1 [5440/60000 (9%)]\tLoss: 0.128131\n",
      "Train Epoch: 1 [5472/60000 (9%)]\tLoss: 0.126053\n",
      "Train Epoch: 1 [5504/60000 (9%)]\tLoss: 0.133375\n",
      "Train Epoch: 1 [5536/60000 (9%)]\tLoss: 0.632367\n",
      "Train Epoch: 1 [5568/60000 (9%)]\tLoss: 0.141046\n",
      "Train Epoch: 1 [5600/60000 (9%)]\tLoss: 0.325819\n",
      "Train Epoch: 1 [5632/60000 (9%)]\tLoss: 0.263332\n",
      "Train Epoch: 1 [5664/60000 (9%)]\tLoss: 0.244227\n",
      "Train Epoch: 1 [5696/60000 (9%)]\tLoss: 0.364209\n",
      "Train Epoch: 1 [5728/60000 (10%)]\tLoss: 0.288028\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.196300\n",
      "Train Epoch: 1 [5792/60000 (10%)]\tLoss: 0.216705\n",
      "Train Epoch: 1 [5824/60000 (10%)]\tLoss: 0.442648\n",
      "Train Epoch: 1 [5856/60000 (10%)]\tLoss: 0.201810\n",
      "Train Epoch: 1 [5888/60000 (10%)]\tLoss: 0.276290\n",
      "Train Epoch: 1 [5920/60000 (10%)]\tLoss: 0.230428\n",
      "Train Epoch: 1 [5952/60000 (10%)]\tLoss: 0.283447\n",
      "Train Epoch: 1 [5984/60000 (10%)]\tLoss: 0.067494\n",
      "Train Epoch: 1 [6016/60000 (10%)]\tLoss: 0.162711\n",
      "Train Epoch: 1 [6048/60000 (10%)]\tLoss: 0.220211\n",
      "Train Epoch: 1 [6080/60000 (10%)]\tLoss: 0.321409\n",
      "Train Epoch: 1 [6112/60000 (10%)]\tLoss: 0.201138\n",
      "Train Epoch: 1 [6144/60000 (10%)]\tLoss: 0.139298\n",
      "Train Epoch: 1 [6176/60000 (10%)]\tLoss: 0.101388\n",
      "Train Epoch: 1 [6208/60000 (10%)]\tLoss: 0.131592\n",
      "Train Epoch: 1 [6240/60000 (10%)]\tLoss: 0.323048\n",
      "Train Epoch: 1 [6272/60000 (10%)]\tLoss: 0.285610\n",
      "Train Epoch: 1 [6304/60000 (11%)]\tLoss: 0.206425\n",
      "Train Epoch: 1 [6336/60000 (11%)]\tLoss: 0.193765\n",
      "Train Epoch: 1 [6368/60000 (11%)]\tLoss: 0.154181\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.338490\n",
      "Train Epoch: 1 [6432/60000 (11%)]\tLoss: 0.177821\n",
      "Train Epoch: 1 [6464/60000 (11%)]\tLoss: 0.498596\n",
      "Train Epoch: 1 [6496/60000 (11%)]\tLoss: 0.267111\n",
      "Train Epoch: 1 [6528/60000 (11%)]\tLoss: 0.177682\n",
      "Train Epoch: 1 [6560/60000 (11%)]\tLoss: 0.159842\n",
      "Train Epoch: 1 [6592/60000 (11%)]\tLoss: 0.172866\n",
      "Train Epoch: 1 [6624/60000 (11%)]\tLoss: 0.212170\n",
      "Train Epoch: 1 [6656/60000 (11%)]\tLoss: 0.379152\n",
      "Train Epoch: 1 [6688/60000 (11%)]\tLoss: 0.151072\n",
      "Train Epoch: 1 [6720/60000 (11%)]\tLoss: 0.148962\n",
      "Train Epoch: 1 [6752/60000 (11%)]\tLoss: 0.136867\n",
      "Train Epoch: 1 [6784/60000 (11%)]\tLoss: 0.340938\n",
      "Train Epoch: 1 [6816/60000 (11%)]\tLoss: 0.428050\n",
      "Train Epoch: 1 [6848/60000 (11%)]\tLoss: 0.455170\n",
      "Train Epoch: 1 [6880/60000 (11%)]\tLoss: 0.381663\n",
      "Train Epoch: 1 [6912/60000 (12%)]\tLoss: 0.409907\n",
      "Train Epoch: 1 [6944/60000 (12%)]\tLoss: 0.310509\n",
      "Train Epoch: 1 [6976/60000 (12%)]\tLoss: 0.257950\n",
      "Train Epoch: 1 [7008/60000 (12%)]\tLoss: 0.670830\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.212460\n",
      "Train Epoch: 1 [7072/60000 (12%)]\tLoss: 0.151595\n",
      "Train Epoch: 1 [7104/60000 (12%)]\tLoss: 0.102530\n",
      "Train Epoch: 1 [7136/60000 (12%)]\tLoss: 0.520643\n",
      "Train Epoch: 1 [7168/60000 (12%)]\tLoss: 0.238577\n",
      "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 0.403430\n",
      "Train Epoch: 1 [7232/60000 (12%)]\tLoss: 0.494664\n",
      "Train Epoch: 1 [7264/60000 (12%)]\tLoss: 0.417177\n",
      "Train Epoch: 1 [7296/60000 (12%)]\tLoss: 0.255429\n",
      "Train Epoch: 1 [7328/60000 (12%)]\tLoss: 0.414487\n",
      "Train Epoch: 1 [7360/60000 (12%)]\tLoss: 0.290761\n",
      "Train Epoch: 1 [7392/60000 (12%)]\tLoss: 0.077483\n",
      "Train Epoch: 1 [7424/60000 (12%)]\tLoss: 0.204081\n",
      "Train Epoch: 1 [7456/60000 (12%)]\tLoss: 0.139702\n",
      "Train Epoch: 1 [7488/60000 (12%)]\tLoss: 0.213316\n",
      "Train Epoch: 1 [7520/60000 (13%)]\tLoss: 0.368638\n",
      "Train Epoch: 1 [7552/60000 (13%)]\tLoss: 0.057884\n",
      "Train Epoch: 1 [7584/60000 (13%)]\tLoss: 0.391995\n",
      "Train Epoch: 1 [7616/60000 (13%)]\tLoss: 0.333368\n",
      "Train Epoch: 1 [7648/60000 (13%)]\tLoss: 0.218854\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.112933\n",
      "Train Epoch: 1 [7712/60000 (13%)]\tLoss: 0.256393\n",
      "Train Epoch: 1 [7744/60000 (13%)]\tLoss: 0.235119\n",
      "Train Epoch: 1 [7776/60000 (13%)]\tLoss: 0.196471\n",
      "Train Epoch: 1 [7808/60000 (13%)]\tLoss: 0.320860\n",
      "Train Epoch: 1 [7840/60000 (13%)]\tLoss: 0.323197\n",
      "Train Epoch: 1 [7872/60000 (13%)]\tLoss: 0.560796\n",
      "Train Epoch: 1 [7904/60000 (13%)]\tLoss: 0.216725\n",
      "Train Epoch: 1 [7936/60000 (13%)]\tLoss: 0.225883\n",
      "Train Epoch: 1 [7968/60000 (13%)]\tLoss: 0.320717\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.262589\n",
      "Train Epoch: 1 [8032/60000 (13%)]\tLoss: 0.103104\n",
      "Train Epoch: 1 [8064/60000 (13%)]\tLoss: 0.125729\n",
      "Train Epoch: 1 [8096/60000 (13%)]\tLoss: 0.723657\n",
      "Train Epoch: 1 [8128/60000 (14%)]\tLoss: 0.239969\n",
      "Train Epoch: 1 [8160/60000 (14%)]\tLoss: 0.168736\n",
      "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 0.713056\n",
      "Train Epoch: 1 [8224/60000 (14%)]\tLoss: 0.397501\n",
      "Train Epoch: 1 [8256/60000 (14%)]\tLoss: 0.208228\n",
      "Train Epoch: 1 [8288/60000 (14%)]\tLoss: 0.348597\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.155861\n",
      "Train Epoch: 1 [8352/60000 (14%)]\tLoss: 0.071796\n",
      "Train Epoch: 1 [8384/60000 (14%)]\tLoss: 0.181074\n",
      "Train Epoch: 1 [8416/60000 (14%)]\tLoss: 0.367553\n",
      "Train Epoch: 1 [8448/60000 (14%)]\tLoss: 0.499697\n",
      "Train Epoch: 1 [8480/60000 (14%)]\tLoss: 0.319053\n",
      "Train Epoch: 1 [8512/60000 (14%)]\tLoss: 0.151199\n",
      "Train Epoch: 1 [8544/60000 (14%)]\tLoss: 0.252690\n",
      "Train Epoch: 1 [8576/60000 (14%)]\tLoss: 0.146737\n",
      "Train Epoch: 1 [8608/60000 (14%)]\tLoss: 0.258544\n",
      "Train Epoch: 1 [8640/60000 (14%)]\tLoss: 0.371913\n",
      "Train Epoch: 1 [8672/60000 (14%)]\tLoss: 0.735075\n",
      "Train Epoch: 1 [8704/60000 (15%)]\tLoss: 1.129848\n",
      "Train Epoch: 1 [8736/60000 (15%)]\tLoss: 0.194814\n",
      "Train Epoch: 1 [8768/60000 (15%)]\tLoss: 0.461548\n",
      "Train Epoch: 1 [8800/60000 (15%)]\tLoss: 0.229894\n",
      "Train Epoch: 1 [8832/60000 (15%)]\tLoss: 0.440594\n",
      "Train Epoch: 1 [8864/60000 (15%)]\tLoss: 0.427996\n",
      "Train Epoch: 1 [8896/60000 (15%)]\tLoss: 0.619543\n",
      "Train Epoch: 1 [8928/60000 (15%)]\tLoss: 0.144996\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.342254\n",
      "Train Epoch: 1 [8992/60000 (15%)]\tLoss: 0.397677\n",
      "Train Epoch: 1 [9024/60000 (15%)]\tLoss: 0.102071\n",
      "Train Epoch: 1 [9056/60000 (15%)]\tLoss: 0.233955\n",
      "Train Epoch: 1 [9088/60000 (15%)]\tLoss: 0.661057\n",
      "Train Epoch: 1 [9120/60000 (15%)]\tLoss: 0.285294\n",
      "Train Epoch: 1 [9152/60000 (15%)]\tLoss: 0.241642\n",
      "Train Epoch: 1 [9184/60000 (15%)]\tLoss: 0.111815\n",
      "Train Epoch: 1 [9216/60000 (15%)]\tLoss: 0.346277\n",
      "Train Epoch: 1 [9248/60000 (15%)]\tLoss: 0.335700\n",
      "Train Epoch: 1 [9280/60000 (15%)]\tLoss: 0.258010\n",
      "Train Epoch: 1 [9312/60000 (16%)]\tLoss: 0.266887\n",
      "Train Epoch: 1 [9344/60000 (16%)]\tLoss: 0.183613\n",
      "Train Epoch: 1 [9376/60000 (16%)]\tLoss: 0.471634\n",
      "Train Epoch: 1 [9408/60000 (16%)]\tLoss: 0.632904\n",
      "Train Epoch: 1 [9440/60000 (16%)]\tLoss: 0.303989\n",
      "Train Epoch: 1 [9472/60000 (16%)]\tLoss: 0.277798\n",
      "Train Epoch: 1 [9504/60000 (16%)]\tLoss: 0.204382\n",
      "Train Epoch: 1 [9536/60000 (16%)]\tLoss: 0.390503\n",
      "Train Epoch: 1 [9568/60000 (16%)]\tLoss: 0.333328\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.160968\n",
      "Train Epoch: 1 [9632/60000 (16%)]\tLoss: 0.328638\n",
      "Train Epoch: 1 [9664/60000 (16%)]\tLoss: 0.202441\n",
      "Train Epoch: 1 [9696/60000 (16%)]\tLoss: 0.060341\n",
      "Train Epoch: 1 [9728/60000 (16%)]\tLoss: 0.235122\n",
      "Train Epoch: 1 [9760/60000 (16%)]\tLoss: 0.560316\n",
      "Train Epoch: 1 [9792/60000 (16%)]\tLoss: 0.163284\n",
      "Train Epoch: 1 [9824/60000 (16%)]\tLoss: 0.068286\n",
      "Train Epoch: 1 [9856/60000 (16%)]\tLoss: 0.286809\n",
      "Train Epoch: 1 [9888/60000 (16%)]\tLoss: 0.066281\n",
      "Train Epoch: 1 [9920/60000 (17%)]\tLoss: 0.162699\n",
      "Train Epoch: 1 [9952/60000 (17%)]\tLoss: 0.200266\n",
      "Train Epoch: 1 [9984/60000 (17%)]\tLoss: 0.089753\n",
      "Train Epoch: 1 [10016/60000 (17%)]\tLoss: 0.324858\n",
      "Train Epoch: 1 [10048/60000 (17%)]\tLoss: 0.163025\n",
      "Train Epoch: 1 [10080/60000 (17%)]\tLoss: 0.140710\n",
      "Train Epoch: 1 [10112/60000 (17%)]\tLoss: 0.238174\n",
      "Train Epoch: 1 [10144/60000 (17%)]\tLoss: 0.229056\n",
      "Train Epoch: 1 [10176/60000 (17%)]\tLoss: 0.347908\n",
      "Train Epoch: 1 [10208/60000 (17%)]\tLoss: 0.224426\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.310529\n",
      "Train Epoch: 1 [10272/60000 (17%)]\tLoss: 0.183733\n",
      "Train Epoch: 1 [10304/60000 (17%)]\tLoss: 0.177721\n",
      "Train Epoch: 1 [10336/60000 (17%)]\tLoss: 0.122439\n",
      "Train Epoch: 1 [10368/60000 (17%)]\tLoss: 0.055874\n",
      "Train Epoch: 1 [10400/60000 (17%)]\tLoss: 0.130902\n",
      "Train Epoch: 1 [10432/60000 (17%)]\tLoss: 0.284436\n",
      "Train Epoch: 1 [10464/60000 (17%)]\tLoss: 0.171999\n",
      "Train Epoch: 1 [10496/60000 (17%)]\tLoss: 0.228351\n",
      "Train Epoch: 1 [10528/60000 (18%)]\tLoss: 0.031626\n",
      "Train Epoch: 1 [10560/60000 (18%)]\tLoss: 0.134563\n",
      "Train Epoch: 1 [10592/60000 (18%)]\tLoss: 0.128040\n",
      "Train Epoch: 1 [10624/60000 (18%)]\tLoss: 0.248690\n",
      "Train Epoch: 1 [10656/60000 (18%)]\tLoss: 0.151402\n",
      "Train Epoch: 1 [10688/60000 (18%)]\tLoss: 0.148147\n",
      "Train Epoch: 1 [10720/60000 (18%)]\tLoss: 0.317443\n",
      "Train Epoch: 1 [10752/60000 (18%)]\tLoss: 0.298186\n",
      "Train Epoch: 1 [10784/60000 (18%)]\tLoss: 0.143754\n",
      "Train Epoch: 1 [10816/60000 (18%)]\tLoss: 0.090224\n",
      "Train Epoch: 1 [10848/60000 (18%)]\tLoss: 0.278227\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.193497\n",
      "Train Epoch: 1 [10912/60000 (18%)]\tLoss: 0.177891\n",
      "Train Epoch: 1 [10944/60000 (18%)]\tLoss: 0.112610\n",
      "Train Epoch: 1 [10976/60000 (18%)]\tLoss: 0.425993\n",
      "Train Epoch: 1 [11008/60000 (18%)]\tLoss: 0.386407\n",
      "Train Epoch: 1 [11040/60000 (18%)]\tLoss: 0.070033\n",
      "Train Epoch: 1 [11072/60000 (18%)]\tLoss: 0.182691\n",
      "Train Epoch: 1 [11104/60000 (19%)]\tLoss: 0.229346\n",
      "Train Epoch: 1 [11136/60000 (19%)]\tLoss: 0.165153\n",
      "Train Epoch: 1 [11168/60000 (19%)]\tLoss: 0.097419\n",
      "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.363955\n",
      "Train Epoch: 1 [11232/60000 (19%)]\tLoss: 0.180236\n",
      "Train Epoch: 1 [11264/60000 (19%)]\tLoss: 0.099471\n",
      "Train Epoch: 1 [11296/60000 (19%)]\tLoss: 0.089859\n",
      "Train Epoch: 1 [11328/60000 (19%)]\tLoss: 0.063520\n",
      "Train Epoch: 1 [11360/60000 (19%)]\tLoss: 0.310154\n",
      "Train Epoch: 1 [11392/60000 (19%)]\tLoss: 0.075821\n",
      "Train Epoch: 1 [11424/60000 (19%)]\tLoss: 0.195843\n",
      "Train Epoch: 1 [11456/60000 (19%)]\tLoss: 0.248759\n",
      "Train Epoch: 1 [11488/60000 (19%)]\tLoss: 0.300438\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.298174\n",
      "Train Epoch: 1 [11552/60000 (19%)]\tLoss: 0.592442\n",
      "Train Epoch: 1 [11584/60000 (19%)]\tLoss: 0.313130\n",
      "Train Epoch: 1 [11616/60000 (19%)]\tLoss: 0.354867\n",
      "Train Epoch: 1 [11648/60000 (19%)]\tLoss: 0.226665\n",
      "Train Epoch: 1 [11680/60000 (19%)]\tLoss: 0.574202\n",
      "Train Epoch: 1 [11712/60000 (20%)]\tLoss: 0.214067\n",
      "Train Epoch: 1 [11744/60000 (20%)]\tLoss: 0.286726\n",
      "Train Epoch: 1 [11776/60000 (20%)]\tLoss: 0.119708\n",
      "Train Epoch: 1 [11808/60000 (20%)]\tLoss: 0.123618\n",
      "Train Epoch: 1 [11840/60000 (20%)]\tLoss: 0.337016\n",
      "Train Epoch: 1 [11872/60000 (20%)]\tLoss: 0.224035\n",
      "Train Epoch: 1 [11904/60000 (20%)]\tLoss: 0.097942\n",
      "Train Epoch: 1 [11936/60000 (20%)]\tLoss: 0.230877\n",
      "Train Epoch: 1 [11968/60000 (20%)]\tLoss: 0.230182\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.120074\n",
      "Train Epoch: 1 [12032/60000 (20%)]\tLoss: 0.319893\n",
      "Train Epoch: 1 [12064/60000 (20%)]\tLoss: 0.311746\n",
      "Train Epoch: 1 [12096/60000 (20%)]\tLoss: 0.168864\n",
      "Train Epoch: 1 [12128/60000 (20%)]\tLoss: 0.089680\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.150638\n",
      "Train Epoch: 1 [12192/60000 (20%)]\tLoss: 0.324290\n",
      "Train Epoch: 1 [12224/60000 (20%)]\tLoss: 0.125432\n",
      "Train Epoch: 1 [12256/60000 (20%)]\tLoss: 0.307580\n",
      "Train Epoch: 1 [12288/60000 (20%)]\tLoss: 0.268564\n",
      "Train Epoch: 1 [12320/60000 (21%)]\tLoss: 0.142333\n",
      "Train Epoch: 1 [12352/60000 (21%)]\tLoss: 0.389185\n",
      "Train Epoch: 1 [12384/60000 (21%)]\tLoss: 0.106921\n",
      "Train Epoch: 1 [12416/60000 (21%)]\tLoss: 0.218410\n",
      "Train Epoch: 1 [12448/60000 (21%)]\tLoss: 0.216529\n",
      "Train Epoch: 1 [12480/60000 (21%)]\tLoss: 0.443454\n",
      "Train Epoch: 1 [12512/60000 (21%)]\tLoss: 0.185479\n",
      "Train Epoch: 1 [12544/60000 (21%)]\tLoss: 0.370813\n",
      "Train Epoch: 1 [12576/60000 (21%)]\tLoss: 0.583191\n",
      "Train Epoch: 1 [12608/60000 (21%)]\tLoss: 0.382403\n",
      "Train Epoch: 1 [12640/60000 (21%)]\tLoss: 0.483329\n",
      "Train Epoch: 1 [12672/60000 (21%)]\tLoss: 0.519045\n",
      "Train Epoch: 1 [12704/60000 (21%)]\tLoss: 0.135147\n",
      "Train Epoch: 1 [12736/60000 (21%)]\tLoss: 0.235943\n",
      "Train Epoch: 1 [12768/60000 (21%)]\tLoss: 0.290633\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.140076\n",
      "Train Epoch: 1 [12832/60000 (21%)]\tLoss: 0.236429\n",
      "Train Epoch: 1 [12864/60000 (21%)]\tLoss: 0.144725\n",
      "Train Epoch: 1 [12896/60000 (21%)]\tLoss: 0.194201\n",
      "Train Epoch: 1 [12928/60000 (22%)]\tLoss: 0.308149\n",
      "Train Epoch: 1 [12960/60000 (22%)]\tLoss: 0.287335\n",
      "Train Epoch: 1 [12992/60000 (22%)]\tLoss: 0.309937\n",
      "Train Epoch: 1 [13024/60000 (22%)]\tLoss: 0.314965\n",
      "Train Epoch: 1 [13056/60000 (22%)]\tLoss: 0.424676\n",
      "Train Epoch: 1 [13088/60000 (22%)]\tLoss: 0.114910\n",
      "Train Epoch: 1 [13120/60000 (22%)]\tLoss: 0.580898\n",
      "Train Epoch: 1 [13152/60000 (22%)]\tLoss: 0.080285\n",
      "Train Epoch: 1 [13184/60000 (22%)]\tLoss: 0.266714\n",
      "Train Epoch: 1 [13216/60000 (22%)]\tLoss: 0.042787\n",
      "Train Epoch: 1 [13248/60000 (22%)]\tLoss: 0.238133\n",
      "Train Epoch: 1 [13280/60000 (22%)]\tLoss: 0.164088\n",
      "Train Epoch: 1 [13312/60000 (22%)]\tLoss: 0.216557\n",
      "Train Epoch: 1 [13344/60000 (22%)]\tLoss: 0.190092\n",
      "Train Epoch: 1 [13376/60000 (22%)]\tLoss: 0.309251\n",
      "Train Epoch: 1 [13408/60000 (22%)]\tLoss: 0.132068\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.294361\n",
      "Train Epoch: 1 [13472/60000 (22%)]\tLoss: 0.069624\n",
      "Train Epoch: 1 [13504/60000 (23%)]\tLoss: 0.375158\n",
      "Train Epoch: 1 [13536/60000 (23%)]\tLoss: 0.123952\n",
      "Train Epoch: 1 [13568/60000 (23%)]\tLoss: 0.049296\n",
      "Train Epoch: 1 [13600/60000 (23%)]\tLoss: 0.042091\n",
      "Train Epoch: 1 [13632/60000 (23%)]\tLoss: 0.280045\n",
      "Train Epoch: 1 [13664/60000 (23%)]\tLoss: 0.268983\n",
      "Train Epoch: 1 [13696/60000 (23%)]\tLoss: 0.328499\n",
      "Train Epoch: 1 [13728/60000 (23%)]\tLoss: 0.366529\n",
      "Train Epoch: 1 [13760/60000 (23%)]\tLoss: 0.055175\n",
      "Train Epoch: 1 [13792/60000 (23%)]\tLoss: 0.103567\n",
      "Train Epoch: 1 [13824/60000 (23%)]\tLoss: 0.287044\n",
      "Train Epoch: 1 [13856/60000 (23%)]\tLoss: 0.137582\n",
      "Train Epoch: 1 [13888/60000 (23%)]\tLoss: 0.132951\n",
      "Train Epoch: 1 [13920/60000 (23%)]\tLoss: 0.160542\n",
      "Train Epoch: 1 [13952/60000 (23%)]\tLoss: 0.577417\n",
      "Train Epoch: 1 [13984/60000 (23%)]\tLoss: 0.284357\n",
      "Train Epoch: 1 [14016/60000 (23%)]\tLoss: 0.109831\n",
      "Train Epoch: 1 [14048/60000 (23%)]\tLoss: 0.341202\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.208354\n",
      "Train Epoch: 1 [14112/60000 (24%)]\tLoss: 0.203495\n",
      "Train Epoch: 1 [14144/60000 (24%)]\tLoss: 0.210984\n",
      "Train Epoch: 1 [14176/60000 (24%)]\tLoss: 0.259905\n",
      "Train Epoch: 1 [14208/60000 (24%)]\tLoss: 0.160876\n",
      "Train Epoch: 1 [14240/60000 (24%)]\tLoss: 0.152806\n",
      "Train Epoch: 1 [14272/60000 (24%)]\tLoss: 0.318895\n",
      "Train Epoch: 1 [14304/60000 (24%)]\tLoss: 0.329030\n",
      "Train Epoch: 1 [14336/60000 (24%)]\tLoss: 0.392681\n",
      "Train Epoch: 1 [14368/60000 (24%)]\tLoss: 0.419454\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.185024\n",
      "Train Epoch: 1 [14432/60000 (24%)]\tLoss: 0.143250\n",
      "Train Epoch: 1 [14464/60000 (24%)]\tLoss: 0.111833\n",
      "Train Epoch: 1 [14496/60000 (24%)]\tLoss: 0.197415\n",
      "Train Epoch: 1 [14528/60000 (24%)]\tLoss: 0.250946\n",
      "Train Epoch: 1 [14560/60000 (24%)]\tLoss: 0.260216\n",
      "Train Epoch: 1 [14592/60000 (24%)]\tLoss: 0.125951\n",
      "Train Epoch: 1 [14624/60000 (24%)]\tLoss: 0.310645\n",
      "Train Epoch: 1 [14656/60000 (24%)]\tLoss: 0.193089\n",
      "Train Epoch: 1 [14688/60000 (24%)]\tLoss: 0.312857\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.351325\n",
      "Train Epoch: 1 [14752/60000 (25%)]\tLoss: 0.440021\n",
      "Train Epoch: 1 [14784/60000 (25%)]\tLoss: 0.373531\n",
      "Train Epoch: 1 [14816/60000 (25%)]\tLoss: 0.227503\n",
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.258946\n",
      "Train Epoch: 1 [14880/60000 (25%)]\tLoss: 0.176431\n",
      "Train Epoch: 1 [14912/60000 (25%)]\tLoss: 0.101451\n",
      "Train Epoch: 1 [14944/60000 (25%)]\tLoss: 0.206384\n",
      "Train Epoch: 1 [14976/60000 (25%)]\tLoss: 0.202793\n",
      "Train Epoch: 1 [15008/60000 (25%)]\tLoss: 0.167204\n",
      "Train Epoch: 1 [15040/60000 (25%)]\tLoss: 0.213582\n",
      "Train Epoch: 1 [15072/60000 (25%)]\tLoss: 0.080696\n",
      "Train Epoch: 1 [15104/60000 (25%)]\tLoss: 0.490686\n",
      "Train Epoch: 1 [15136/60000 (25%)]\tLoss: 0.256549\n",
      "Train Epoch: 1 [15168/60000 (25%)]\tLoss: 0.170404\n",
      "Train Epoch: 1 [15200/60000 (25%)]\tLoss: 0.190729\n",
      "Train Epoch: 1 [15232/60000 (25%)]\tLoss: 0.171358\n",
      "Train Epoch: 1 [15264/60000 (25%)]\tLoss: 0.143758\n",
      "Train Epoch: 1 [15296/60000 (25%)]\tLoss: 0.086556\n",
      "Train Epoch: 1 [15328/60000 (26%)]\tLoss: 0.179636\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.189754\n",
      "Train Epoch: 1 [15392/60000 (26%)]\tLoss: 0.082763\n",
      "Train Epoch: 1 [15424/60000 (26%)]\tLoss: 0.269579\n",
      "Train Epoch: 1 [15456/60000 (26%)]\tLoss: 0.101323\n",
      "Train Epoch: 1 [15488/60000 (26%)]\tLoss: 0.310593\n",
      "Train Epoch: 1 [15520/60000 (26%)]\tLoss: 0.174895\n",
      "Train Epoch: 1 [15552/60000 (26%)]\tLoss: 0.182020\n",
      "Train Epoch: 1 [15584/60000 (26%)]\tLoss: 0.185585\n",
      "Train Epoch: 1 [15616/60000 (26%)]\tLoss: 0.126453\n",
      "Train Epoch: 1 [15648/60000 (26%)]\tLoss: 0.112983\n",
      "Train Epoch: 1 [15680/60000 (26%)]\tLoss: 0.028486\n",
      "Train Epoch: 1 [15712/60000 (26%)]\tLoss: 0.341616\n",
      "Train Epoch: 1 [15744/60000 (26%)]\tLoss: 0.198317\n",
      "Train Epoch: 1 [15776/60000 (26%)]\tLoss: 0.255936\n",
      "Train Epoch: 1 [15808/60000 (26%)]\tLoss: 0.171256\n",
      "Train Epoch: 1 [15840/60000 (26%)]\tLoss: 0.251906\n",
      "Train Epoch: 1 [15872/60000 (26%)]\tLoss: 0.271566\n",
      "Train Epoch: 1 [15904/60000 (27%)]\tLoss: 0.157846\n",
      "Train Epoch: 1 [15936/60000 (27%)]\tLoss: 0.590447\n",
      "Train Epoch: 1 [15968/60000 (27%)]\tLoss: 0.302979\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.261638\n",
      "Train Epoch: 1 [16032/60000 (27%)]\tLoss: 0.372962\n",
      "Train Epoch: 1 [16064/60000 (27%)]\tLoss: 0.083612\n",
      "Train Epoch: 1 [16096/60000 (27%)]\tLoss: 0.139617\n",
      "Train Epoch: 1 [16128/60000 (27%)]\tLoss: 0.119231\n",
      "Train Epoch: 1 [16160/60000 (27%)]\tLoss: 0.063295\n",
      "Train Epoch: 1 [16192/60000 (27%)]\tLoss: 0.307255\n",
      "Train Epoch: 1 [16224/60000 (27%)]\tLoss: 0.034248\n",
      "Train Epoch: 1 [16256/60000 (27%)]\tLoss: 0.141495\n",
      "Train Epoch: 1 [16288/60000 (27%)]\tLoss: 0.131604\n",
      "Train Epoch: 1 [16320/60000 (27%)]\tLoss: 0.047265\n",
      "Train Epoch: 1 [16352/60000 (27%)]\tLoss: 0.285033\n",
      "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 0.068034\n",
      "Train Epoch: 1 [16416/60000 (27%)]\tLoss: 0.222693\n",
      "Train Epoch: 1 [16448/60000 (27%)]\tLoss: 0.096753\n",
      "Train Epoch: 1 [16480/60000 (27%)]\tLoss: 0.215267\n",
      "Train Epoch: 1 [16512/60000 (28%)]\tLoss: 0.054429\n",
      "Train Epoch: 1 [16544/60000 (28%)]\tLoss: 0.440925\n",
      "Train Epoch: 1 [16576/60000 (28%)]\tLoss: 0.092594\n",
      "Train Epoch: 1 [16608/60000 (28%)]\tLoss: 0.125078\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.188876\n",
      "Train Epoch: 1 [16672/60000 (28%)]\tLoss: 0.264029\n",
      "Train Epoch: 1 [16704/60000 (28%)]\tLoss: 0.193039\n",
      "Train Epoch: 1 [16736/60000 (28%)]\tLoss: 0.261746\n",
      "Train Epoch: 1 [16768/60000 (28%)]\tLoss: 0.113404\n",
      "Train Epoch: 1 [16800/60000 (28%)]\tLoss: 0.064159\n",
      "Train Epoch: 1 [16832/60000 (28%)]\tLoss: 0.077786\n",
      "Train Epoch: 1 [16864/60000 (28%)]\tLoss: 0.119615\n",
      "Train Epoch: 1 [16896/60000 (28%)]\tLoss: 0.117068\n",
      "Train Epoch: 1 [16928/60000 (28%)]\tLoss: 0.150573\n",
      "Train Epoch: 1 [16960/60000 (28%)]\tLoss: 0.184294\n",
      "Train Epoch: 1 [16992/60000 (28%)]\tLoss: 0.209849\n",
      "Train Epoch: 1 [17024/60000 (28%)]\tLoss: 0.255793\n",
      "Train Epoch: 1 [17056/60000 (28%)]\tLoss: 0.144009\n",
      "Train Epoch: 1 [17088/60000 (28%)]\tLoss: 0.197236\n",
      "Train Epoch: 1 [17120/60000 (29%)]\tLoss: 0.100567\n",
      "Train Epoch: 1 [17152/60000 (29%)]\tLoss: 0.077398\n",
      "Train Epoch: 1 [17184/60000 (29%)]\tLoss: 0.231415\n",
      "Train Epoch: 1 [17216/60000 (29%)]\tLoss: 0.449526\n",
      "Train Epoch: 1 [17248/60000 (29%)]\tLoss: 0.040126\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.124706\n",
      "Train Epoch: 1 [17312/60000 (29%)]\tLoss: 0.030701\n",
      "Train Epoch: 1 [17344/60000 (29%)]\tLoss: 0.100320\n",
      "Train Epoch: 1 [17376/60000 (29%)]\tLoss: 0.189166\n",
      "Train Epoch: 1 [17408/60000 (29%)]\tLoss: 0.093873\n",
      "Train Epoch: 1 [17440/60000 (29%)]\tLoss: 0.130306\n",
      "Train Epoch: 1 [17472/60000 (29%)]\tLoss: 0.329585\n",
      "Train Epoch: 1 [17504/60000 (29%)]\tLoss: 0.067981\n",
      "Train Epoch: 1 [17536/60000 (29%)]\tLoss: 0.379854\n",
      "Train Epoch: 1 [17568/60000 (29%)]\tLoss: 0.200026\n",
      "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.137752\n",
      "Train Epoch: 1 [17632/60000 (29%)]\tLoss: 0.161988\n",
      "Train Epoch: 1 [17664/60000 (29%)]\tLoss: 0.047588\n",
      "Train Epoch: 1 [17696/60000 (29%)]\tLoss: 0.259547\n",
      "Train Epoch: 1 [17728/60000 (30%)]\tLoss: 0.201415\n",
      "Train Epoch: 1 [17760/60000 (30%)]\tLoss: 0.239040\n",
      "Train Epoch: 1 [17792/60000 (30%)]\tLoss: 0.332520\n",
      "Train Epoch: 1 [17824/60000 (30%)]\tLoss: 0.127986\n",
      "Train Epoch: 1 [17856/60000 (30%)]\tLoss: 0.082061\n",
      "Train Epoch: 1 [17888/60000 (30%)]\tLoss: 0.186988\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.155872\n",
      "Train Epoch: 1 [17952/60000 (30%)]\tLoss: 0.141099\n",
      "Train Epoch: 1 [17984/60000 (30%)]\tLoss: 0.225947\n",
      "Train Epoch: 1 [18016/60000 (30%)]\tLoss: 0.082795\n",
      "Train Epoch: 1 [18048/60000 (30%)]\tLoss: 0.106760\n",
      "Train Epoch: 1 [18080/60000 (30%)]\tLoss: 0.196122\n",
      "Train Epoch: 1 [18112/60000 (30%)]\tLoss: 0.075471\n",
      "Train Epoch: 1 [18144/60000 (30%)]\tLoss: 0.200051\n",
      "Train Epoch: 1 [18176/60000 (30%)]\tLoss: 0.068931\n",
      "Train Epoch: 1 [18208/60000 (30%)]\tLoss: 0.110780\n",
      "Train Epoch: 1 [18240/60000 (30%)]\tLoss: 0.126447\n",
      "Train Epoch: 1 [18272/60000 (30%)]\tLoss: 0.120595\n",
      "Train Epoch: 1 [18304/60000 (31%)]\tLoss: 0.176730\n",
      "Train Epoch: 1 [18336/60000 (31%)]\tLoss: 0.233792\n",
      "Train Epoch: 1 [18368/60000 (31%)]\tLoss: 0.075743\n",
      "Train Epoch: 1 [18400/60000 (31%)]\tLoss: 0.134041\n",
      "Train Epoch: 1 [18432/60000 (31%)]\tLoss: 0.060878\n",
      "Train Epoch: 1 [18464/60000 (31%)]\tLoss: 0.180537\n",
      "Train Epoch: 1 [18496/60000 (31%)]\tLoss: 0.130196\n",
      "Train Epoch: 1 [18528/60000 (31%)]\tLoss: 0.072058\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.105172\n",
      "Train Epoch: 1 [18592/60000 (31%)]\tLoss: 0.319074\n",
      "Train Epoch: 1 [18624/60000 (31%)]\tLoss: 0.149745\n",
      "Train Epoch: 1 [18656/60000 (31%)]\tLoss: 0.075546\n",
      "Train Epoch: 1 [18688/60000 (31%)]\tLoss: 0.136489\n",
      "Train Epoch: 1 [18720/60000 (31%)]\tLoss: 0.192659\n",
      "Train Epoch: 1 [18752/60000 (31%)]\tLoss: 0.076914\n",
      "Train Epoch: 1 [18784/60000 (31%)]\tLoss: 0.057986\n",
      "Train Epoch: 1 [18816/60000 (31%)]\tLoss: 0.276490\n",
      "Train Epoch: 1 [18848/60000 (31%)]\tLoss: 0.026533\n",
      "Train Epoch: 1 [18880/60000 (31%)]\tLoss: 0.077010\n",
      "Train Epoch: 1 [18912/60000 (32%)]\tLoss: 0.038679\n",
      "Train Epoch: 1 [18944/60000 (32%)]\tLoss: 0.031236\n",
      "Train Epoch: 1 [18976/60000 (32%)]\tLoss: 0.111902\n",
      "Train Epoch: 1 [19008/60000 (32%)]\tLoss: 0.202729\n",
      "Train Epoch: 1 [19040/60000 (32%)]\tLoss: 0.147323\n",
      "Train Epoch: 1 [19072/60000 (32%)]\tLoss: 0.175495\n",
      "Train Epoch: 1 [19104/60000 (32%)]\tLoss: 0.281338\n",
      "Train Epoch: 1 [19136/60000 (32%)]\tLoss: 0.170654\n",
      "Train Epoch: 1 [19168/60000 (32%)]\tLoss: 0.094950\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.080529\n",
      "Train Epoch: 1 [19232/60000 (32%)]\tLoss: 0.276499\n",
      "Train Epoch: 1 [19264/60000 (32%)]\tLoss: 0.093309\n",
      "Train Epoch: 1 [19296/60000 (32%)]\tLoss: 0.090763\n",
      "Train Epoch: 1 [19328/60000 (32%)]\tLoss: 0.180061\n",
      "Train Epoch: 1 [19360/60000 (32%)]\tLoss: 0.116127\n",
      "Train Epoch: 1 [19392/60000 (32%)]\tLoss: 0.087247\n",
      "Train Epoch: 1 [19424/60000 (32%)]\tLoss: 0.106049\n",
      "Train Epoch: 1 [19456/60000 (32%)]\tLoss: 0.081732\n",
      "Train Epoch: 1 [19488/60000 (32%)]\tLoss: 0.242697\n",
      "Train Epoch: 1 [19520/60000 (33%)]\tLoss: 0.156549\n",
      "Train Epoch: 1 [19552/60000 (33%)]\tLoss: 0.120649\n",
      "Train Epoch: 1 [19584/60000 (33%)]\tLoss: 0.121722\n",
      "Train Epoch: 1 [19616/60000 (33%)]\tLoss: 0.072306\n",
      "Train Epoch: 1 [19648/60000 (33%)]\tLoss: 0.084554\n",
      "Train Epoch: 1 [19680/60000 (33%)]\tLoss: 0.059132\n",
      "Train Epoch: 1 [19712/60000 (33%)]\tLoss: 0.027390\n",
      "Train Epoch: 1 [19744/60000 (33%)]\tLoss: 0.044926\n",
      "Train Epoch: 1 [19776/60000 (33%)]\tLoss: 0.129380\n",
      "Train Epoch: 1 [19808/60000 (33%)]\tLoss: 0.405363\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.106073\n",
      "Train Epoch: 1 [19872/60000 (33%)]\tLoss: 0.039557\n",
      "Train Epoch: 1 [19904/60000 (33%)]\tLoss: 0.109169\n",
      "Train Epoch: 1 [19936/60000 (33%)]\tLoss: 0.193773\n",
      "Train Epoch: 1 [19968/60000 (33%)]\tLoss: 0.132215\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.182741\n",
      "Train Epoch: 1 [20032/60000 (33%)]\tLoss: 0.199921\n",
      "Train Epoch: 1 [20064/60000 (33%)]\tLoss: 0.254293\n",
      "Train Epoch: 1 [20096/60000 (33%)]\tLoss: 0.165176\n",
      "Train Epoch: 1 [20128/60000 (34%)]\tLoss: 0.040128\n",
      "Train Epoch: 1 [20160/60000 (34%)]\tLoss: 0.421867\n",
      "Train Epoch: 1 [20192/60000 (34%)]\tLoss: 0.147577\n",
      "Train Epoch: 1 [20224/60000 (34%)]\tLoss: 0.145508\n",
      "Train Epoch: 1 [20256/60000 (34%)]\tLoss: 0.082458\n",
      "Train Epoch: 1 [20288/60000 (34%)]\tLoss: 0.078692\n",
      "Train Epoch: 1 [20320/60000 (34%)]\tLoss: 0.214844\n",
      "Train Epoch: 1 [20352/60000 (34%)]\tLoss: 0.101173\n",
      "Train Epoch: 1 [20384/60000 (34%)]\tLoss: 0.030328\n",
      "Train Epoch: 1 [20416/60000 (34%)]\tLoss: 0.067570\n",
      "Train Epoch: 1 [20448/60000 (34%)]\tLoss: 0.075498\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.028455\n",
      "Train Epoch: 1 [20512/60000 (34%)]\tLoss: 0.088840\n",
      "Train Epoch: 1 [20544/60000 (34%)]\tLoss: 0.166886\n",
      "Train Epoch: 1 [20576/60000 (34%)]\tLoss: 0.066482\n",
      "Train Epoch: 1 [20608/60000 (34%)]\tLoss: 0.045587\n",
      "Train Epoch: 1 [20640/60000 (34%)]\tLoss: 0.219368\n",
      "Train Epoch: 1 [20672/60000 (34%)]\tLoss: 0.325730\n",
      "Train Epoch: 1 [20704/60000 (35%)]\tLoss: 0.329390\n",
      "Train Epoch: 1 [20736/60000 (35%)]\tLoss: 0.152483\n",
      "Train Epoch: 1 [20768/60000 (35%)]\tLoss: 0.382919\n",
      "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.149079\n",
      "Train Epoch: 1 [20832/60000 (35%)]\tLoss: 0.147940\n",
      "Train Epoch: 1 [20864/60000 (35%)]\tLoss: 0.203971\n",
      "Train Epoch: 1 [20896/60000 (35%)]\tLoss: 0.458793\n",
      "Train Epoch: 1 [20928/60000 (35%)]\tLoss: 0.265852\n",
      "Train Epoch: 1 [20960/60000 (35%)]\tLoss: 0.278470\n",
      "Train Epoch: 1 [20992/60000 (35%)]\tLoss: 0.182838\n",
      "Train Epoch: 1 [21024/60000 (35%)]\tLoss: 0.216356\n",
      "Train Epoch: 1 [21056/60000 (35%)]\tLoss: 0.274552\n",
      "Train Epoch: 1 [21088/60000 (35%)]\tLoss: 0.134895\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.227615\n",
      "Train Epoch: 1 [21152/60000 (35%)]\tLoss: 0.117978\n",
      "Train Epoch: 1 [21184/60000 (35%)]\tLoss: 0.173830\n",
      "Train Epoch: 1 [21216/60000 (35%)]\tLoss: 0.062015\n",
      "Train Epoch: 1 [21248/60000 (35%)]\tLoss: 0.029907\n",
      "Train Epoch: 1 [21280/60000 (35%)]\tLoss: 0.203547\n",
      "Train Epoch: 1 [21312/60000 (36%)]\tLoss: 0.074836\n",
      "Train Epoch: 1 [21344/60000 (36%)]\tLoss: 0.173778\n",
      "Train Epoch: 1 [21376/60000 (36%)]\tLoss: 0.139228\n",
      "Train Epoch: 1 [21408/60000 (36%)]\tLoss: 0.149479\n",
      "Train Epoch: 1 [21440/60000 (36%)]\tLoss: 0.098136\n",
      "Train Epoch: 1 [21472/60000 (36%)]\tLoss: 0.023070\n",
      "Train Epoch: 1 [21504/60000 (36%)]\tLoss: 0.093168\n",
      "Train Epoch: 1 [21536/60000 (36%)]\tLoss: 0.073840\n",
      "Train Epoch: 1 [21568/60000 (36%)]\tLoss: 0.221094\n",
      "Train Epoch: 1 [21600/60000 (36%)]\tLoss: 0.390474\n",
      "Train Epoch: 1 [21632/60000 (36%)]\tLoss: 0.090097\n",
      "Train Epoch: 1 [21664/60000 (36%)]\tLoss: 0.080161\n",
      "Train Epoch: 1 [21696/60000 (36%)]\tLoss: 0.193414\n",
      "Train Epoch: 1 [21728/60000 (36%)]\tLoss: 0.076800\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.028269\n",
      "Train Epoch: 1 [21792/60000 (36%)]\tLoss: 0.025641\n",
      "Train Epoch: 1 [21824/60000 (36%)]\tLoss: 0.058181\n",
      "Train Epoch: 1 [21856/60000 (36%)]\tLoss: 0.044523\n",
      "Train Epoch: 1 [21888/60000 (36%)]\tLoss: 0.113916\n",
      "Train Epoch: 1 [21920/60000 (37%)]\tLoss: 0.102739\n",
      "Train Epoch: 1 [21952/60000 (37%)]\tLoss: 0.269569\n",
      "Train Epoch: 1 [21984/60000 (37%)]\tLoss: 0.128319\n",
      "Train Epoch: 1 [22016/60000 (37%)]\tLoss: 0.042559\n",
      "Train Epoch: 1 [22048/60000 (37%)]\tLoss: 0.109647\n",
      "Train Epoch: 1 [22080/60000 (37%)]\tLoss: 0.049736\n",
      "Train Epoch: 1 [22112/60000 (37%)]\tLoss: 0.274944\n",
      "Train Epoch: 1 [22144/60000 (37%)]\tLoss: 0.133113\n",
      "Train Epoch: 1 [22176/60000 (37%)]\tLoss: 0.248902\n",
      "Train Epoch: 1 [22208/60000 (37%)]\tLoss: 0.392882\n",
      "Train Epoch: 1 [22240/60000 (37%)]\tLoss: 0.078094\n",
      "Train Epoch: 1 [22272/60000 (37%)]\tLoss: 0.150363\n",
      "Train Epoch: 1 [22304/60000 (37%)]\tLoss: 0.123022\n",
      "Train Epoch: 1 [22336/60000 (37%)]\tLoss: 0.023707\n",
      "Train Epoch: 1 [22368/60000 (37%)]\tLoss: 0.031533\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.063055\n",
      "Train Epoch: 1 [22432/60000 (37%)]\tLoss: 0.156417\n",
      "Train Epoch: 1 [22464/60000 (37%)]\tLoss: 0.177868\n",
      "Train Epoch: 1 [22496/60000 (37%)]\tLoss: 0.286331\n",
      "Train Epoch: 1 [22528/60000 (38%)]\tLoss: 0.265656\n",
      "Train Epoch: 1 [22560/60000 (38%)]\tLoss: 0.289274\n",
      "Train Epoch: 1 [22592/60000 (38%)]\tLoss: 0.215705\n",
      "Train Epoch: 1 [22624/60000 (38%)]\tLoss: 0.153053\n",
      "Train Epoch: 1 [22656/60000 (38%)]\tLoss: 0.123180\n",
      "Train Epoch: 1 [22688/60000 (38%)]\tLoss: 0.102555\n",
      "Train Epoch: 1 [22720/60000 (38%)]\tLoss: 0.134403\n",
      "Train Epoch: 1 [22752/60000 (38%)]\tLoss: 0.134894\n",
      "Train Epoch: 1 [22784/60000 (38%)]\tLoss: 0.105800\n",
      "Train Epoch: 1 [22816/60000 (38%)]\tLoss: 0.088128\n",
      "Train Epoch: 1 [22848/60000 (38%)]\tLoss: 0.067844\n",
      "Train Epoch: 1 [22880/60000 (38%)]\tLoss: 0.130011\n",
      "Train Epoch: 1 [22912/60000 (38%)]\tLoss: 0.070159\n",
      "Train Epoch: 1 [22944/60000 (38%)]\tLoss: 0.014768\n",
      "Train Epoch: 1 [22976/60000 (38%)]\tLoss: 0.090167\n",
      "Train Epoch: 1 [23008/60000 (38%)]\tLoss: 0.151421\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.134268\n",
      "Train Epoch: 1 [23072/60000 (38%)]\tLoss: 0.569901\n",
      "Train Epoch: 1 [23104/60000 (39%)]\tLoss: 0.147131\n",
      "Train Epoch: 1 [23136/60000 (39%)]\tLoss: 0.165937\n",
      "Train Epoch: 1 [23168/60000 (39%)]\tLoss: 0.083116\n",
      "Train Epoch: 1 [23200/60000 (39%)]\tLoss: 0.163482\n",
      "Train Epoch: 1 [23232/60000 (39%)]\tLoss: 0.017762\n",
      "Train Epoch: 1 [23264/60000 (39%)]\tLoss: 0.059795\n",
      "Train Epoch: 1 [23296/60000 (39%)]\tLoss: 0.032010\n",
      "Train Epoch: 1 [23328/60000 (39%)]\tLoss: 0.120233\n",
      "Train Epoch: 1 [23360/60000 (39%)]\tLoss: 0.083552\n",
      "Train Epoch: 1 [23392/60000 (39%)]\tLoss: 0.073870\n",
      "Train Epoch: 1 [23424/60000 (39%)]\tLoss: 0.088047\n",
      "Train Epoch: 1 [23456/60000 (39%)]\tLoss: 0.244012\n",
      "Train Epoch: 1 [23488/60000 (39%)]\tLoss: 0.060285\n",
      "Train Epoch: 1 [23520/60000 (39%)]\tLoss: 0.111511\n",
      "Train Epoch: 1 [23552/60000 (39%)]\tLoss: 0.085970\n",
      "Train Epoch: 1 [23584/60000 (39%)]\tLoss: 0.212432\n",
      "Train Epoch: 1 [23616/60000 (39%)]\tLoss: 0.168620\n",
      "Train Epoch: 1 [23648/60000 (39%)]\tLoss: 0.074636\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.150743\n",
      "Train Epoch: 1 [23712/60000 (40%)]\tLoss: 0.286300\n",
      "Train Epoch: 1 [23744/60000 (40%)]\tLoss: 0.051177\n",
      "Train Epoch: 1 [23776/60000 (40%)]\tLoss: 0.097360\n",
      "Train Epoch: 1 [23808/60000 (40%)]\tLoss: 0.254167\n",
      "Train Epoch: 1 [23840/60000 (40%)]\tLoss: 0.204906\n",
      "Train Epoch: 1 [23872/60000 (40%)]\tLoss: 0.150418\n",
      "Train Epoch: 1 [23904/60000 (40%)]\tLoss: 0.204322\n",
      "Train Epoch: 1 [23936/60000 (40%)]\tLoss: 0.266759\n",
      "Train Epoch: 1 [23968/60000 (40%)]\tLoss: 0.059360\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.103436\n",
      "Train Epoch: 1 [24032/60000 (40%)]\tLoss: 0.249971\n",
      "Train Epoch: 1 [24064/60000 (40%)]\tLoss: 0.093363\n",
      "Train Epoch: 1 [24096/60000 (40%)]\tLoss: 0.102669\n",
      "Train Epoch: 1 [24128/60000 (40%)]\tLoss: 0.071842\n",
      "Train Epoch: 1 [24160/60000 (40%)]\tLoss: 0.076096\n",
      "Train Epoch: 1 [24192/60000 (40%)]\tLoss: 0.130111\n",
      "Train Epoch: 1 [24224/60000 (40%)]\tLoss: 0.047673\n",
      "Train Epoch: 1 [24256/60000 (40%)]\tLoss: 0.224951\n",
      "Train Epoch: 1 [24288/60000 (40%)]\tLoss: 0.083626\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.066830\n",
      "Train Epoch: 1 [24352/60000 (41%)]\tLoss: 0.077756\n",
      "Train Epoch: 1 [24384/60000 (41%)]\tLoss: 0.057678\n",
      "Train Epoch: 1 [24416/60000 (41%)]\tLoss: 0.135619\n",
      "Train Epoch: 1 [24448/60000 (41%)]\tLoss: 0.045863\n",
      "Train Epoch: 1 [24480/60000 (41%)]\tLoss: 0.054393\n",
      "Train Epoch: 1 [24512/60000 (41%)]\tLoss: 0.162046\n",
      "Train Epoch: 1 [24544/60000 (41%)]\tLoss: 0.150992\n",
      "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 0.185342\n",
      "Train Epoch: 1 [24608/60000 (41%)]\tLoss: 0.169087\n",
      "Train Epoch: 1 [24640/60000 (41%)]\tLoss: 0.133476\n",
      "Train Epoch: 1 [24672/60000 (41%)]\tLoss: 0.149765\n",
      "Train Epoch: 1 [24704/60000 (41%)]\tLoss: 0.109821\n",
      "Train Epoch: 1 [24736/60000 (41%)]\tLoss: 0.101999\n",
      "Train Epoch: 1 [24768/60000 (41%)]\tLoss: 0.467625\n",
      "Train Epoch: 1 [24800/60000 (41%)]\tLoss: 0.086366\n",
      "Train Epoch: 1 [24832/60000 (41%)]\tLoss: 0.131055\n",
      "Train Epoch: 1 [24864/60000 (41%)]\tLoss: 0.135526\n",
      "Train Epoch: 1 [24896/60000 (41%)]\tLoss: 0.180612\n",
      "Train Epoch: 1 [24928/60000 (42%)]\tLoss: 0.241652\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.177817\n",
      "Train Epoch: 1 [24992/60000 (42%)]\tLoss: 0.046929\n",
      "Train Epoch: 1 [25024/60000 (42%)]\tLoss: 0.028753\n",
      "Train Epoch: 1 [25056/60000 (42%)]\tLoss: 0.044775\n",
      "Train Epoch: 1 [25088/60000 (42%)]\tLoss: 0.187697\n",
      "Train Epoch: 1 [25120/60000 (42%)]\tLoss: 0.061256\n",
      "Train Epoch: 1 [25152/60000 (42%)]\tLoss: 0.160331\n",
      "Train Epoch: 1 [25184/60000 (42%)]\tLoss: 0.101879\n",
      "Train Epoch: 1 [25216/60000 (42%)]\tLoss: 0.125534\n",
      "Train Epoch: 1 [25248/60000 (42%)]\tLoss: 0.044358\n",
      "Train Epoch: 1 [25280/60000 (42%)]\tLoss: 0.224614\n",
      "Train Epoch: 1 [25312/60000 (42%)]\tLoss: 0.132353\n",
      "Train Epoch: 1 [25344/60000 (42%)]\tLoss: 0.027063\n",
      "Train Epoch: 1 [25376/60000 (42%)]\tLoss: 0.098985\n",
      "Train Epoch: 1 [25408/60000 (42%)]\tLoss: 0.048815\n",
      "Train Epoch: 1 [25440/60000 (42%)]\tLoss: 0.039195\n",
      "Train Epoch: 1 [25472/60000 (42%)]\tLoss: 0.294565\n",
      "Train Epoch: 1 [25504/60000 (43%)]\tLoss: 0.024863\n",
      "Train Epoch: 1 [25536/60000 (43%)]\tLoss: 0.418901\n",
      "Train Epoch: 1 [25568/60000 (43%)]\tLoss: 0.055240\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.103555\n",
      "Train Epoch: 1 [25632/60000 (43%)]\tLoss: 0.069082\n",
      "Train Epoch: 1 [25664/60000 (43%)]\tLoss: 0.249580\n",
      "Train Epoch: 1 [25696/60000 (43%)]\tLoss: 0.105479\n",
      "Train Epoch: 1 [25728/60000 (43%)]\tLoss: 0.080899\n",
      "Train Epoch: 1 [25760/60000 (43%)]\tLoss: 0.050792\n",
      "Train Epoch: 1 [25792/60000 (43%)]\tLoss: 0.347618\n",
      "Train Epoch: 1 [25824/60000 (43%)]\tLoss: 0.261778\n",
      "Train Epoch: 1 [25856/60000 (43%)]\tLoss: 0.082716\n",
      "Train Epoch: 1 [25888/60000 (43%)]\tLoss: 0.088490\n",
      "Train Epoch: 1 [25920/60000 (43%)]\tLoss: 0.147091\n",
      "Train Epoch: 1 [25952/60000 (43%)]\tLoss: 0.078503\n",
      "Train Epoch: 1 [25984/60000 (43%)]\tLoss: 0.096868\n",
      "Train Epoch: 1 [26016/60000 (43%)]\tLoss: 0.066516\n",
      "Train Epoch: 1 [26048/60000 (43%)]\tLoss: 0.178616\n",
      "Train Epoch: 1 [26080/60000 (43%)]\tLoss: 0.029297\n",
      "Train Epoch: 1 [26112/60000 (44%)]\tLoss: 0.090148\n",
      "Train Epoch: 1 [26144/60000 (44%)]\tLoss: 0.057768\n",
      "Train Epoch: 1 [26176/60000 (44%)]\tLoss: 0.061119\n",
      "Train Epoch: 1 [26208/60000 (44%)]\tLoss: 0.056449\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.137552\n",
      "Train Epoch: 1 [26272/60000 (44%)]\tLoss: 0.090483\n",
      "Train Epoch: 1 [26304/60000 (44%)]\tLoss: 0.015192\n",
      "Train Epoch: 1 [26336/60000 (44%)]\tLoss: 0.228836\n",
      "Train Epoch: 1 [26368/60000 (44%)]\tLoss: 0.357088\n",
      "Train Epoch: 1 [26400/60000 (44%)]\tLoss: 0.240884\n",
      "Train Epoch: 1 [26432/60000 (44%)]\tLoss: 0.179720\n",
      "Train Epoch: 1 [26464/60000 (44%)]\tLoss: 0.130182\n",
      "Train Epoch: 1 [26496/60000 (44%)]\tLoss: 0.319423\n",
      "Train Epoch: 1 [26528/60000 (44%)]\tLoss: 0.053788\n",
      "Train Epoch: 1 [26560/60000 (44%)]\tLoss: 0.271848\n",
      "Train Epoch: 1 [26592/60000 (44%)]\tLoss: 0.073246\n",
      "Train Epoch: 1 [26624/60000 (44%)]\tLoss: 0.717175\n",
      "Train Epoch: 1 [26656/60000 (44%)]\tLoss: 0.045782\n",
      "Train Epoch: 1 [26688/60000 (44%)]\tLoss: 0.157137\n",
      "Train Epoch: 1 [26720/60000 (45%)]\tLoss: 0.404856\n",
      "Train Epoch: 1 [26752/60000 (45%)]\tLoss: 0.092554\n",
      "Train Epoch: 1 [26784/60000 (45%)]\tLoss: 0.084599\n",
      "Train Epoch: 1 [26816/60000 (45%)]\tLoss: 0.043077\n",
      "Train Epoch: 1 [26848/60000 (45%)]\tLoss: 0.285931\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.475613\n",
      "Train Epoch: 1 [26912/60000 (45%)]\tLoss: 0.066633\n",
      "Train Epoch: 1 [26944/60000 (45%)]\tLoss: 0.030281\n",
      "Train Epoch: 1 [26976/60000 (45%)]\tLoss: 0.022739\n",
      "Train Epoch: 1 [27008/60000 (45%)]\tLoss: 0.063924\n",
      "Train Epoch: 1 [27040/60000 (45%)]\tLoss: 0.033661\n",
      "Train Epoch: 1 [27072/60000 (45%)]\tLoss: 0.068088\n",
      "Train Epoch: 1 [27104/60000 (45%)]\tLoss: 0.069726\n",
      "Train Epoch: 1 [27136/60000 (45%)]\tLoss: 0.320179\n",
      "Train Epoch: 1 [27168/60000 (45%)]\tLoss: 0.254918\n",
      "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.134783\n",
      "Train Epoch: 1 [27232/60000 (45%)]\tLoss: 0.325646\n",
      "Train Epoch: 1 [27264/60000 (45%)]\tLoss: 0.042085\n",
      "Train Epoch: 1 [27296/60000 (45%)]\tLoss: 0.074752\n",
      "Train Epoch: 1 [27328/60000 (46%)]\tLoss: 0.107137\n",
      "Train Epoch: 1 [27360/60000 (46%)]\tLoss: 0.039375\n",
      "Train Epoch: 1 [27392/60000 (46%)]\tLoss: 0.045819\n",
      "Train Epoch: 1 [27424/60000 (46%)]\tLoss: 0.099014\n",
      "Train Epoch: 1 [27456/60000 (46%)]\tLoss: 0.109491\n",
      "Train Epoch: 1 [27488/60000 (46%)]\tLoss: 0.247762\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.125759\n",
      "Train Epoch: 1 [27552/60000 (46%)]\tLoss: 0.045350\n",
      "Train Epoch: 1 [27584/60000 (46%)]\tLoss: 0.226868\n",
      "Train Epoch: 1 [27616/60000 (46%)]\tLoss: 0.151016\n",
      "Train Epoch: 1 [27648/60000 (46%)]\tLoss: 0.088650\n",
      "Train Epoch: 1 [27680/60000 (46%)]\tLoss: 0.131826\n",
      "Train Epoch: 1 [27712/60000 (46%)]\tLoss: 0.087295\n",
      "Train Epoch: 1 [27744/60000 (46%)]\tLoss: 0.021199\n",
      "Train Epoch: 1 [27776/60000 (46%)]\tLoss: 0.086603\n",
      "Train Epoch: 1 [27808/60000 (46%)]\tLoss: 0.093800\n",
      "Train Epoch: 1 [27840/60000 (46%)]\tLoss: 0.088826\n",
      "Train Epoch: 1 [27872/60000 (46%)]\tLoss: 0.051503\n",
      "Train Epoch: 1 [27904/60000 (47%)]\tLoss: 0.029890\n",
      "Train Epoch: 1 [27936/60000 (47%)]\tLoss: 0.069810\n",
      "Train Epoch: 1 [27968/60000 (47%)]\tLoss: 0.116908\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.125633\n",
      "Train Epoch: 1 [28032/60000 (47%)]\tLoss: 0.020607\n",
      "Train Epoch: 1 [28064/60000 (47%)]\tLoss: 0.075440\n",
      "Train Epoch: 1 [28096/60000 (47%)]\tLoss: 0.086528\n",
      "Train Epoch: 1 [28128/60000 (47%)]\tLoss: 0.250406\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.133499\n",
      "Train Epoch: 1 [28192/60000 (47%)]\tLoss: 0.076870\n",
      "Train Epoch: 1 [28224/60000 (47%)]\tLoss: 0.039939\n",
      "Train Epoch: 1 [28256/60000 (47%)]\tLoss: 0.057093\n",
      "Train Epoch: 1 [28288/60000 (47%)]\tLoss: 0.037494\n",
      "Train Epoch: 1 [28320/60000 (47%)]\tLoss: 0.016634\n",
      "Train Epoch: 1 [28352/60000 (47%)]\tLoss: 0.439731\n",
      "Train Epoch: 1 [28384/60000 (47%)]\tLoss: 0.231231\n",
      "Train Epoch: 1 [28416/60000 (47%)]\tLoss: 0.129457\n",
      "Train Epoch: 1 [28448/60000 (47%)]\tLoss: 0.025672\n",
      "Train Epoch: 1 [28480/60000 (47%)]\tLoss: 0.081029\n",
      "Train Epoch: 1 [28512/60000 (48%)]\tLoss: 0.062823\n",
      "Train Epoch: 1 [28544/60000 (48%)]\tLoss: 0.168089\n",
      "Train Epoch: 1 [28576/60000 (48%)]\tLoss: 0.063396\n",
      "Train Epoch: 1 [28608/60000 (48%)]\tLoss: 0.329979\n",
      "Train Epoch: 1 [28640/60000 (48%)]\tLoss: 0.527799\n",
      "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 0.044353\n",
      "Train Epoch: 1 [28704/60000 (48%)]\tLoss: 0.184053\n",
      "Train Epoch: 1 [28736/60000 (48%)]\tLoss: 0.028138\n",
      "Train Epoch: 1 [28768/60000 (48%)]\tLoss: 0.198920\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.139593\n",
      "Train Epoch: 1 [28832/60000 (48%)]\tLoss: 0.064177\n",
      "Train Epoch: 1 [28864/60000 (48%)]\tLoss: 0.019047\n",
      "Train Epoch: 1 [28896/60000 (48%)]\tLoss: 0.039306\n",
      "Train Epoch: 1 [28928/60000 (48%)]\tLoss: 0.183192\n",
      "Train Epoch: 1 [28960/60000 (48%)]\tLoss: 0.132928\n",
      "Train Epoch: 1 [28992/60000 (48%)]\tLoss: 0.073700\n",
      "Train Epoch: 1 [29024/60000 (48%)]\tLoss: 0.106626\n",
      "Train Epoch: 1 [29056/60000 (48%)]\tLoss: 0.155100\n",
      "Train Epoch: 1 [29088/60000 (48%)]\tLoss: 0.080679\n",
      "Train Epoch: 1 [29120/60000 (49%)]\tLoss: 0.071322\n",
      "Train Epoch: 1 [29152/60000 (49%)]\tLoss: 0.176343\n",
      "Train Epoch: 1 [29184/60000 (49%)]\tLoss: 0.198231\n",
      "Train Epoch: 1 [29216/60000 (49%)]\tLoss: 0.165700\n",
      "Train Epoch: 1 [29248/60000 (49%)]\tLoss: 0.077034\n",
      "Train Epoch: 1 [29280/60000 (49%)]\tLoss: 0.253274\n",
      "Train Epoch: 1 [29312/60000 (49%)]\tLoss: 0.192688\n",
      "Train Epoch: 1 [29344/60000 (49%)]\tLoss: 0.048671\n",
      "Train Epoch: 1 [29376/60000 (49%)]\tLoss: 0.044197\n",
      "Train Epoch: 1 [29408/60000 (49%)]\tLoss: 0.232255\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.109935\n",
      "Train Epoch: 1 [29472/60000 (49%)]\tLoss: 0.033900\n",
      "Train Epoch: 1 [29504/60000 (49%)]\tLoss: 0.142275\n",
      "Train Epoch: 1 [29536/60000 (49%)]\tLoss: 0.056291\n",
      "Train Epoch: 1 [29568/60000 (49%)]\tLoss: 0.168503\n",
      "Train Epoch: 1 [29600/60000 (49%)]\tLoss: 0.021321\n",
      "Train Epoch: 1 [29632/60000 (49%)]\tLoss: 0.064561\n",
      "Train Epoch: 1 [29664/60000 (49%)]\tLoss: 0.174099\n",
      "Train Epoch: 1 [29696/60000 (49%)]\tLoss: 0.206629\n",
      "Train Epoch: 1 [29728/60000 (50%)]\tLoss: 0.199252\n",
      "Train Epoch: 1 [29760/60000 (50%)]\tLoss: 0.058464\n",
      "Train Epoch: 1 [29792/60000 (50%)]\tLoss: 0.062829\n",
      "Train Epoch: 1 [29824/60000 (50%)]\tLoss: 0.260281\n",
      "Train Epoch: 1 [29856/60000 (50%)]\tLoss: 0.164873\n",
      "Train Epoch: 1 [29888/60000 (50%)]\tLoss: 0.095955\n",
      "Train Epoch: 1 [29920/60000 (50%)]\tLoss: 0.175025\n",
      "Train Epoch: 1 [29952/60000 (50%)]\tLoss: 0.139111\n",
      "Train Epoch: 1 [29984/60000 (50%)]\tLoss: 0.096505\n",
      "Train Epoch: 1 [30016/60000 (50%)]\tLoss: 0.118529\n",
      "Train Epoch: 1 [30048/60000 (50%)]\tLoss: 0.231395\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.065819\n",
      "Train Epoch: 1 [30112/60000 (50%)]\tLoss: 0.219758\n",
      "Train Epoch: 1 [30144/60000 (50%)]\tLoss: 0.137800\n",
      "Train Epoch: 1 [30176/60000 (50%)]\tLoss: 0.091515\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.162651\n",
      "Train Epoch: 1 [30240/60000 (50%)]\tLoss: 0.181531\n",
      "Train Epoch: 1 [30272/60000 (50%)]\tLoss: 0.064316\n",
      "Train Epoch: 1 [30304/60000 (51%)]\tLoss: 0.106297\n",
      "Train Epoch: 1 [30336/60000 (51%)]\tLoss: 0.134666\n",
      "Train Epoch: 1 [30368/60000 (51%)]\tLoss: 0.037449\n",
      "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 0.086869\n",
      "Train Epoch: 1 [30432/60000 (51%)]\tLoss: 0.070428\n",
      "Train Epoch: 1 [30464/60000 (51%)]\tLoss: 0.140854\n",
      "Train Epoch: 1 [30496/60000 (51%)]\tLoss: 0.082766\n",
      "Train Epoch: 1 [30528/60000 (51%)]\tLoss: 0.058289\n",
      "Train Epoch: 1 [30560/60000 (51%)]\tLoss: 0.071405\n",
      "Train Epoch: 1 [30592/60000 (51%)]\tLoss: 0.220422\n",
      "Train Epoch: 1 [30624/60000 (51%)]\tLoss: 0.056878\n",
      "Train Epoch: 1 [30656/60000 (51%)]\tLoss: 0.129790\n",
      "Train Epoch: 1 [30688/60000 (51%)]\tLoss: 0.161374\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.102641\n",
      "Train Epoch: 1 [30752/60000 (51%)]\tLoss: 0.064457\n",
      "Train Epoch: 1 [30784/60000 (51%)]\tLoss: 0.166940\n",
      "Train Epoch: 1 [30816/60000 (51%)]\tLoss: 0.170117\n",
      "Train Epoch: 1 [30848/60000 (51%)]\tLoss: 0.088416\n",
      "Train Epoch: 1 [30880/60000 (51%)]\tLoss: 0.178660\n",
      "Train Epoch: 1 [30912/60000 (52%)]\tLoss: 0.049276\n",
      "Train Epoch: 1 [30944/60000 (52%)]\tLoss: 0.158208\n",
      "Train Epoch: 1 [30976/60000 (52%)]\tLoss: 0.100662\n",
      "Train Epoch: 1 [31008/60000 (52%)]\tLoss: 0.099438\n",
      "Train Epoch: 1 [31040/60000 (52%)]\tLoss: 0.107550\n",
      "Train Epoch: 1 [31072/60000 (52%)]\tLoss: 0.095166\n",
      "Train Epoch: 1 [31104/60000 (52%)]\tLoss: 0.392568\n",
      "Train Epoch: 1 [31136/60000 (52%)]\tLoss: 0.029937\n",
      "Train Epoch: 1 [31168/60000 (52%)]\tLoss: 0.326720\n",
      "Train Epoch: 1 [31200/60000 (52%)]\tLoss: 0.070750\n",
      "Train Epoch: 1 [31232/60000 (52%)]\tLoss: 0.169006\n",
      "Train Epoch: 1 [31264/60000 (52%)]\tLoss: 0.173340\n",
      "Train Epoch: 1 [31296/60000 (52%)]\tLoss: 0.493232\n",
      "Train Epoch: 1 [31328/60000 (52%)]\tLoss: 0.134803\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.153466\n",
      "Train Epoch: 1 [31392/60000 (52%)]\tLoss: 0.207136\n",
      "Train Epoch: 1 [31424/60000 (52%)]\tLoss: 0.093520\n",
      "Train Epoch: 1 [31456/60000 (52%)]\tLoss: 0.102564\n",
      "Train Epoch: 1 [31488/60000 (52%)]\tLoss: 0.084339\n",
      "Train Epoch: 1 [31520/60000 (53%)]\tLoss: 0.122534\n",
      "Train Epoch: 1 [31552/60000 (53%)]\tLoss: 0.124370\n",
      "Train Epoch: 1 [31584/60000 (53%)]\tLoss: 0.170002\n",
      "Train Epoch: 1 [31616/60000 (53%)]\tLoss: 0.020066\n",
      "Train Epoch: 1 [31648/60000 (53%)]\tLoss: 0.323022\n",
      "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 0.225836\n",
      "Train Epoch: 1 [31712/60000 (53%)]\tLoss: 0.379613\n",
      "Train Epoch: 1 [31744/60000 (53%)]\tLoss: 0.182919\n",
      "Train Epoch: 1 [31776/60000 (53%)]\tLoss: 0.188618\n",
      "Train Epoch: 1 [31808/60000 (53%)]\tLoss: 0.025398\n",
      "Train Epoch: 1 [31840/60000 (53%)]\tLoss: 0.292462\n",
      "Train Epoch: 1 [31872/60000 (53%)]\tLoss: 0.055037\n",
      "Train Epoch: 1 [31904/60000 (53%)]\tLoss: 0.049259\n",
      "Train Epoch: 1 [31936/60000 (53%)]\tLoss: 0.257569\n",
      "Train Epoch: 1 [31968/60000 (53%)]\tLoss: 0.047267\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.343242\n",
      "Train Epoch: 1 [32032/60000 (53%)]\tLoss: 0.161014\n",
      "Train Epoch: 1 [32064/60000 (53%)]\tLoss: 0.100356\n",
      "Train Epoch: 1 [32096/60000 (53%)]\tLoss: 0.196545\n",
      "Train Epoch: 1 [32128/60000 (54%)]\tLoss: 0.159845\n",
      "Train Epoch: 1 [32160/60000 (54%)]\tLoss: 0.219121\n",
      "Train Epoch: 1 [32192/60000 (54%)]\tLoss: 0.051420\n",
      "Train Epoch: 1 [32224/60000 (54%)]\tLoss: 0.095508\n",
      "Train Epoch: 1 [32256/60000 (54%)]\tLoss: 0.135287\n",
      "Train Epoch: 1 [32288/60000 (54%)]\tLoss: 0.097545\n",
      "Train Epoch: 1 [32320/60000 (54%)]\tLoss: 0.388173\n",
      "Train Epoch: 1 [32352/60000 (54%)]\tLoss: 0.099629\n",
      "Train Epoch: 1 [32384/60000 (54%)]\tLoss: 0.111613\n",
      "Train Epoch: 1 [32416/60000 (54%)]\tLoss: 0.348747\n",
      "Train Epoch: 1 [32448/60000 (54%)]\tLoss: 0.178517\n",
      "Train Epoch: 1 [32480/60000 (54%)]\tLoss: 0.111261\n",
      "Train Epoch: 1 [32512/60000 (54%)]\tLoss: 0.029223\n",
      "Train Epoch: 1 [32544/60000 (54%)]\tLoss: 0.154407\n",
      "Train Epoch: 1 [32576/60000 (54%)]\tLoss: 0.017051\n",
      "Train Epoch: 1 [32608/60000 (54%)]\tLoss: 0.054610\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.286558\n",
      "Train Epoch: 1 [32672/60000 (54%)]\tLoss: 0.072766\n",
      "Train Epoch: 1 [32704/60000 (55%)]\tLoss: 0.032102\n",
      "Train Epoch: 1 [32736/60000 (55%)]\tLoss: 0.094443\n",
      "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.221969\n",
      "Train Epoch: 1 [32800/60000 (55%)]\tLoss: 0.107945\n",
      "Train Epoch: 1 [32832/60000 (55%)]\tLoss: 0.060432\n",
      "Train Epoch: 1 [32864/60000 (55%)]\tLoss: 0.283216\n",
      "Train Epoch: 1 [32896/60000 (55%)]\tLoss: 0.154515\n",
      "Train Epoch: 1 [32928/60000 (55%)]\tLoss: 0.064558\n",
      "Train Epoch: 1 [32960/60000 (55%)]\tLoss: 0.011624\n",
      "Train Epoch: 1 [32992/60000 (55%)]\tLoss: 0.079515\n",
      "Train Epoch: 1 [33024/60000 (55%)]\tLoss: 0.039998\n",
      "Train Epoch: 1 [33056/60000 (55%)]\tLoss: 0.208097\n",
      "Train Epoch: 1 [33088/60000 (55%)]\tLoss: 0.038981\n",
      "Train Epoch: 1 [33120/60000 (55%)]\tLoss: 0.127709\n",
      "Train Epoch: 1 [33152/60000 (55%)]\tLoss: 0.030579\n",
      "Train Epoch: 1 [33184/60000 (55%)]\tLoss: 0.084713\n",
      "Train Epoch: 1 [33216/60000 (55%)]\tLoss: 0.195976\n",
      "Train Epoch: 1 [33248/60000 (55%)]\tLoss: 0.036900\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.136858\n",
      "Train Epoch: 1 [33312/60000 (56%)]\tLoss: 0.141545\n",
      "Train Epoch: 1 [33344/60000 (56%)]\tLoss: 0.056649\n",
      "Train Epoch: 1 [33376/60000 (56%)]\tLoss: 0.187201\n",
      "Train Epoch: 1 [33408/60000 (56%)]\tLoss: 0.129978\n",
      "Train Epoch: 1 [33440/60000 (56%)]\tLoss: 0.059484\n",
      "Train Epoch: 1 [33472/60000 (56%)]\tLoss: 0.088188\n",
      "Train Epoch: 1 [33504/60000 (56%)]\tLoss: 0.192459\n",
      "Train Epoch: 1 [33536/60000 (56%)]\tLoss: 0.077294\n",
      "Train Epoch: 1 [33568/60000 (56%)]\tLoss: 0.075313\n",
      "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.091811\n",
      "Train Epoch: 1 [33632/60000 (56%)]\tLoss: 0.038079\n",
      "Train Epoch: 1 [33664/60000 (56%)]\tLoss: 0.170986\n",
      "Train Epoch: 1 [33696/60000 (56%)]\tLoss: 0.019920\n",
      "Train Epoch: 1 [33728/60000 (56%)]\tLoss: 0.052567\n",
      "Train Epoch: 1 [33760/60000 (56%)]\tLoss: 0.356732\n",
      "Train Epoch: 1 [33792/60000 (56%)]\tLoss: 0.058119\n",
      "Train Epoch: 1 [33824/60000 (56%)]\tLoss: 0.054862\n",
      "Train Epoch: 1 [33856/60000 (56%)]\tLoss: 0.027127\n",
      "Train Epoch: 1 [33888/60000 (56%)]\tLoss: 0.032331\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.009306\n",
      "Train Epoch: 1 [33952/60000 (57%)]\tLoss: 0.107511\n",
      "Train Epoch: 1 [33984/60000 (57%)]\tLoss: 0.095054\n",
      "Train Epoch: 1 [34016/60000 (57%)]\tLoss: 0.031707\n",
      "Train Epoch: 1 [34048/60000 (57%)]\tLoss: 0.256502\n",
      "Train Epoch: 1 [34080/60000 (57%)]\tLoss: 0.075211\n",
      "Train Epoch: 1 [34112/60000 (57%)]\tLoss: 0.083060\n",
      "Train Epoch: 1 [34144/60000 (57%)]\tLoss: 0.026874\n",
      "Train Epoch: 1 [34176/60000 (57%)]\tLoss: 0.088645\n",
      "Train Epoch: 1 [34208/60000 (57%)]\tLoss: 0.075298\n",
      "Train Epoch: 1 [34240/60000 (57%)]\tLoss: 0.070168\n",
      "Train Epoch: 1 [34272/60000 (57%)]\tLoss: 0.016169\n",
      "Train Epoch: 1 [34304/60000 (57%)]\tLoss: 0.114267\n",
      "Train Epoch: 1 [34336/60000 (57%)]\tLoss: 0.049113\n",
      "Train Epoch: 1 [34368/60000 (57%)]\tLoss: 0.037319\n",
      "Train Epoch: 1 [34400/60000 (57%)]\tLoss: 0.349260\n",
      "Train Epoch: 1 [34432/60000 (57%)]\tLoss: 0.101797\n",
      "Train Epoch: 1 [34464/60000 (57%)]\tLoss: 0.149455\n",
      "Train Epoch: 1 [34496/60000 (57%)]\tLoss: 0.192264\n",
      "Train Epoch: 1 [34528/60000 (58%)]\tLoss: 0.144073\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.079634\n",
      "Train Epoch: 1 [34592/60000 (58%)]\tLoss: 0.046878\n",
      "Train Epoch: 1 [34624/60000 (58%)]\tLoss: 0.046835\n",
      "Train Epoch: 1 [34656/60000 (58%)]\tLoss: 0.349169\n",
      "Train Epoch: 1 [34688/60000 (58%)]\tLoss: 0.234791\n",
      "Train Epoch: 1 [34720/60000 (58%)]\tLoss: 0.189649\n",
      "Train Epoch: 1 [34752/60000 (58%)]\tLoss: 0.071488\n",
      "Train Epoch: 1 [34784/60000 (58%)]\tLoss: 0.155432\n",
      "Train Epoch: 1 [34816/60000 (58%)]\tLoss: 0.149261\n",
      "Train Epoch: 1 [34848/60000 (58%)]\tLoss: 0.042944\n",
      "Train Epoch: 1 [34880/60000 (58%)]\tLoss: 0.095222\n",
      "Train Epoch: 1 [34912/60000 (58%)]\tLoss: 0.271651\n",
      "Train Epoch: 1 [34944/60000 (58%)]\tLoss: 0.030617\n",
      "Train Epoch: 1 [34976/60000 (58%)]\tLoss: 0.028083\n",
      "Train Epoch: 1 [35008/60000 (58%)]\tLoss: 0.035351\n",
      "Train Epoch: 1 [35040/60000 (58%)]\tLoss: 0.155780\n",
      "Train Epoch: 1 [35072/60000 (58%)]\tLoss: 0.060734\n",
      "Train Epoch: 1 [35104/60000 (59%)]\tLoss: 0.032095\n",
      "Train Epoch: 1 [35136/60000 (59%)]\tLoss: 0.168638\n",
      "Train Epoch: 1 [35168/60000 (59%)]\tLoss: 0.045078\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.073910\n",
      "Train Epoch: 1 [35232/60000 (59%)]\tLoss: 0.292932\n",
      "Train Epoch: 1 [35264/60000 (59%)]\tLoss: 0.019299\n",
      "Train Epoch: 1 [35296/60000 (59%)]\tLoss: 0.089874\n",
      "Train Epoch: 1 [35328/60000 (59%)]\tLoss: 0.031041\n",
      "Train Epoch: 1 [35360/60000 (59%)]\tLoss: 0.063203\n",
      "Train Epoch: 1 [35392/60000 (59%)]\tLoss: 0.171108\n",
      "Train Epoch: 1 [35424/60000 (59%)]\tLoss: 0.042563\n",
      "Train Epoch: 1 [35456/60000 (59%)]\tLoss: 0.353532\n",
      "Train Epoch: 1 [35488/60000 (59%)]\tLoss: 0.105731\n",
      "Train Epoch: 1 [35520/60000 (59%)]\tLoss: 0.022808\n",
      "Train Epoch: 1 [35552/60000 (59%)]\tLoss: 0.071817\n",
      "Train Epoch: 1 [35584/60000 (59%)]\tLoss: 0.030562\n",
      "Train Epoch: 1 [35616/60000 (59%)]\tLoss: 0.390229\n",
      "Train Epoch: 1 [35648/60000 (59%)]\tLoss: 0.024237\n",
      "Train Epoch: 1 [35680/60000 (59%)]\tLoss: 0.130654\n",
      "Train Epoch: 1 [35712/60000 (60%)]\tLoss: 0.084447\n",
      "Train Epoch: 1 [35744/60000 (60%)]\tLoss: 0.043332\n",
      "Train Epoch: 1 [35776/60000 (60%)]\tLoss: 0.028684\n",
      "Train Epoch: 1 [35808/60000 (60%)]\tLoss: 0.017785\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.221548\n",
      "Train Epoch: 1 [35872/60000 (60%)]\tLoss: 0.068600\n",
      "Train Epoch: 1 [35904/60000 (60%)]\tLoss: 0.049797\n",
      "Train Epoch: 1 [35936/60000 (60%)]\tLoss: 0.128938\n",
      "Train Epoch: 1 [35968/60000 (60%)]\tLoss: 0.174402\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.289905\n",
      "Train Epoch: 1 [36032/60000 (60%)]\tLoss: 0.285066\n",
      "Train Epoch: 1 [36064/60000 (60%)]\tLoss: 0.181526\n",
      "Train Epoch: 1 [36096/60000 (60%)]\tLoss: 0.318783\n",
      "Train Epoch: 1 [36128/60000 (60%)]\tLoss: 0.023226\n",
      "Train Epoch: 1 [36160/60000 (60%)]\tLoss: 0.110073\n",
      "Train Epoch: 1 [36192/60000 (60%)]\tLoss: 0.096153\n",
      "Train Epoch: 1 [36224/60000 (60%)]\tLoss: 0.161407\n",
      "Train Epoch: 1 [36256/60000 (60%)]\tLoss: 0.112253\n",
      "Train Epoch: 1 [36288/60000 (60%)]\tLoss: 0.030773\n",
      "Train Epoch: 1 [36320/60000 (61%)]\tLoss: 0.047846\n",
      "Train Epoch: 1 [36352/60000 (61%)]\tLoss: 0.057594\n",
      "Train Epoch: 1 [36384/60000 (61%)]\tLoss: 0.247660\n",
      "Train Epoch: 1 [36416/60000 (61%)]\tLoss: 0.419625\n",
      "Train Epoch: 1 [36448/60000 (61%)]\tLoss: 0.091352\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.032754\n",
      "Train Epoch: 1 [36512/60000 (61%)]\tLoss: 0.041124\n",
      "Train Epoch: 1 [36544/60000 (61%)]\tLoss: 0.066736\n",
      "Train Epoch: 1 [36576/60000 (61%)]\tLoss: 0.168017\n",
      "Train Epoch: 1 [36608/60000 (61%)]\tLoss: 0.054623\n",
      "Train Epoch: 1 [36640/60000 (61%)]\tLoss: 0.076679\n",
      "Train Epoch: 1 [36672/60000 (61%)]\tLoss: 0.018166\n",
      "Train Epoch: 1 [36704/60000 (61%)]\tLoss: 0.184285\n",
      "Train Epoch: 1 [36736/60000 (61%)]\tLoss: 0.402984\n",
      "Train Epoch: 1 [36768/60000 (61%)]\tLoss: 0.067850\n",
      "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 0.160923\n",
      "Train Epoch: 1 [36832/60000 (61%)]\tLoss: 0.171187\n",
      "Train Epoch: 1 [36864/60000 (61%)]\tLoss: 0.156781\n",
      "Train Epoch: 1 [36896/60000 (61%)]\tLoss: 0.061482\n",
      "Train Epoch: 1 [36928/60000 (62%)]\tLoss: 0.104113\n",
      "Train Epoch: 1 [36960/60000 (62%)]\tLoss: 0.033066\n",
      "Train Epoch: 1 [36992/60000 (62%)]\tLoss: 0.042271\n",
      "Train Epoch: 1 [37024/60000 (62%)]\tLoss: 0.483481\n",
      "Train Epoch: 1 [37056/60000 (62%)]\tLoss: 0.254494\n",
      "Train Epoch: 1 [37088/60000 (62%)]\tLoss: 0.196663\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.139695\n",
      "Train Epoch: 1 [37152/60000 (62%)]\tLoss: 0.155188\n",
      "Train Epoch: 1 [37184/60000 (62%)]\tLoss: 0.104270\n",
      "Train Epoch: 1 [37216/60000 (62%)]\tLoss: 0.034433\n",
      "Train Epoch: 1 [37248/60000 (62%)]\tLoss: 0.130226\n",
      "Train Epoch: 1 [37280/60000 (62%)]\tLoss: 0.196130\n",
      "Train Epoch: 1 [37312/60000 (62%)]\tLoss: 0.110683\n",
      "Train Epoch: 1 [37344/60000 (62%)]\tLoss: 0.414127\n",
      "Train Epoch: 1 [37376/60000 (62%)]\tLoss: 0.232998\n",
      "Train Epoch: 1 [37408/60000 (62%)]\tLoss: 0.212928\n",
      "Train Epoch: 1 [37440/60000 (62%)]\tLoss: 0.413997\n",
      "Train Epoch: 1 [37472/60000 (62%)]\tLoss: 0.117205\n",
      "Train Epoch: 1 [37504/60000 (63%)]\tLoss: 0.102562\n",
      "Train Epoch: 1 [37536/60000 (63%)]\tLoss: 0.256790\n",
      "Train Epoch: 1 [37568/60000 (63%)]\tLoss: 0.105815\n",
      "Train Epoch: 1 [37600/60000 (63%)]\tLoss: 0.058499\n",
      "Train Epoch: 1 [37632/60000 (63%)]\tLoss: 0.118679\n",
      "Train Epoch: 1 [37664/60000 (63%)]\tLoss: 0.108486\n",
      "Train Epoch: 1 [37696/60000 (63%)]\tLoss: 0.185724\n",
      "Train Epoch: 1 [37728/60000 (63%)]\tLoss: 0.242996\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.076997\n",
      "Train Epoch: 1 [37792/60000 (63%)]\tLoss: 0.316322\n",
      "Train Epoch: 1 [37824/60000 (63%)]\tLoss: 0.307461\n",
      "Train Epoch: 1 [37856/60000 (63%)]\tLoss: 0.111761\n",
      "Train Epoch: 1 [37888/60000 (63%)]\tLoss: 0.045370\n",
      "Train Epoch: 1 [37920/60000 (63%)]\tLoss: 0.145938\n",
      "Train Epoch: 1 [37952/60000 (63%)]\tLoss: 0.076066\n",
      "Train Epoch: 1 [37984/60000 (63%)]\tLoss: 0.112613\n",
      "Train Epoch: 1 [38016/60000 (63%)]\tLoss: 0.141600\n",
      "Train Epoch: 1 [38048/60000 (63%)]\tLoss: 0.077328\n",
      "Train Epoch: 1 [38080/60000 (63%)]\tLoss: 0.063525\n",
      "Train Epoch: 1 [38112/60000 (64%)]\tLoss: 0.058782\n",
      "Train Epoch: 1 [38144/60000 (64%)]\tLoss: 0.025282\n",
      "Train Epoch: 1 [38176/60000 (64%)]\tLoss: 0.074649\n",
      "Train Epoch: 1 [38208/60000 (64%)]\tLoss: 0.093298\n",
      "Train Epoch: 1 [38240/60000 (64%)]\tLoss: 0.177951\n",
      "Train Epoch: 1 [38272/60000 (64%)]\tLoss: 0.047163\n",
      "Train Epoch: 1 [38304/60000 (64%)]\tLoss: 0.179396\n",
      "Train Epoch: 1 [38336/60000 (64%)]\tLoss: 0.076622\n",
      "Train Epoch: 1 [38368/60000 (64%)]\tLoss: 0.185742\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.135106\n",
      "Train Epoch: 1 [38432/60000 (64%)]\tLoss: 0.027781\n",
      "Train Epoch: 1 [38464/60000 (64%)]\tLoss: 0.039728\n",
      "Train Epoch: 1 [38496/60000 (64%)]\tLoss: 0.256940\n",
      "Train Epoch: 1 [38528/60000 (64%)]\tLoss: 0.033190\n",
      "Train Epoch: 1 [38560/60000 (64%)]\tLoss: 0.095853\n",
      "Train Epoch: 1 [38592/60000 (64%)]\tLoss: 0.223251\n",
      "Train Epoch: 1 [38624/60000 (64%)]\tLoss: 0.069271\n",
      "Train Epoch: 1 [38656/60000 (64%)]\tLoss: 0.198149\n",
      "Train Epoch: 1 [38688/60000 (64%)]\tLoss: 0.138979\n",
      "Train Epoch: 1 [38720/60000 (65%)]\tLoss: 0.015126\n",
      "Train Epoch: 1 [38752/60000 (65%)]\tLoss: 0.097198\n",
      "Train Epoch: 1 [38784/60000 (65%)]\tLoss: 0.113839\n",
      "Train Epoch: 1 [38816/60000 (65%)]\tLoss: 0.023344\n",
      "Train Epoch: 1 [38848/60000 (65%)]\tLoss: 0.013750\n",
      "Train Epoch: 1 [38880/60000 (65%)]\tLoss: 0.092178\n",
      "Train Epoch: 1 [38912/60000 (65%)]\tLoss: 0.074337\n",
      "Train Epoch: 1 [38944/60000 (65%)]\tLoss: 0.019583\n",
      "Train Epoch: 1 [38976/60000 (65%)]\tLoss: 0.049670\n",
      "Train Epoch: 1 [39008/60000 (65%)]\tLoss: 0.146648\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.030998\n",
      "Train Epoch: 1 [39072/60000 (65%)]\tLoss: 0.021717\n",
      "Train Epoch: 1 [39104/60000 (65%)]\tLoss: 0.087251\n",
      "Train Epoch: 1 [39136/60000 (65%)]\tLoss: 0.034247\n",
      "Train Epoch: 1 [39168/60000 (65%)]\tLoss: 0.239652\n",
      "Train Epoch: 1 [39200/60000 (65%)]\tLoss: 0.020669\n",
      "Train Epoch: 1 [39232/60000 (65%)]\tLoss: 0.057306\n",
      "Train Epoch: 1 [39264/60000 (65%)]\tLoss: 0.168687\n",
      "Train Epoch: 1 [39296/60000 (65%)]\tLoss: 0.364074\n",
      "Train Epoch: 1 [39328/60000 (66%)]\tLoss: 0.266846\n",
      "Train Epoch: 1 [39360/60000 (66%)]\tLoss: 0.234233\n",
      "Train Epoch: 1 [39392/60000 (66%)]\tLoss: 0.200366\n",
      "Train Epoch: 1 [39424/60000 (66%)]\tLoss: 0.105969\n",
      "Train Epoch: 1 [39456/60000 (66%)]\tLoss: 0.122836\n",
      "Train Epoch: 1 [39488/60000 (66%)]\tLoss: 0.046333\n",
      "Train Epoch: 1 [39520/60000 (66%)]\tLoss: 0.065697\n",
      "Train Epoch: 1 [39552/60000 (66%)]\tLoss: 0.054833\n",
      "Train Epoch: 1 [39584/60000 (66%)]\tLoss: 0.093350\n",
      "Train Epoch: 1 [39616/60000 (66%)]\tLoss: 0.184163\n",
      "Train Epoch: 1 [39648/60000 (66%)]\tLoss: 0.198639\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.091704\n",
      "Train Epoch: 1 [39712/60000 (66%)]\tLoss: 0.052545\n",
      "Train Epoch: 1 [39744/60000 (66%)]\tLoss: 0.274213\n",
      "Train Epoch: 1 [39776/60000 (66%)]\tLoss: 0.125697\n",
      "Train Epoch: 1 [39808/60000 (66%)]\tLoss: 0.124379\n",
      "Train Epoch: 1 [39840/60000 (66%)]\tLoss: 0.171252\n",
      "Train Epoch: 1 [39872/60000 (66%)]\tLoss: 0.075362\n",
      "Train Epoch: 1 [39904/60000 (67%)]\tLoss: 0.083980\n",
      "Train Epoch: 1 [39936/60000 (67%)]\tLoss: 0.269125\n",
      "Train Epoch: 1 [39968/60000 (67%)]\tLoss: 0.090757\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.077452\n",
      "Train Epoch: 1 [40032/60000 (67%)]\tLoss: 0.159063\n",
      "Train Epoch: 1 [40064/60000 (67%)]\tLoss: 0.060775\n",
      "Train Epoch: 1 [40096/60000 (67%)]\tLoss: 0.069812\n",
      "Train Epoch: 1 [40128/60000 (67%)]\tLoss: 0.230362\n",
      "Train Epoch: 1 [40160/60000 (67%)]\tLoss: 0.113164\n",
      "Train Epoch: 1 [40192/60000 (67%)]\tLoss: 0.060901\n",
      "Train Epoch: 1 [40224/60000 (67%)]\tLoss: 0.086849\n",
      "Train Epoch: 1 [40256/60000 (67%)]\tLoss: 0.163017\n",
      "Train Epoch: 1 [40288/60000 (67%)]\tLoss: 0.146165\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.015246\n",
      "Train Epoch: 1 [40352/60000 (67%)]\tLoss: 0.215063\n",
      "Train Epoch: 1 [40384/60000 (67%)]\tLoss: 0.063195\n",
      "Train Epoch: 1 [40416/60000 (67%)]\tLoss: 0.021002\n",
      "Train Epoch: 1 [40448/60000 (67%)]\tLoss: 0.090772\n",
      "Train Epoch: 1 [40480/60000 (67%)]\tLoss: 0.068933\n",
      "Train Epoch: 1 [40512/60000 (68%)]\tLoss: 0.095841\n",
      "Train Epoch: 1 [40544/60000 (68%)]\tLoss: 0.142101\n",
      "Train Epoch: 1 [40576/60000 (68%)]\tLoss: 0.076884\n",
      "Train Epoch: 1 [40608/60000 (68%)]\tLoss: 0.155261\n",
      "Train Epoch: 1 [40640/60000 (68%)]\tLoss: 0.207503\n",
      "Train Epoch: 1 [40672/60000 (68%)]\tLoss: 0.015509\n",
      "Train Epoch: 1 [40704/60000 (68%)]\tLoss: 0.056309\n",
      "Train Epoch: 1 [40736/60000 (68%)]\tLoss: 0.088757\n",
      "Train Epoch: 1 [40768/60000 (68%)]\tLoss: 0.019138\n",
      "Train Epoch: 1 [40800/60000 (68%)]\tLoss: 0.066336\n",
      "Train Epoch: 1 [40832/60000 (68%)]\tLoss: 0.012839\n",
      "Train Epoch: 1 [40864/60000 (68%)]\tLoss: 0.170166\n",
      "Train Epoch: 1 [40896/60000 (68%)]\tLoss: 0.025081\n",
      "Train Epoch: 1 [40928/60000 (68%)]\tLoss: 0.038237\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.249399\n",
      "Train Epoch: 1 [40992/60000 (68%)]\tLoss: 0.042272\n",
      "Train Epoch: 1 [41024/60000 (68%)]\tLoss: 0.058043\n",
      "Train Epoch: 1 [41056/60000 (68%)]\tLoss: 0.174635\n",
      "Train Epoch: 1 [41088/60000 (68%)]\tLoss: 0.173060\n",
      "Train Epoch: 1 [41120/60000 (69%)]\tLoss: 0.027413\n",
      "Train Epoch: 1 [41152/60000 (69%)]\tLoss: 0.065164\n",
      "Train Epoch: 1 [41184/60000 (69%)]\tLoss: 0.194264\n",
      "Train Epoch: 1 [41216/60000 (69%)]\tLoss: 0.033012\n",
      "Train Epoch: 1 [41248/60000 (69%)]\tLoss: 0.308949\n",
      "Train Epoch: 1 [41280/60000 (69%)]\tLoss: 0.191104\n",
      "Train Epoch: 1 [41312/60000 (69%)]\tLoss: 0.219408\n",
      "Train Epoch: 1 [41344/60000 (69%)]\tLoss: 0.094453\n",
      "Train Epoch: 1 [41376/60000 (69%)]\tLoss: 0.097718\n",
      "Train Epoch: 1 [41408/60000 (69%)]\tLoss: 0.175606\n",
      "Train Epoch: 1 [41440/60000 (69%)]\tLoss: 0.254575\n",
      "Train Epoch: 1 [41472/60000 (69%)]\tLoss: 0.044676\n",
      "Train Epoch: 1 [41504/60000 (69%)]\tLoss: 0.077739\n",
      "Train Epoch: 1 [41536/60000 (69%)]\tLoss: 0.216096\n",
      "Train Epoch: 1 [41568/60000 (69%)]\tLoss: 0.079554\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.117599\n",
      "Train Epoch: 1 [41632/60000 (69%)]\tLoss: 0.015081\n",
      "Train Epoch: 1 [41664/60000 (69%)]\tLoss: 0.052778\n",
      "Train Epoch: 1 [41696/60000 (69%)]\tLoss: 0.079492\n",
      "Train Epoch: 1 [41728/60000 (70%)]\tLoss: 0.059456\n",
      "Train Epoch: 1 [41760/60000 (70%)]\tLoss: 0.071615\n",
      "Train Epoch: 1 [41792/60000 (70%)]\tLoss: 0.098171\n",
      "Train Epoch: 1 [41824/60000 (70%)]\tLoss: 0.065069\n",
      "Train Epoch: 1 [41856/60000 (70%)]\tLoss: 0.039365\n",
      "Train Epoch: 1 [41888/60000 (70%)]\tLoss: 0.095065\n",
      "Train Epoch: 1 [41920/60000 (70%)]\tLoss: 0.083295\n",
      "Train Epoch: 1 [41952/60000 (70%)]\tLoss: 0.028842\n",
      "Train Epoch: 1 [41984/60000 (70%)]\tLoss: 0.230058\n",
      "Train Epoch: 1 [42016/60000 (70%)]\tLoss: 0.153943\n",
      "Train Epoch: 1 [42048/60000 (70%)]\tLoss: 0.037322\n",
      "Train Epoch: 1 [42080/60000 (70%)]\tLoss: 0.029544\n",
      "Train Epoch: 1 [42112/60000 (70%)]\tLoss: 0.175150\n",
      "Train Epoch: 1 [42144/60000 (70%)]\tLoss: 0.024050\n",
      "Train Epoch: 1 [42176/60000 (70%)]\tLoss: 0.077243\n",
      "Train Epoch: 1 [42208/60000 (70%)]\tLoss: 0.074899\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.020196\n",
      "Train Epoch: 1 [42272/60000 (70%)]\tLoss: 0.044393\n",
      "Train Epoch: 1 [42304/60000 (71%)]\tLoss: 0.109078\n",
      "Train Epoch: 1 [42336/60000 (71%)]\tLoss: 0.130570\n",
      "Train Epoch: 1 [42368/60000 (71%)]\tLoss: 0.081670\n",
      "Train Epoch: 1 [42400/60000 (71%)]\tLoss: 0.138407\n",
      "Train Epoch: 1 [42432/60000 (71%)]\tLoss: 0.394112\n",
      "Train Epoch: 1 [42464/60000 (71%)]\tLoss: 0.237818\n",
      "Train Epoch: 1 [42496/60000 (71%)]\tLoss: 0.417502\n",
      "Train Epoch: 1 [42528/60000 (71%)]\tLoss: 0.040868\n",
      "Train Epoch: 1 [42560/60000 (71%)]\tLoss: 0.163694\n",
      "Train Epoch: 1 [42592/60000 (71%)]\tLoss: 0.026987\n",
      "Train Epoch: 1 [42624/60000 (71%)]\tLoss: 0.027662\n",
      "Train Epoch: 1 [42656/60000 (71%)]\tLoss: 0.104386\n",
      "Train Epoch: 1 [42688/60000 (71%)]\tLoss: 0.157815\n",
      "Train Epoch: 1 [42720/60000 (71%)]\tLoss: 0.040307\n",
      "Train Epoch: 1 [42752/60000 (71%)]\tLoss: 0.099070\n",
      "Train Epoch: 1 [42784/60000 (71%)]\tLoss: 0.034506\n",
      "Train Epoch: 1 [42816/60000 (71%)]\tLoss: 0.134676\n",
      "Train Epoch: 1 [42848/60000 (71%)]\tLoss: 0.330023\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.163039\n",
      "Train Epoch: 1 [42912/60000 (72%)]\tLoss: 0.139428\n",
      "Train Epoch: 1 [42944/60000 (72%)]\tLoss: 0.179299\n",
      "Train Epoch: 1 [42976/60000 (72%)]\tLoss: 0.164699\n",
      "Train Epoch: 1 [43008/60000 (72%)]\tLoss: 0.092407\n",
      "Train Epoch: 1 [43040/60000 (72%)]\tLoss: 0.161321\n",
      "Train Epoch: 1 [43072/60000 (72%)]\tLoss: 0.091356\n",
      "Train Epoch: 1 [43104/60000 (72%)]\tLoss: 0.135012\n",
      "Train Epoch: 1 [43136/60000 (72%)]\tLoss: 0.057723\n",
      "Train Epoch: 1 [43168/60000 (72%)]\tLoss: 0.085375\n",
      "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.111375\n",
      "Train Epoch: 1 [43232/60000 (72%)]\tLoss: 0.050304\n",
      "Train Epoch: 1 [43264/60000 (72%)]\tLoss: 0.036204\n",
      "Train Epoch: 1 [43296/60000 (72%)]\tLoss: 0.008768\n",
      "Train Epoch: 1 [43328/60000 (72%)]\tLoss: 0.050594\n",
      "Train Epoch: 1 [43360/60000 (72%)]\tLoss: 0.108942\n",
      "Train Epoch: 1 [43392/60000 (72%)]\tLoss: 0.022104\n",
      "Train Epoch: 1 [43424/60000 (72%)]\tLoss: 0.192915\n",
      "Train Epoch: 1 [43456/60000 (72%)]\tLoss: 0.077022\n",
      "Train Epoch: 1 [43488/60000 (72%)]\tLoss: 0.059979\n",
      "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 0.163501\n",
      "Train Epoch: 1 [43552/60000 (73%)]\tLoss: 0.234077\n",
      "Train Epoch: 1 [43584/60000 (73%)]\tLoss: 0.012128\n",
      "Train Epoch: 1 [43616/60000 (73%)]\tLoss: 0.022409\n",
      "Train Epoch: 1 [43648/60000 (73%)]\tLoss: 0.274318\n",
      "Train Epoch: 1 [43680/60000 (73%)]\tLoss: 0.049639\n",
      "Train Epoch: 1 [43712/60000 (73%)]\tLoss: 0.019399\n",
      "Train Epoch: 1 [43744/60000 (73%)]\tLoss: 0.019982\n",
      "Train Epoch: 1 [43776/60000 (73%)]\tLoss: 0.077654\n",
      "Train Epoch: 1 [43808/60000 (73%)]\tLoss: 0.076346\n",
      "Train Epoch: 1 [43840/60000 (73%)]\tLoss: 0.085963\n",
      "Train Epoch: 1 [43872/60000 (73%)]\tLoss: 0.261492\n",
      "Train Epoch: 1 [43904/60000 (73%)]\tLoss: 0.059211\n",
      "Train Epoch: 1 [43936/60000 (73%)]\tLoss: 0.235355\n",
      "Train Epoch: 1 [43968/60000 (73%)]\tLoss: 0.260593\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.046888\n",
      "Train Epoch: 1 [44032/60000 (73%)]\tLoss: 0.089641\n",
      "Train Epoch: 1 [44064/60000 (73%)]\tLoss: 0.128470\n",
      "Train Epoch: 1 [44096/60000 (73%)]\tLoss: 0.164549\n",
      "Train Epoch: 1 [44128/60000 (74%)]\tLoss: 0.056945\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.089963\n",
      "Train Epoch: 1 [44192/60000 (74%)]\tLoss: 0.060317\n",
      "Train Epoch: 1 [44224/60000 (74%)]\tLoss: 0.167638\n",
      "Train Epoch: 1 [44256/60000 (74%)]\tLoss: 0.060928\n",
      "Train Epoch: 1 [44288/60000 (74%)]\tLoss: 0.054349\n",
      "Train Epoch: 1 [44320/60000 (74%)]\tLoss: 0.084256\n",
      "Train Epoch: 1 [44352/60000 (74%)]\tLoss: 0.254520\n",
      "Train Epoch: 1 [44384/60000 (74%)]\tLoss: 0.035325\n",
      "Train Epoch: 1 [44416/60000 (74%)]\tLoss: 0.172211\n",
      "Train Epoch: 1 [44448/60000 (74%)]\tLoss: 0.236174\n",
      "Train Epoch: 1 [44480/60000 (74%)]\tLoss: 0.077873\n",
      "Train Epoch: 1 [44512/60000 (74%)]\tLoss: 0.115649\n",
      "Train Epoch: 1 [44544/60000 (74%)]\tLoss: 0.053866\n",
      "Train Epoch: 1 [44576/60000 (74%)]\tLoss: 0.026040\n",
      "Train Epoch: 1 [44608/60000 (74%)]\tLoss: 0.069247\n",
      "Train Epoch: 1 [44640/60000 (74%)]\tLoss: 0.024306\n",
      "Train Epoch: 1 [44672/60000 (74%)]\tLoss: 0.042256\n",
      "Train Epoch: 1 [44704/60000 (75%)]\tLoss: 0.050942\n",
      "Train Epoch: 1 [44736/60000 (75%)]\tLoss: 0.219592\n",
      "Train Epoch: 1 [44768/60000 (75%)]\tLoss: 0.068075\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.105728\n",
      "Train Epoch: 1 [44832/60000 (75%)]\tLoss: 0.274302\n",
      "Train Epoch: 1 [44864/60000 (75%)]\tLoss: 0.134827\n",
      "Train Epoch: 1 [44896/60000 (75%)]\tLoss: 0.142472\n",
      "Train Epoch: 1 [44928/60000 (75%)]\tLoss: 0.038996\n",
      "Train Epoch: 1 [44960/60000 (75%)]\tLoss: 0.256434\n",
      "Train Epoch: 1 [44992/60000 (75%)]\tLoss: 0.056320\n",
      "Train Epoch: 1 [45024/60000 (75%)]\tLoss: 0.119003\n",
      "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 0.052252\n",
      "Train Epoch: 1 [45088/60000 (75%)]\tLoss: 0.189136\n",
      "Train Epoch: 1 [45120/60000 (75%)]\tLoss: 0.270020\n",
      "Train Epoch: 1 [45152/60000 (75%)]\tLoss: 0.143942\n",
      "Train Epoch: 1 [45184/60000 (75%)]\tLoss: 0.212100\n",
      "Train Epoch: 1 [45216/60000 (75%)]\tLoss: 0.023498\n",
      "Train Epoch: 1 [45248/60000 (75%)]\tLoss: 0.125890\n",
      "Train Epoch: 1 [45280/60000 (75%)]\tLoss: 0.016168\n",
      "Train Epoch: 1 [45312/60000 (76%)]\tLoss: 0.005859\n",
      "Train Epoch: 1 [45344/60000 (76%)]\tLoss: 0.110094\n",
      "Train Epoch: 1 [45376/60000 (76%)]\tLoss: 0.062994\n",
      "Train Epoch: 1 [45408/60000 (76%)]\tLoss: 0.257684\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.119716\n",
      "Train Epoch: 1 [45472/60000 (76%)]\tLoss: 0.175455\n",
      "Train Epoch: 1 [45504/60000 (76%)]\tLoss: 0.176483\n",
      "Train Epoch: 1 [45536/60000 (76%)]\tLoss: 0.014668\n",
      "Train Epoch: 1 [45568/60000 (76%)]\tLoss: 0.138444\n",
      "Train Epoch: 1 [45600/60000 (76%)]\tLoss: 0.303170\n",
      "Train Epoch: 1 [45632/60000 (76%)]\tLoss: 0.026604\n",
      "Train Epoch: 1 [45664/60000 (76%)]\tLoss: 0.026125\n",
      "Train Epoch: 1 [45696/60000 (76%)]\tLoss: 0.046062\n",
      "Train Epoch: 1 [45728/60000 (76%)]\tLoss: 0.070054\n",
      "Train Epoch: 1 [45760/60000 (76%)]\tLoss: 0.126789\n",
      "Train Epoch: 1 [45792/60000 (76%)]\tLoss: 0.291394\n",
      "Train Epoch: 1 [45824/60000 (76%)]\tLoss: 0.076212\n",
      "Train Epoch: 1 [45856/60000 (76%)]\tLoss: 0.254582\n",
      "Train Epoch: 1 [45888/60000 (76%)]\tLoss: 0.194466\n",
      "Train Epoch: 1 [45920/60000 (77%)]\tLoss: 0.051110\n",
      "Train Epoch: 1 [45952/60000 (77%)]\tLoss: 0.283383\n",
      "Train Epoch: 1 [45984/60000 (77%)]\tLoss: 0.052152\n",
      "Train Epoch: 1 [46016/60000 (77%)]\tLoss: 0.116392\n",
      "Train Epoch: 1 [46048/60000 (77%)]\tLoss: 0.148794\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.194385\n",
      "Train Epoch: 1 [46112/60000 (77%)]\tLoss: 0.177876\n",
      "Train Epoch: 1 [46144/60000 (77%)]\tLoss: 0.050571\n",
      "Train Epoch: 1 [46176/60000 (77%)]\tLoss: 0.136118\n",
      "Train Epoch: 1 [46208/60000 (77%)]\tLoss: 0.032182\n",
      "Train Epoch: 1 [46240/60000 (77%)]\tLoss: 0.323073\n",
      "Train Epoch: 1 [46272/60000 (77%)]\tLoss: 0.357621\n",
      "Train Epoch: 1 [46304/60000 (77%)]\tLoss: 0.104950\n",
      "Train Epoch: 1 [46336/60000 (77%)]\tLoss: 0.166512\n",
      "Train Epoch: 1 [46368/60000 (77%)]\tLoss: 0.101342\n",
      "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.291686\n",
      "Train Epoch: 1 [46432/60000 (77%)]\tLoss: 0.193301\n",
      "Train Epoch: 1 [46464/60000 (77%)]\tLoss: 0.038932\n",
      "Train Epoch: 1 [46496/60000 (77%)]\tLoss: 0.013975\n",
      "Train Epoch: 1 [46528/60000 (78%)]\tLoss: 0.011779\n",
      "Train Epoch: 1 [46560/60000 (78%)]\tLoss: 0.150516\n",
      "Train Epoch: 1 [46592/60000 (78%)]\tLoss: 0.089234\n",
      "Train Epoch: 1 [46624/60000 (78%)]\tLoss: 0.065687\n",
      "Train Epoch: 1 [46656/60000 (78%)]\tLoss: 0.012955\n",
      "Train Epoch: 1 [46688/60000 (78%)]\tLoss: 0.095263\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.284770\n",
      "Train Epoch: 1 [46752/60000 (78%)]\tLoss: 0.036801\n",
      "Train Epoch: 1 [46784/60000 (78%)]\tLoss: 0.049658\n",
      "Train Epoch: 1 [46816/60000 (78%)]\tLoss: 0.018055\n",
      "Train Epoch: 1 [46848/60000 (78%)]\tLoss: 0.101048\n",
      "Train Epoch: 1 [46880/60000 (78%)]\tLoss: 0.021879\n",
      "Train Epoch: 1 [46912/60000 (78%)]\tLoss: 0.063710\n",
      "Train Epoch: 1 [46944/60000 (78%)]\tLoss: 0.063578\n",
      "Train Epoch: 1 [46976/60000 (78%)]\tLoss: 0.131126\n",
      "Train Epoch: 1 [47008/60000 (78%)]\tLoss: 0.265504\n",
      "Train Epoch: 1 [47040/60000 (78%)]\tLoss: 0.043600\n",
      "Train Epoch: 1 [47072/60000 (78%)]\tLoss: 0.162228\n",
      "Train Epoch: 1 [47104/60000 (79%)]\tLoss: 0.095408\n",
      "Train Epoch: 1 [47136/60000 (79%)]\tLoss: 0.180656\n",
      "Train Epoch: 1 [47168/60000 (79%)]\tLoss: 0.009124\n",
      "Train Epoch: 1 [47200/60000 (79%)]\tLoss: 0.176033\n",
      "Train Epoch: 1 [47232/60000 (79%)]\tLoss: 0.328100\n",
      "Train Epoch: 1 [47264/60000 (79%)]\tLoss: 0.281085\n",
      "Train Epoch: 1 [47296/60000 (79%)]\tLoss: 0.042100\n",
      "Train Epoch: 1 [47328/60000 (79%)]\tLoss: 0.209530\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.170316\n",
      "Train Epoch: 1 [47392/60000 (79%)]\tLoss: 0.079585\n",
      "Train Epoch: 1 [47424/60000 (79%)]\tLoss: 0.098622\n",
      "Train Epoch: 1 [47456/60000 (79%)]\tLoss: 0.328154\n",
      "Train Epoch: 1 [47488/60000 (79%)]\tLoss: 0.094938\n",
      "Train Epoch: 1 [47520/60000 (79%)]\tLoss: 0.102809\n",
      "Train Epoch: 1 [47552/60000 (79%)]\tLoss: 0.152401\n",
      "Train Epoch: 1 [47584/60000 (79%)]\tLoss: 0.356552\n",
      "Train Epoch: 1 [47616/60000 (79%)]\tLoss: 0.068385\n",
      "Train Epoch: 1 [47648/60000 (79%)]\tLoss: 0.023297\n",
      "Train Epoch: 1 [47680/60000 (79%)]\tLoss: 0.212409\n",
      "Train Epoch: 1 [47712/60000 (80%)]\tLoss: 0.020575\n",
      "Train Epoch: 1 [47744/60000 (80%)]\tLoss: 0.143984\n",
      "Train Epoch: 1 [47776/60000 (80%)]\tLoss: 0.041036\n",
      "Train Epoch: 1 [47808/60000 (80%)]\tLoss: 0.085239\n",
      "Train Epoch: 1 [47840/60000 (80%)]\tLoss: 0.118964\n",
      "Train Epoch: 1 [47872/60000 (80%)]\tLoss: 0.108943\n",
      "Train Epoch: 1 [47904/60000 (80%)]\tLoss: 0.228508\n",
      "Train Epoch: 1 [47936/60000 (80%)]\tLoss: 0.209018\n",
      "Train Epoch: 1 [47968/60000 (80%)]\tLoss: 0.034275\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.076761\n",
      "Train Epoch: 1 [48032/60000 (80%)]\tLoss: 0.043433\n",
      "Train Epoch: 1 [48064/60000 (80%)]\tLoss: 0.076220\n",
      "Train Epoch: 1 [48096/60000 (80%)]\tLoss: 0.194641\n",
      "Train Epoch: 1 [48128/60000 (80%)]\tLoss: 0.068206\n",
      "Train Epoch: 1 [48160/60000 (80%)]\tLoss: 0.020333\n",
      "Train Epoch: 1 [48192/60000 (80%)]\tLoss: 0.027037\n",
      "Train Epoch: 1 [48224/60000 (80%)]\tLoss: 0.047679\n",
      "Train Epoch: 1 [48256/60000 (80%)]\tLoss: 0.123389\n",
      "Train Epoch: 1 [48288/60000 (80%)]\tLoss: 0.058267\n",
      "Train Epoch: 1 [48320/60000 (81%)]\tLoss: 0.101708\n",
      "Train Epoch: 1 [48352/60000 (81%)]\tLoss: 0.326459\n",
      "Train Epoch: 1 [48384/60000 (81%)]\tLoss: 0.086728\n",
      "Train Epoch: 1 [48416/60000 (81%)]\tLoss: 0.007797\n",
      "Train Epoch: 1 [48448/60000 (81%)]\tLoss: 0.012916\n",
      "Train Epoch: 1 [48480/60000 (81%)]\tLoss: 0.023061\n",
      "Train Epoch: 1 [48512/60000 (81%)]\tLoss: 0.081140\n",
      "Train Epoch: 1 [48544/60000 (81%)]\tLoss: 0.017474\n",
      "Train Epoch: 1 [48576/60000 (81%)]\tLoss: 0.062635\n",
      "Train Epoch: 1 [48608/60000 (81%)]\tLoss: 0.026087\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.155041\n",
      "Train Epoch: 1 [48672/60000 (81%)]\tLoss: 0.010451\n",
      "Train Epoch: 1 [48704/60000 (81%)]\tLoss: 0.033656\n",
      "Train Epoch: 1 [48736/60000 (81%)]\tLoss: 0.013304\n",
      "Train Epoch: 1 [48768/60000 (81%)]\tLoss: 0.068067\n",
      "Train Epoch: 1 [48800/60000 (81%)]\tLoss: 0.126098\n",
      "Train Epoch: 1 [48832/60000 (81%)]\tLoss: 0.044653\n",
      "Train Epoch: 1 [48864/60000 (81%)]\tLoss: 0.014621\n",
      "Train Epoch: 1 [48896/60000 (81%)]\tLoss: 0.091459\n",
      "Train Epoch: 1 [48928/60000 (82%)]\tLoss: 0.358362\n",
      "Train Epoch: 1 [48960/60000 (82%)]\tLoss: 0.243057\n",
      "Train Epoch: 1 [48992/60000 (82%)]\tLoss: 0.261026\n",
      "Train Epoch: 1 [49024/60000 (82%)]\tLoss: 0.143414\n",
      "Train Epoch: 1 [49056/60000 (82%)]\tLoss: 0.112713\n",
      "Train Epoch: 1 [49088/60000 (82%)]\tLoss: 0.066994\n",
      "Train Epoch: 1 [49120/60000 (82%)]\tLoss: 0.147983\n",
      "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.040250\n",
      "Train Epoch: 1 [49184/60000 (82%)]\tLoss: 0.260715\n",
      "Train Epoch: 1 [49216/60000 (82%)]\tLoss: 0.139033\n",
      "Train Epoch: 1 [49248/60000 (82%)]\tLoss: 0.108145\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.070562\n",
      "Train Epoch: 1 [49312/60000 (82%)]\tLoss: 0.033138\n",
      "Train Epoch: 1 [49344/60000 (82%)]\tLoss: 0.027405\n",
      "Train Epoch: 1 [49376/60000 (82%)]\tLoss: 0.013907\n",
      "Train Epoch: 1 [49408/60000 (82%)]\tLoss: 0.106773\n",
      "Train Epoch: 1 [49440/60000 (82%)]\tLoss: 0.122062\n",
      "Train Epoch: 1 [49472/60000 (82%)]\tLoss: 0.413820\n",
      "Train Epoch: 1 [49504/60000 (83%)]\tLoss: 0.247538\n",
      "Train Epoch: 1 [49536/60000 (83%)]\tLoss: 0.552870\n",
      "Train Epoch: 1 [49568/60000 (83%)]\tLoss: 0.234357\n",
      "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.117906\n",
      "Train Epoch: 1 [49632/60000 (83%)]\tLoss: 0.380005\n",
      "Train Epoch: 1 [49664/60000 (83%)]\tLoss: 0.109750\n",
      "Train Epoch: 1 [49696/60000 (83%)]\tLoss: 0.045115\n",
      "Train Epoch: 1 [49728/60000 (83%)]\tLoss: 0.139004\n",
      "Train Epoch: 1 [49760/60000 (83%)]\tLoss: 0.083693\n",
      "Train Epoch: 1 [49792/60000 (83%)]\tLoss: 0.042683\n",
      "Train Epoch: 1 [49824/60000 (83%)]\tLoss: 0.108412\n",
      "Train Epoch: 1 [49856/60000 (83%)]\tLoss: 0.064072\n",
      "Train Epoch: 1 [49888/60000 (83%)]\tLoss: 0.387218\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.045819\n",
      "Train Epoch: 1 [49952/60000 (83%)]\tLoss: 0.026713\n",
      "Train Epoch: 1 [49984/60000 (83%)]\tLoss: 0.042940\n",
      "Train Epoch: 1 [50016/60000 (83%)]\tLoss: 0.033672\n",
      "Train Epoch: 1 [50048/60000 (83%)]\tLoss: 0.091682\n",
      "Train Epoch: 1 [50080/60000 (83%)]\tLoss: 0.076383\n",
      "Train Epoch: 1 [50112/60000 (84%)]\tLoss: 0.106551\n",
      "Train Epoch: 1 [50144/60000 (84%)]\tLoss: 0.059394\n",
      "Train Epoch: 1 [50176/60000 (84%)]\tLoss: 0.065956\n",
      "Train Epoch: 1 [50208/60000 (84%)]\tLoss: 0.270952\n",
      "Train Epoch: 1 [50240/60000 (84%)]\tLoss: 0.186741\n",
      "Train Epoch: 1 [50272/60000 (84%)]\tLoss: 0.063849\n",
      "Train Epoch: 1 [50304/60000 (84%)]\tLoss: 0.075176\n",
      "Train Epoch: 1 [50336/60000 (84%)]\tLoss: 0.187994\n",
      "Train Epoch: 1 [50368/60000 (84%)]\tLoss: 0.298392\n",
      "Train Epoch: 1 [50400/60000 (84%)]\tLoss: 0.509615\n",
      "Train Epoch: 1 [50432/60000 (84%)]\tLoss: 0.124513\n",
      "Train Epoch: 1 [50464/60000 (84%)]\tLoss: 0.031256\n",
      "Train Epoch: 1 [50496/60000 (84%)]\tLoss: 0.352578\n",
      "Train Epoch: 1 [50528/60000 (84%)]\tLoss: 0.024064\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.136080\n",
      "Train Epoch: 1 [50592/60000 (84%)]\tLoss: 0.072473\n",
      "Train Epoch: 1 [50624/60000 (84%)]\tLoss: 0.230595\n",
      "Train Epoch: 1 [50656/60000 (84%)]\tLoss: 0.017067\n",
      "Train Epoch: 1 [50688/60000 (84%)]\tLoss: 0.151651\n",
      "Train Epoch: 1 [50720/60000 (85%)]\tLoss: 0.063608\n",
      "Train Epoch: 1 [50752/60000 (85%)]\tLoss: 0.105382\n",
      "Train Epoch: 1 [50784/60000 (85%)]\tLoss: 0.041486\n",
      "Train Epoch: 1 [50816/60000 (85%)]\tLoss: 0.084394\n",
      "Train Epoch: 1 [50848/60000 (85%)]\tLoss: 0.029721\n",
      "Train Epoch: 1 [50880/60000 (85%)]\tLoss: 0.086757\n",
      "Train Epoch: 1 [50912/60000 (85%)]\tLoss: 0.072050\n",
      "Train Epoch: 1 [50944/60000 (85%)]\tLoss: 0.061006\n",
      "Train Epoch: 1 [50976/60000 (85%)]\tLoss: 0.087417\n",
      "Train Epoch: 1 [51008/60000 (85%)]\tLoss: 0.018199\n",
      "Train Epoch: 1 [51040/60000 (85%)]\tLoss: 0.100073\n",
      "Train Epoch: 1 [51072/60000 (85%)]\tLoss: 0.081450\n",
      "Train Epoch: 1 [51104/60000 (85%)]\tLoss: 0.058690\n",
      "Train Epoch: 1 [51136/60000 (85%)]\tLoss: 0.164174\n",
      "Train Epoch: 1 [51168/60000 (85%)]\tLoss: 0.078618\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.169249\n",
      "Train Epoch: 1 [51232/60000 (85%)]\tLoss: 0.198626\n",
      "Train Epoch: 1 [51264/60000 (85%)]\tLoss: 0.268596\n",
      "Train Epoch: 1 [51296/60000 (85%)]\tLoss: 0.164411\n",
      "Train Epoch: 1 [51328/60000 (86%)]\tLoss: 0.098682\n",
      "Train Epoch: 1 [51360/60000 (86%)]\tLoss: 0.042109\n",
      "Train Epoch: 1 [51392/60000 (86%)]\tLoss: 0.023123\n",
      "Train Epoch: 1 [51424/60000 (86%)]\tLoss: 0.079798\n",
      "Train Epoch: 1 [51456/60000 (86%)]\tLoss: 0.145351\n",
      "Train Epoch: 1 [51488/60000 (86%)]\tLoss: 0.007381\n",
      "Train Epoch: 1 [51520/60000 (86%)]\tLoss: 0.265249\n",
      "Train Epoch: 1 [51552/60000 (86%)]\tLoss: 0.100955\n",
      "Train Epoch: 1 [51584/60000 (86%)]\tLoss: 0.126843\n",
      "Train Epoch: 1 [51616/60000 (86%)]\tLoss: 0.035135\n",
      "Train Epoch: 1 [51648/60000 (86%)]\tLoss: 0.028929\n",
      "Train Epoch: 1 [51680/60000 (86%)]\tLoss: 0.128260\n",
      "Train Epoch: 1 [51712/60000 (86%)]\tLoss: 0.116589\n",
      "Train Epoch: 1 [51744/60000 (86%)]\tLoss: 0.218676\n",
      "Train Epoch: 1 [51776/60000 (86%)]\tLoss: 0.079153\n",
      "Train Epoch: 1 [51808/60000 (86%)]\tLoss: 0.010715\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.044467\n",
      "Train Epoch: 1 [51872/60000 (86%)]\tLoss: 0.058381\n",
      "Train Epoch: 1 [51904/60000 (87%)]\tLoss: 0.061386\n",
      "Train Epoch: 1 [51936/60000 (87%)]\tLoss: 0.187953\n",
      "Train Epoch: 1 [51968/60000 (87%)]\tLoss: 0.505242\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.067027\n",
      "Train Epoch: 1 [52032/60000 (87%)]\tLoss: 0.023786\n",
      "Train Epoch: 1 [52064/60000 (87%)]\tLoss: 0.192577\n",
      "Train Epoch: 1 [52096/60000 (87%)]\tLoss: 0.097223\n",
      "Train Epoch: 1 [52128/60000 (87%)]\tLoss: 0.474347\n",
      "Train Epoch: 1 [52160/60000 (87%)]\tLoss: 0.151501\n",
      "Train Epoch: 1 [52192/60000 (87%)]\tLoss: 0.160029\n",
      "Train Epoch: 1 [52224/60000 (87%)]\tLoss: 0.210665\n",
      "Train Epoch: 1 [52256/60000 (87%)]\tLoss: 0.095814\n",
      "Train Epoch: 1 [52288/60000 (87%)]\tLoss: 0.086602\n",
      "Train Epoch: 1 [52320/60000 (87%)]\tLoss: 0.144214\n",
      "Train Epoch: 1 [52352/60000 (87%)]\tLoss: 0.087859\n",
      "Train Epoch: 1 [52384/60000 (87%)]\tLoss: 0.076039\n",
      "Train Epoch: 1 [52416/60000 (87%)]\tLoss: 0.027563\n",
      "Train Epoch: 1 [52448/60000 (87%)]\tLoss: 0.072629\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.016144\n",
      "Train Epoch: 1 [52512/60000 (88%)]\tLoss: 0.021775\n",
      "Train Epoch: 1 [52544/60000 (88%)]\tLoss: 0.022936\n",
      "Train Epoch: 1 [52576/60000 (88%)]\tLoss: 0.021961\n",
      "Train Epoch: 1 [52608/60000 (88%)]\tLoss: 0.025906\n",
      "Train Epoch: 1 [52640/60000 (88%)]\tLoss: 0.057549\n",
      "Train Epoch: 1 [52672/60000 (88%)]\tLoss: 0.193465\n",
      "Train Epoch: 1 [52704/60000 (88%)]\tLoss: 0.088384\n",
      "Train Epoch: 1 [52736/60000 (88%)]\tLoss: 0.103553\n",
      "Train Epoch: 1 [52768/60000 (88%)]\tLoss: 0.041625\n",
      "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.240341\n",
      "Train Epoch: 1 [52832/60000 (88%)]\tLoss: 0.094170\n",
      "Train Epoch: 1 [52864/60000 (88%)]\tLoss: 0.121919\n",
      "Train Epoch: 1 [52896/60000 (88%)]\tLoss: 0.337004\n",
      "Train Epoch: 1 [52928/60000 (88%)]\tLoss: 0.361782\n",
      "Train Epoch: 1 [52960/60000 (88%)]\tLoss: 0.306115\n",
      "Train Epoch: 1 [52992/60000 (88%)]\tLoss: 0.031140\n",
      "Train Epoch: 1 [53024/60000 (88%)]\tLoss: 0.137183\n",
      "Train Epoch: 1 [53056/60000 (88%)]\tLoss: 0.030037\n",
      "Train Epoch: 1 [53088/60000 (88%)]\tLoss: 0.028348\n",
      "Train Epoch: 1 [53120/60000 (89%)]\tLoss: 0.043422\n",
      "Train Epoch: 1 [53152/60000 (89%)]\tLoss: 0.300188\n",
      "Train Epoch: 1 [53184/60000 (89%)]\tLoss: 0.044959\n",
      "Train Epoch: 1 [53216/60000 (89%)]\tLoss: 0.282995\n",
      "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 0.015719\n",
      "Train Epoch: 1 [53280/60000 (89%)]\tLoss: 0.006196\n",
      "Train Epoch: 1 [53312/60000 (89%)]\tLoss: 0.054557\n",
      "Train Epoch: 1 [53344/60000 (89%)]\tLoss: 0.004860\n",
      "Train Epoch: 1 [53376/60000 (89%)]\tLoss: 0.080645\n",
      "Train Epoch: 1 [53408/60000 (89%)]\tLoss: 0.009583\n",
      "Train Epoch: 1 [53440/60000 (89%)]\tLoss: 0.075694\n",
      "Train Epoch: 1 [53472/60000 (89%)]\tLoss: 0.099425\n",
      "Train Epoch: 1 [53504/60000 (89%)]\tLoss: 0.063719\n",
      "Train Epoch: 1 [53536/60000 (89%)]\tLoss: 0.068245\n",
      "Train Epoch: 1 [53568/60000 (89%)]\tLoss: 0.196027\n",
      "Train Epoch: 1 [53600/60000 (89%)]\tLoss: 0.097451\n",
      "Train Epoch: 1 [53632/60000 (89%)]\tLoss: 0.093380\n",
      "Train Epoch: 1 [53664/60000 (89%)]\tLoss: 0.068933\n",
      "Train Epoch: 1 [53696/60000 (89%)]\tLoss: 0.015927\n",
      "Train Epoch: 1 [53728/60000 (90%)]\tLoss: 0.083540\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.014346\n",
      "Train Epoch: 1 [53792/60000 (90%)]\tLoss: 0.104805\n",
      "Train Epoch: 1 [53824/60000 (90%)]\tLoss: 0.135857\n",
      "Train Epoch: 1 [53856/60000 (90%)]\tLoss: 0.347128\n",
      "Train Epoch: 1 [53888/60000 (90%)]\tLoss: 0.172657\n",
      "Train Epoch: 1 [53920/60000 (90%)]\tLoss: 0.020615\n",
      "Train Epoch: 1 [53952/60000 (90%)]\tLoss: 0.062644\n",
      "Train Epoch: 1 [53984/60000 (90%)]\tLoss: 0.110095\n",
      "Train Epoch: 1 [54016/60000 (90%)]\tLoss: 0.054474\n",
      "Train Epoch: 1 [54048/60000 (90%)]\tLoss: 0.057085\n",
      "Train Epoch: 1 [54080/60000 (90%)]\tLoss: 0.152147\n",
      "Train Epoch: 1 [54112/60000 (90%)]\tLoss: 0.018243\n",
      "Train Epoch: 1 [54144/60000 (90%)]\tLoss: 0.020468\n",
      "Train Epoch: 1 [54176/60000 (90%)]\tLoss: 0.084010\n",
      "Train Epoch: 1 [54208/60000 (90%)]\tLoss: 0.011034\n",
      "Train Epoch: 1 [54240/60000 (90%)]\tLoss: 0.099899\n",
      "Train Epoch: 1 [54272/60000 (90%)]\tLoss: 0.064401\n",
      "Train Epoch: 1 [54304/60000 (91%)]\tLoss: 0.079516\n",
      "Train Epoch: 1 [54336/60000 (91%)]\tLoss: 0.014768\n",
      "Train Epoch: 1 [54368/60000 (91%)]\tLoss: 0.098619\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.048279\n",
      "Train Epoch: 1 [54432/60000 (91%)]\tLoss: 0.076867\n",
      "Train Epoch: 1 [54464/60000 (91%)]\tLoss: 0.027867\n",
      "Train Epoch: 1 [54496/60000 (91%)]\tLoss: 0.232960\n",
      "Train Epoch: 1 [54528/60000 (91%)]\tLoss: 0.098861\n",
      "Train Epoch: 1 [54560/60000 (91%)]\tLoss: 0.121308\n",
      "Train Epoch: 1 [54592/60000 (91%)]\tLoss: 0.010615\n",
      "Train Epoch: 1 [54624/60000 (91%)]\tLoss: 0.022796\n",
      "Train Epoch: 1 [54656/60000 (91%)]\tLoss: 0.050362\n",
      "Train Epoch: 1 [54688/60000 (91%)]\tLoss: 0.035549\n",
      "Train Epoch: 1 [54720/60000 (91%)]\tLoss: 0.025745\n",
      "Train Epoch: 1 [54752/60000 (91%)]\tLoss: 0.133910\n",
      "Train Epoch: 1 [54784/60000 (91%)]\tLoss: 0.063684\n",
      "Train Epoch: 1 [54816/60000 (91%)]\tLoss: 0.070935\n",
      "Train Epoch: 1 [54848/60000 (91%)]\tLoss: 0.126254\n",
      "Train Epoch: 1 [54880/60000 (91%)]\tLoss: 0.153259\n",
      "Train Epoch: 1 [54912/60000 (92%)]\tLoss: 0.194966\n",
      "Train Epoch: 1 [54944/60000 (92%)]\tLoss: 0.162058\n",
      "Train Epoch: 1 [54976/60000 (92%)]\tLoss: 0.047903\n",
      "Train Epoch: 1 [55008/60000 (92%)]\tLoss: 0.029811\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.068498\n",
      "Train Epoch: 1 [55072/60000 (92%)]\tLoss: 0.025863\n",
      "Train Epoch: 1 [55104/60000 (92%)]\tLoss: 0.008745\n",
      "Train Epoch: 1 [55136/60000 (92%)]\tLoss: 0.031444\n",
      "Train Epoch: 1 [55168/60000 (92%)]\tLoss: 0.049574\n",
      "Train Epoch: 1 [55200/60000 (92%)]\tLoss: 0.055404\n",
      "Train Epoch: 1 [55232/60000 (92%)]\tLoss: 0.015849\n",
      "Train Epoch: 1 [55264/60000 (92%)]\tLoss: 0.055329\n",
      "Train Epoch: 1 [55296/60000 (92%)]\tLoss: 0.048950\n",
      "Train Epoch: 1 [55328/60000 (92%)]\tLoss: 0.246601\n",
      "Train Epoch: 1 [55360/60000 (92%)]\tLoss: 0.016194\n",
      "Train Epoch: 1 [55392/60000 (92%)]\tLoss: 0.032635\n",
      "Train Epoch: 1 [55424/60000 (92%)]\tLoss: 0.140721\n",
      "Train Epoch: 1 [55456/60000 (92%)]\tLoss: 0.043466\n",
      "Train Epoch: 1 [55488/60000 (92%)]\tLoss: 0.135493\n",
      "Train Epoch: 1 [55520/60000 (93%)]\tLoss: 0.103358\n",
      "Train Epoch: 1 [55552/60000 (93%)]\tLoss: 0.010836\n",
      "Train Epoch: 1 [55584/60000 (93%)]\tLoss: 0.141500\n",
      "Train Epoch: 1 [55616/60000 (93%)]\tLoss: 0.011903\n",
      "Train Epoch: 1 [55648/60000 (93%)]\tLoss: 0.061114\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.012009\n",
      "Train Epoch: 1 [55712/60000 (93%)]\tLoss: 0.131883\n",
      "Train Epoch: 1 [55744/60000 (93%)]\tLoss: 0.060837\n",
      "Train Epoch: 1 [55776/60000 (93%)]\tLoss: 0.135850\n",
      "Train Epoch: 1 [55808/60000 (93%)]\tLoss: 0.098376\n",
      "Train Epoch: 1 [55840/60000 (93%)]\tLoss: 0.168819\n",
      "Train Epoch: 1 [55872/60000 (93%)]\tLoss: 0.087124\n",
      "Train Epoch: 1 [55904/60000 (93%)]\tLoss: 0.038520\n",
      "Train Epoch: 1 [55936/60000 (93%)]\tLoss: 0.015490\n",
      "Train Epoch: 1 [55968/60000 (93%)]\tLoss: 0.033415\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.093052\n",
      "Train Epoch: 1 [56032/60000 (93%)]\tLoss: 0.015438\n",
      "Train Epoch: 1 [56064/60000 (93%)]\tLoss: 0.173547\n",
      "Train Epoch: 1 [56096/60000 (93%)]\tLoss: 0.016611\n",
      "Train Epoch: 1 [56128/60000 (94%)]\tLoss: 0.043914\n",
      "Train Epoch: 1 [56160/60000 (94%)]\tLoss: 0.137687\n",
      "Train Epoch: 1 [56192/60000 (94%)]\tLoss: 0.059863\n",
      "Train Epoch: 1 [56224/60000 (94%)]\tLoss: 0.185629\n",
      "Train Epoch: 1 [56256/60000 (94%)]\tLoss: 0.161611\n",
      "Train Epoch: 1 [56288/60000 (94%)]\tLoss: 0.041237\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.030243\n",
      "Train Epoch: 1 [56352/60000 (94%)]\tLoss: 0.089155\n",
      "Train Epoch: 1 [56384/60000 (94%)]\tLoss: 0.127697\n",
      "Train Epoch: 1 [56416/60000 (94%)]\tLoss: 0.009138\n",
      "Train Epoch: 1 [56448/60000 (94%)]\tLoss: 0.258810\n",
      "Train Epoch: 1 [56480/60000 (94%)]\tLoss: 0.198227\n",
      "Train Epoch: 1 [56512/60000 (94%)]\tLoss: 0.058544\n",
      "Train Epoch: 1 [56544/60000 (94%)]\tLoss: 0.011940\n",
      "Train Epoch: 1 [56576/60000 (94%)]\tLoss: 0.158951\n",
      "Train Epoch: 1 [56608/60000 (94%)]\tLoss: 0.083580\n",
      "Train Epoch: 1 [56640/60000 (94%)]\tLoss: 0.179031\n",
      "Train Epoch: 1 [56672/60000 (94%)]\tLoss: 0.024668\n",
      "Train Epoch: 1 [56704/60000 (95%)]\tLoss: 0.039560\n",
      "Train Epoch: 1 [56736/60000 (95%)]\tLoss: 0.015055\n",
      "Train Epoch: 1 [56768/60000 (95%)]\tLoss: 0.143164\n",
      "Train Epoch: 1 [56800/60000 (95%)]\tLoss: 0.159065\n",
      "Train Epoch: 1 [56832/60000 (95%)]\tLoss: 0.177247\n",
      "Train Epoch: 1 [56864/60000 (95%)]\tLoss: 0.105192\n",
      "Train Epoch: 1 [56896/60000 (95%)]\tLoss: 0.042330\n",
      "Train Epoch: 1 [56928/60000 (95%)]\tLoss: 0.002724\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.030510\n",
      "Train Epoch: 1 [56992/60000 (95%)]\tLoss: 0.051968\n",
      "Train Epoch: 1 [57024/60000 (95%)]\tLoss: 0.138140\n",
      "Train Epoch: 1 [57056/60000 (95%)]\tLoss: 0.106565\n",
      "Train Epoch: 1 [57088/60000 (95%)]\tLoss: 0.030010\n",
      "Train Epoch: 1 [57120/60000 (95%)]\tLoss: 0.022049\n",
      "Train Epoch: 1 [57152/60000 (95%)]\tLoss: 0.042795\n",
      "Train Epoch: 1 [57184/60000 (95%)]\tLoss: 0.082509\n",
      "Train Epoch: 1 [57216/60000 (95%)]\tLoss: 0.030551\n",
      "Train Epoch: 1 [57248/60000 (95%)]\tLoss: 0.147237\n",
      "Train Epoch: 1 [57280/60000 (95%)]\tLoss: 0.121186\n",
      "Train Epoch: 1 [57312/60000 (96%)]\tLoss: 0.064602\n",
      "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 0.012023\n",
      "Train Epoch: 1 [57376/60000 (96%)]\tLoss: 0.042322\n",
      "Train Epoch: 1 [57408/60000 (96%)]\tLoss: 0.020805\n",
      "Train Epoch: 1 [57440/60000 (96%)]\tLoss: 0.026002\n",
      "Train Epoch: 1 [57472/60000 (96%)]\tLoss: 0.106756\n",
      "Train Epoch: 1 [57504/60000 (96%)]\tLoss: 0.099323\n",
      "Train Epoch: 1 [57536/60000 (96%)]\tLoss: 0.034599\n",
      "Train Epoch: 1 [57568/60000 (96%)]\tLoss: 0.019389\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.068380\n",
      "Train Epoch: 1 [57632/60000 (96%)]\tLoss: 0.141271\n",
      "Train Epoch: 1 [57664/60000 (96%)]\tLoss: 0.073609\n",
      "Train Epoch: 1 [57696/60000 (96%)]\tLoss: 0.074525\n",
      "Train Epoch: 1 [57728/60000 (96%)]\tLoss: 0.320945\n",
      "Train Epoch: 1 [57760/60000 (96%)]\tLoss: 0.280892\n",
      "Train Epoch: 1 [57792/60000 (96%)]\tLoss: 0.024445\n",
      "Train Epoch: 1 [57824/60000 (96%)]\tLoss: 0.011025\n",
      "Train Epoch: 1 [57856/60000 (96%)]\tLoss: 0.076453\n",
      "Train Epoch: 1 [57888/60000 (96%)]\tLoss: 0.013719\n",
      "Train Epoch: 1 [57920/60000 (97%)]\tLoss: 0.010076\n",
      "Train Epoch: 1 [57952/60000 (97%)]\tLoss: 0.129968\n",
      "Train Epoch: 1 [57984/60000 (97%)]\tLoss: 0.007285\n",
      "Train Epoch: 1 [58016/60000 (97%)]\tLoss: 0.051046\n",
      "Train Epoch: 1 [58048/60000 (97%)]\tLoss: 0.063195\n",
      "Train Epoch: 1 [58080/60000 (97%)]\tLoss: 0.102100\n",
      "Train Epoch: 1 [58112/60000 (97%)]\tLoss: 0.008205\n",
      "Train Epoch: 1 [58144/60000 (97%)]\tLoss: 0.005689\n",
      "Train Epoch: 1 [58176/60000 (97%)]\tLoss: 0.030120\n",
      "Train Epoch: 1 [58208/60000 (97%)]\tLoss: 0.001780\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.056165\n",
      "Train Epoch: 1 [58272/60000 (97%)]\tLoss: 0.006895\n",
      "Train Epoch: 1 [58304/60000 (97%)]\tLoss: 0.016591\n",
      "Train Epoch: 1 [58336/60000 (97%)]\tLoss: 0.016305\n",
      "Train Epoch: 1 [58368/60000 (97%)]\tLoss: 0.066768\n",
      "Train Epoch: 1 [58400/60000 (97%)]\tLoss: 0.042453\n",
      "Train Epoch: 1 [58432/60000 (97%)]\tLoss: 0.005929\n",
      "Train Epoch: 1 [58464/60000 (97%)]\tLoss: 0.022750\n",
      "Train Epoch: 1 [58496/60000 (97%)]\tLoss: 0.003586\n",
      "Train Epoch: 1 [58528/60000 (98%)]\tLoss: 0.010468\n",
      "Train Epoch: 1 [58560/60000 (98%)]\tLoss: 0.004508\n",
      "Train Epoch: 1 [58592/60000 (98%)]\tLoss: 0.035140\n",
      "Train Epoch: 1 [58624/60000 (98%)]\tLoss: 0.063995\n",
      "Train Epoch: 1 [58656/60000 (98%)]\tLoss: 0.008904\n",
      "Train Epoch: 1 [58688/60000 (98%)]\tLoss: 0.014368\n",
      "Train Epoch: 1 [58720/60000 (98%)]\tLoss: 0.006802\n",
      "Train Epoch: 1 [58752/60000 (98%)]\tLoss: 0.011541\n",
      "Train Epoch: 1 [58784/60000 (98%)]\tLoss: 0.218889\n",
      "Train Epoch: 1 [58816/60000 (98%)]\tLoss: 0.191781\n",
      "Train Epoch: 1 [58848/60000 (98%)]\tLoss: 0.006921\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.005122\n",
      "Train Epoch: 1 [58912/60000 (98%)]\tLoss: 0.005045\n",
      "Train Epoch: 1 [58944/60000 (98%)]\tLoss: 0.003893\n",
      "Train Epoch: 1 [58976/60000 (98%)]\tLoss: 0.002677\n",
      "Train Epoch: 1 [59008/60000 (98%)]\tLoss: 0.006206\n",
      "Train Epoch: 1 [59040/60000 (98%)]\tLoss: 0.009680\n",
      "Train Epoch: 1 [59072/60000 (98%)]\tLoss: 0.020280\n",
      "Train Epoch: 1 [59104/60000 (99%)]\tLoss: 0.007332\n",
      "Train Epoch: 1 [59136/60000 (99%)]\tLoss: 0.001933\n",
      "Train Epoch: 1 [59168/60000 (99%)]\tLoss: 0.002102\n",
      "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.032125\n",
      "Train Epoch: 1 [59232/60000 (99%)]\tLoss: 0.010109\n",
      "Train Epoch: 1 [59264/60000 (99%)]\tLoss: 0.061706\n",
      "Train Epoch: 1 [59296/60000 (99%)]\tLoss: 0.090341\n",
      "Train Epoch: 1 [59328/60000 (99%)]\tLoss: 0.037248\n",
      "Train Epoch: 1 [59360/60000 (99%)]\tLoss: 0.060404\n",
      "Train Epoch: 1 [59392/60000 (99%)]\tLoss: 0.191253\n",
      "Train Epoch: 1 [59424/60000 (99%)]\tLoss: 0.030614\n",
      "Train Epoch: 1 [59456/60000 (99%)]\tLoss: 0.103801\n",
      "Train Epoch: 1 [59488/60000 (99%)]\tLoss: 0.003665\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.004191\n",
      "Train Epoch: 1 [59552/60000 (99%)]\tLoss: 0.009358\n",
      "Train Epoch: 1 [59584/60000 (99%)]\tLoss: 0.006548\n",
      "Train Epoch: 1 [59616/60000 (99%)]\tLoss: 0.014812\n",
      "Train Epoch: 1 [59648/60000 (99%)]\tLoss: 0.141163\n",
      "Train Epoch: 1 [59680/60000 (99%)]\tLoss: 0.234420\n",
      "Train Epoch: 1 [59712/60000 (100%)]\tLoss: 0.802660\n",
      "Train Epoch: 1 [59744/60000 (100%)]\tLoss: 0.194289\n",
      "Train Epoch: 1 [59776/60000 (100%)]\tLoss: 0.078206\n",
      "Train Epoch: 1 [59808/60000 (100%)]\tLoss: 0.063700\n",
      "Train Epoch: 1 [59840/60000 (100%)]\tLoss: 0.011735\n",
      "Train Epoch: 1 [59872/60000 (100%)]\tLoss: 0.047789\n",
      "Train Epoch: 1 [59904/60000 (100%)]\tLoss: 0.631175\n",
      "Train Epoch: 1 [59936/60000 (100%)]\tLoss: 0.046610\n",
      "Train Epoch: 1 [59968/60000 (100%)]\tLoss: 0.045027\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(12 * 13 * 13, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)  \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.fc(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, 32)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, 32)\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 216K\n",
      "-rw-rw-r-- 1 harzad harzad 82K Dis  20 07:29 mnist_model.onnx\n",
      "-rw-rw-r-- 1 harzad harzad 82K Dis  23 10:26 original_model.p\n",
      "-rw-rw-r-- 1 harzad harzad 24K Dis  20 23:25 post_quantized_model.p\n",
      "-rw-rw-r-- 1 harzad harzad 23K Dis  23 10:26 quantized_model.p\n"
     ]
    }
   ],
   "source": [
    "models_dir = pathlib.Path(\"./models/\")\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "torch.save(model.state_dict(), \"./models/original_model.p\")\n",
    "torch.save(quantized_model.state_dict(), \"./models/quantized_model.p\")\n",
    "\n",
    "%ls -lh models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model accuracy: 97%\n",
      "Quantized model accuracy: 97%\n"
     ]
    }
   ],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "original_acc = test(model, device, test_loader)\n",
    "quantized_acc = test(quantized_model, device, test_loader)\n",
    "\n",
    "print('Original model accuracy: {:.0f}%'.format(original_acc))\n",
    "print('Quantized model accuracy: {:.0f}%'.format(quantized_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, data_loader, neval_batches):\n",
    "    model.eval()\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "            cnt += 1\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            print('.', end = '')\n",
    "            top1.update(acc1[0], image.size(0))\n",
    "            top5.update(acc5[0], image.size(0))\n",
    "            if cnt >= neval_batches:\n",
    "                 return top1, top5\n",
    "\n",
    "    return top1, top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-training static quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 220K\n",
      "-rw-rw-r-- 1 harzad harzad 82K Dis  20 07:29 mnist_model.onnx\n",
      "-rw-rw-r-- 1 harzad harzad 82K Dis  23 10:26 original_model.p\n",
      "-rw-rw-r-- 1 harzad harzad 25K Dis  23 10:37 post_quantized_model.p\n",
      "-rw-rw-r-- 1 harzad harzad 23K Dis  23 10:26 quantized_model.p\n"
     ]
    }
   ],
   "source": [
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load(\"./models/original_model.p\"))\n",
    "loaded_model.to(\"cpu\")\n",
    "loaded_model.eval()\n",
    "\n",
    "loaded_model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "\n",
    "# model_fp32_fused = torch.ao.quantization.fuse_modules(loaded_model, [['conv1']])\n",
    "model_fp32_prepared = torch.ao.quantization.prepare(loaded_model)\n",
    "\n",
    "\n",
    "input_fp32 = next(iter(test_loader))[0][0:1]\n",
    "input_fp32.to(\"cpu\")\n",
    "model_fp32_prepared(input_fp32)\n",
    "model_int8 = torch.ao.quantization.convert(model_fp32_prepared)\n",
    "\n",
    "torch.save(model_int8.state_dict(), \"./models/post_quantized_model.p\")\n",
    "\n",
    "%ls -lh models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1874 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Conv.cpp:388 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:296 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:382 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:249 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:710 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quantized_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_int8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPost quantized model accuracy: \u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(quantized_acc))\n",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m      8\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# sum up batch loss\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# get the index of the max log-probability\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/model_optimization/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/model_optimization/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)  \n\u001b[0;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \n",
      "File \u001b[0;32m~/anaconda3/envs/model_optimization/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/model_optimization/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/model_optimization/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:468\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    465\u001b[0m     _reversed_padding_repeated_twice \u001b[38;5;241m=\u001b[39m _reverse_repeat_padding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding)\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, _reversed_padding_repeated_twice,\n\u001b[1;32m    467\u001b[0m                   mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_packed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_point\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/model_optimization/lib/python3.10/site-packages/torch/_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1874 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Conv.cpp:388 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:290 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:296 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:382 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:249 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:710 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "quantized_acc = test(model_int8, \"cpu\", test_loader)\n",
    "print('Post quantized model accuracy: {:.0f}%'.format(quantized_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_optimization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
